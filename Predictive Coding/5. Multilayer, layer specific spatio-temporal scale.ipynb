{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from torchviz import make_dot\n",
    "import pdb\n",
    "import numpy as np\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, hidden_size=10):\n",
    "        super(G, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        self.g1 = nn.Linear(np.prod(input_shape), hidden_size, bias=True)\n",
    "        self.g2 = nn.Linear(hidden_size, np.prod(output_shape), bias=True)\n",
    "        self.act = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape == self.input_shape\n",
    "        x = x.flatten()\n",
    "        x = F.relu(self.g1(x))\n",
    "        x = self.g2(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class Unit(nn.Module):\n",
    "    def __init__(self, name, layer_index, mu_shape, mu_next_shape, device):\n",
    "        super(Unit, self).__init__()\n",
    "        self.device = device\n",
    "        self.name = name\n",
    "        self.mu_shape = mu_shape\n",
    "        self.mu_next_shape = mu_next_shape\n",
    "\n",
    "        self.g = G(input_shape=mu_next_shape, output_shape=mu_shape)\n",
    "        self.f = G(input_shape=mu_shape, output_shape=mu_shape)\n",
    "        self.loss_g = 0\n",
    "        self.loss_f = 0\n",
    "\n",
    "        lr = 0.2\n",
    "        self.optimizer_g = optim.SGD(self.g.parameters(), lr=lr, momentum=0)\n",
    "        self.optimizer_f = optim.SGD(self.f.parameters(), lr=lr, momentum=0)\n",
    "\n",
    "        # this unit's state\n",
    "        self.previous_mu = torch.zeros(mu_shape).to(device)\n",
    "        self.mu = torch.zeros(mu_shape).to(device)\n",
    "        self.mu_bar = torch.zeros(mu_shape).to(device)\n",
    "        self.mu_hat = torch.zeros(mu_shape).to(device)\n",
    "\n",
    "        # next unit's mu\n",
    "        self.mu_next = torch.zeros(mu_next_shape).to(device)\n",
    "\n",
    "        # buffer for collecting mu\n",
    "        self.mu_buffer = SlidingWindowBuffer(mu_shape[0])\n",
    "\n",
    "#     def pool(self, buffer):\n",
    "#         x = np.reshape(np.array([b.detach().numpy() for b in buffer]), (1, 1, self.t_sample * self.temporal_pooling_size))\n",
    "#         x = torch.nn.functional.avg_pool1d(torch.tensor(x), kernel_size=self.temporal_pooling_size)\n",
    "#         return x.reshape(self.t_sample)\n",
    "\n",
    "    def add_mu_item(self, mu_item):\n",
    "        x = self.mu_buffer.append_item(mu_item)\n",
    "        if x is not None:\n",
    "            self.mu = torch.tensor(mu_buffer.buffer)\n",
    "        \n",
    "    def set_mu_next(self, mu_next):\n",
    "        self.mu_next = mu_next\n",
    "\n",
    "    def before_step(self):\n",
    "        pass\n",
    "\n",
    "    def compute_predictions(self):\n",
    "        self.mu_bar = self.f(self.previous_mu)\n",
    "        self.mu_hat = self.g(self.mu_next)\n",
    "\n",
    "    def train(self):\n",
    "        self.g.train()\n",
    "        self.optimizer_g.zero_grad()\n",
    "        self.mu_hat = self.g(self.mu_next)\n",
    "        self.loss_g = F.mse_loss(self.mu_hat, self.mu - self.mu_bar)\n",
    "        self.loss_g.backward()\n",
    "        self.optimizer_g.step()\n",
    "\n",
    "        self.f.train()\n",
    "        self.optimizer_f.zero_grad()\n",
    "        self.mu_bar = self.f(self.previous_mu)\n",
    "        self.loss_f = F.mse_loss(self.mu_bar, self.mu)\n",
    "        self.loss_f.backward()\n",
    "        self.optimizer_f.step()\n",
    "\n",
    "        self.previous_mu = self.mu.detach()\n",
    "\n",
    "    def history(self):\n",
    "        return [self.loss_g, self.loss_f, self.mu_bar[-1], self.mu_hat[-1], self.mu[-1], self.mu_bar[-1] + self.mu_hat[-1]]\n",
    "\n",
    "\n",
    "class UnitStack(nn.Module):\n",
    "    def __init__(self, units):\n",
    "        super(UnitStack, self).__init__()\n",
    "        self.units = units\n",
    "        self.unit_count = len(units)\n",
    "\n",
    "    def step(self, mu_item, mu_awareness, train=True):\n",
    "        # before step initialization\n",
    "        [self.units[layer].before_step() for layer in range(self.unit_count)]\n",
    "        \n",
    "        # forward error propagation\n",
    "        self.units[0].add_mu_item(mu_item)\n",
    "        self.units[-1].add_mu_item(mu_awareness)\n",
    "\n",
    "        for layer in range(1, self.unit_count):\n",
    "            # compute mu using previous layer's predictions\n",
    "            # mu is part of the signal the previous layer could not predict\n",
    "            self.units[layer].add_mu_item((self.units[layer - 1].mu - (self.units[layer - 1].mu_hat + self.units[layer - 1].mu_bar)).detach()[-1])\n",
    "                                                               \n",
    "            self.units[layer - 1].set_mu_next(self.units[layer].mu)\n",
    "\n",
    "        # backward flow of predictions\n",
    "        [self.units[layer].compute_predictions() for layer in range(self.unit_count - 1, -1, -1)]\n",
    "\n",
    "        # train\n",
    "        if train:\n",
    "            for layer in range(self.unit_count):\n",
    "                self.units[layer].train()\n",
    "        \n",
    "        # return stats\n",
    "        return [self.units[layer].history() for layer in range(self.unit_count)]\n",
    "        \n",
    "class SlidingWindowBuffer(object):\n",
    "    def __init__(self, item_count):\n",
    "        self.item_count = item_count\n",
    "        self.buffer = []\n",
    "        \n",
    "    def append_item(self, item):\n",
    "        # return None while gathering initial items\n",
    "        if len(self.buffer) < self.item_count - 1:\n",
    "            self.buffer.append(item)\n",
    "            return None\n",
    "        \n",
    "        # once enough items, convert to np.array\n",
    "        elif len(self.buffer) == self.item_count - 1:\n",
    "            self.buffer.append(item)\n",
    "            self.buffer = np.array(self.buffer)\n",
    "            \n",
    "        else:\n",
    "            self.buffer = np.roll(self.buffer, -1, axis=0)\n",
    "            self.buffer[-1] = item\n",
    "\n",
    "        return self.buffer\n",
    "\n",
    "class SampleDataPointsGenerator(object):\n",
    "    def __init__(self, shape=(1,)):\n",
    "        self.index = 0\n",
    "        self.count = np.empty(shape).size\n",
    "        \n",
    "    def __next__(self):\n",
    "        self.index += 1\n",
    "        if self.count == 1:\n",
    "            return np.sin(self.index/10.0 + np.random.random_sample() * 0.0) * np.cos(self.index/25.0) + np.random.random_sample() * 0.0\n",
    "        elif self.count == 2:\n",
    "            return [\n",
    "                np.cos(self.index/10.0 + np.random.random_sample() * 0.2) * np.sin(self.index/5.0),\n",
    "                np.sin(self.index/10.0 + np.random.random_sample() * 0.2) * np.cos(self.index/20.0)\n",
    "            ]\n",
    "\n",
    "def plot_history(loss_history, title=None):\n",
    "    loss_history = np.array(loss_history)\n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.plot(loss_history[:, 0],\"--\",label='loss_g')\n",
    "    plt.plot(loss_history[:, 1],\"--\",label='loss_f')\n",
    "    plt.plot(loss_history[:, 2],\"-\",label='mu_bar',linewidth=1,alpha = 0.3)\n",
    "    plt.plot(loss_history[:, 3],\"-\",label='mu_hat',linewidth=1,alpha = 0.3)\n",
    "    plt.plot(loss_history[:, 4],\"-\",label='mu', linewidth=2)\n",
    "    plt.plot(loss_history[:, 5],\"-\",label='mu_pred',linewidth=2, alpha = 0.5)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "torch.set_num_threads(12)\n",
    "\n",
    "t_sample = 10\n",
    "mu_shape = (t_sample, 1)\n",
    "unit_count = 10\n",
    "units = [Unit(name=\"unit{}\".format(i), layer_index=i, mu_shape=mu_shape, mu_next_shape=mu_shape, device=device) for i in range(unit_count)]\n",
    "\n",
    "network = UnitStack(units)\n",
    "\n",
    "loss_history = []\n",
    "mu_awareness = np.ones((t_sample,))\n",
    "\n",
    "mu_awareness = torch.tensor(mu_awareness, requires_grad=True).float().to(device)\n",
    "data_generator = SampleDataPointsGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input and target shapes do not match: input [10], target [10 x 1] at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/THNN/generic/MSECriterion.c:12",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9ad16589d1bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu_item\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_awareness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu_awareness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4338dfd2d403>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, mu_item, mu_awareness, train)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# return stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4338dfd2d403>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pointwise_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pointwise_loss\u001b[0;34m(lambd, lambd_optimized, input, target, reduction)\u001b[0m\n\u001b[1;32m   1672\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlambd_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input and target shapes do not match: input [10], target [10 x 1] at /Users/soumith/miniconda2/conda-bld/pytorch_1532623076075/work/aten/src/THNN/generic/MSECriterion.c:12"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "for i in range(5000):\n",
    "    loss = network.step(mu_item=next(data_generator), mu_awareness=mu_awareness, train=True)\n",
    "    # print(loss)\n",
    "\n",
    "    loss_history.append(loss)\n",
    "        \n",
    "    if (i+1) % 500 == 0:\n",
    "        [plot_history(np.array(loss_history)[:, i, :], title='unit {}'.format(i)) for i in range(unit_count)]\n",
    "\n",
    "        loss_history = []\n",
    "\n",
    "print(\"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cd4427ab4792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "s = torch.ones(10,2,3)\n",
    "s.view(10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"shell_port\": 53880,\n",
      "  \"iopub_port\": 53881,\n",
      "  \"stdin_port\": 53882,\n",
      "  \"control_port\": 53883,\n",
      "  \"hb_port\": 53884,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"8ec79334-75b11a739f32f5ee52a950e2\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-e5d06227-3a46-4532-af3b-cc0b7fd5cc2d.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
