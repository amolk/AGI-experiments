{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern Machine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOT52+8HWJWPEQRp2Y0HnD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amolk/AGI-experiments/blob/master/Pattern%20Machine/02_Pattern_Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH0h1CpkBIIc"
      },
      "source": [
        "Pattern machine\n",
        "- continuous, i.e. activation changes over time as decaying history of instantaneous activation\n",
        "- modular, i.e. connect up more flexibly,\n",
        "- use multi-patterns, i.e. pattern contains more than 1 weights tensor. This is to represent input and output jointly.\n",
        "\n",
        "Architectural decisions\n",
        "- Signal, SignalGrid, CompositeSignalGrid\n",
        "- input patches may overlap when utility factor > 1, fixed number (a grid) of patterns per patch\n",
        "- output neighborhood is the patterns corresponding to a neighborhood of patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4SBcILxqTNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61bb72d7-5a5b-44a2-ef83-ece2e75edc12"
      },
      "source": [
        "!pip install ipytest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipytest\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/d6/1797c114d57ec1c93b8078d81bd09b9f82d5f3a989c11fd1c575ff2846e7/ipytest-0.9.1-py3-none-any.whl\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipytest) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ipytest) (20.4)\n",
            "Collecting pytest>=5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ee/53945d50284906adb1e613fabf2e1b8b25926e8676854bb25b93564c0ce7/pytest-6.1.2-py3-none-any.whl (272kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.3.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (50.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (2.4.7)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (0.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (20.2.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipytest) (0.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.4->ipytest) (3.4.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, ipytest\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed ipytest-0.9.1 pluggy-0.13.1 pytest-6.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQhsjAS1XKB5"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WI0DQENlMSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c28d82d-3e24-43fe-a0d5-10a77e386d61"
      },
      "source": [
        "%%writefile utils.py\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "\n",
        "def pretty_s(name, clas, indent=0):\n",
        "  if type(clas).__name__ == 'Tensor':\n",
        "    return ' ' * indent + name + \":\" + type(clas).__name__ + \" size\" + str(tuple(clas.shape))\n",
        "\n",
        "  strs = []\n",
        "  strs.append(' ' * indent + name + \":\" + type(clas).__name__)\n",
        "\n",
        "  indent += 2\n",
        "  for k,v in clas.__dict__.items():\n",
        "    if '__dict__' in dir(v):\n",
        "      strs.append(pretty_s(k, v,indent))\n",
        "    elif '__iter__' in dir(v):\n",
        "      if type(v) is tuple:\n",
        "        strs.append(' ' * indent + k + ' = ' + str(v))\n",
        "      else:\n",
        "        strs.append(' ' * indent +  k + ' = [')\n",
        "        for index, item in enumerate(v):\n",
        "          if '__dict__' in dir(item):\n",
        "            strs.append(pretty_s(str(index), item, indent+2))\n",
        "          else:\n",
        "            strs.append(' ' * (indent+2) + str(item))\n",
        "        strs.append(' ' * indent +  ']')\n",
        "    else:\n",
        "      strs.append(' ' * indent +  k + ' = ' + str(v))\n",
        "\n",
        "  return \"\\n\".join(strs)\n",
        "          \n",
        "def pretty_print(name, clas, indent=0):\n",
        "  print(pretty_s(name, clas, indent))\n",
        "\n",
        "def soft_add(a, b, tau):\n",
        "  return a * (1 - tau) + b * tau\n",
        "\n",
        "def add_gaussian_noise(tensor, mean=0., std=1.):\n",
        "    t = tensor + torch.randn(tensor.size()).to(device) * std + mean\n",
        "    t.to(device)\n",
        "    return t\n",
        "\n",
        "def plot_patterns(patterns, pattern_lr, dataset, voronoi=False, annotate=False, figsize=(7,7), dpi=100):\n",
        "  patterns = patterns.cpu()\n",
        "  dataset = dataset.cpu()\n",
        "  assert len(patterns.shape) == 2 # (pattern count, 2)\n",
        "  assert patterns.shape[1] == 2 # 2D\n",
        "\n",
        "  rgba_colors = torch.zeros((patterns.shape[0], 4))\n",
        "\n",
        "  # for blue the last column needs to be one\n",
        "  rgba_colors[:,2] = 1.0\n",
        "  # the fourth column needs to be your alphas\n",
        "  if pattern_lr is not None:\n",
        "    alpha = (1.1 - pattern_lr.cpu()).clamp(0, 1) * 0.9\n",
        "    rgba_colors[:, 3] = alpha\n",
        "  else:\n",
        "    rgba_colors[:, 3] = 1.0\n",
        "\n",
        "  plt.figure(figsize=figsize, dpi=dpi)\n",
        "  ax = plt.gca()\n",
        "  ax.cla() # clear things for fresh plot\n",
        "\n",
        "  if annotate:\n",
        "    for i in range(patterns.shape[0]):\n",
        "      ax.annotate(str(i), (patterns[i][0], patterns[i][1]), xytext=(5,-3), textcoords='offset points')\n",
        "\n",
        "  ax.scatter(patterns[:, 0], patterns[:, 1], marker='.', c=rgba_colors, s=50)\n",
        "  ax.scatter(dataset[:, 0], dataset[:, 1], marker='.', c='r', s=10)\n",
        "\n",
        "  if voronoi:\n",
        "    vor = Voronoi(patterns)\n",
        "    vor_fig = voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='gray',\n",
        "                              line_width=1, line_alpha=0.2, point_size=0)\n",
        "\n",
        "  ax.set_xlim(0, 1)\n",
        "  ax.set_ylim(0, 1)\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Create a numpy array of given shape, each element initialized using supplied function\n",
        "Example: make_ndarray((2,3), lambda multi_index:multi_index)\n",
        "\"\"\"\n",
        "def make_ndarray(shape, fn):\n",
        "  a = np.empty(shape, dtype=object)\n",
        "  with np.nditer(a, flags=['refs_ok', 'multi_index'], op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      a[it.multi_index] = fn(it.multi_index)\n",
        "\n",
        "  return a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFuOT8nFZ9pl"
      },
      "source": [
        "%aimport utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbp81xkiBF_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c12c81-53a8-4222-e9ca-9bbb19aaa4fe"
      },
      "source": [
        "%%writefile pattern.py\n",
        "\n",
        "import torch\n",
        "import numpy\n",
        "import pdb\n",
        "from typing import List\n",
        "from utils import pretty_s\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GridShapeMismatchError(Exception): pass\n",
        "class NoComponentsError(Exception): pass\n",
        "\n",
        "class SignalUtils:\n",
        "  @staticmethod\n",
        "  def compute_precision(variance):\n",
        "    return torch.exp(-variance)\n",
        "\n",
        "class SignalGridHP:\n",
        "  def __init__(self, grid_shape, signal_shape, init_pixel_scale=0.1, init_variance=10):\n",
        "    self.grid_shape = grid_shape\n",
        "    self.grid_size = numpy.prod(self.grid_shape)\n",
        "    if self.grid_size <= 0:\n",
        "      raise ValueError(\"Invalid grid size\")\n",
        "\n",
        "    self.signal_shape = signal_shape\n",
        "    self.signal_size = numpy.prod(self.signal_shape)\n",
        "    if self.signal_size <= 0:\n",
        "      raise ValueError(\"Invalid signal size\")\n",
        "\n",
        "    self.init_pixel_scale = init_pixel_scale\n",
        "    self.init_variance = init_variance\n",
        "\n",
        "class SignalGrid:\n",
        "  def __init__(self, hp:SignalGridHP, alloc_pixels=True, pixels=None):\n",
        "    self.hp = hp\n",
        "    if pixels is not None:\n",
        "      self.pixels = pixels\n",
        "    elif alloc_pixels:\n",
        "      self.pixels = torch.rand((hp.grid_size, hp.signal_size)).to(device) * hp.init_pixel_scale\n",
        "    else:\n",
        "      self.pixels = None\n",
        "\n",
        "    self.variance = torch.ones((hp.grid_size, hp.signal_size)).to(device) * hp.init_variance\n",
        "    self.precision = SignalUtils.compute_precision(self.variance)\n",
        "\n",
        "  @property\n",
        "  def signal_shape(self):\n",
        "    return self.hp.signal_shape\n",
        "\n",
        "  @property\n",
        "  def __dict__(self):\n",
        "    return {\n",
        "        'grid_shape': self.hp.grid_shape,\n",
        "        'signal_shape': self.hp.signal_shape,\n",
        "        'pixels': self.pixels,\n",
        "        'precision': self.precision\n",
        "    }\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class CompositeSignalGridHP:\n",
        "  def __init__(self, hps:List[SignalGridHP]):\n",
        "    if len(hps) == 0:\n",
        "      raise NoComponentsError(\"Must specify at least one component\")\n",
        "\n",
        "    self.components = hps\n",
        "    self.grid_shape = hps[0].grid_shape\n",
        "\n",
        "    # all components must have same grid size\n",
        "    for component_hp in hps:\n",
        "      if component_hp.grid_shape != hps[0].grid_shape:\n",
        "        raise GridShapeMismatchError\n",
        "\n",
        "class CompositeSignalGrid:\n",
        "  @staticmethod\n",
        "  def from_tensors(signals:List[torch.Tensor], variance:float=0.0):\n",
        "    signal_hps = [SignalGridHP(grid_shape=(1,), signal_shape=signal.shape, init_variance=variance) for signal in signals]\n",
        "    hp = CompositeSignalGridHP(hps=signal_hps)\n",
        "    result = CompositeSignalGrid(hp=hp, alloc=False)\n",
        "    for index, component in enumerate(result.components):\n",
        "      component.pixels = signals[index].unsqueeze(0)\n",
        "    return result\n",
        "\n",
        "  def from_signal_grids(signal_grids:List[SignalGrid]):\n",
        "    result = CompositeSignalGrid(hp=None)\n",
        "    hp = CompositeSignalGridHP(hps=[sg.hp for sg in signal_grids])\n",
        "    result.hp = hp\n",
        "    result.components = signal_grids\n",
        "    return result\n",
        "\n",
        "  def __init__(self, hp:CompositeSignalGridHP=None, alloc=True):\n",
        "    self.hp = hp\n",
        "    if hp:\n",
        "      self.grid_shape = hp.grid_shape\n",
        "      self.components = [SignalGrid(component_hp, alloc_pixels=alloc) for component_hp in hp.components]\n",
        "\n",
        "  # add a SignalGrid as a component  \n",
        "  def add_component(self, o:SignalGrid):\n",
        "    assert self.hp.grid_shape == o.hp.grid_shape\n",
        "\n",
        "    self.hp.components.append(o.hp)\n",
        "    self.components.append(o)\n",
        "\n",
        "  @property\n",
        "  def signal_shape(self):\n",
        "    return [c.hp.signal_shape for c in self.components]\n",
        "\n",
        "  @property\n",
        "  def component_count(self):\n",
        "    return len(self.components)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class PatternGridHP:\n",
        "  def __init__(self, grid_shape, composite_signal_grid_hp:CompositeSignalGridHP):\n",
        "    self.grid_shape = grid_shape\n",
        "    self.grid_size = numpy.prod(self.grid_shape)\n",
        "\n",
        "    self.composite_signal_grid_hp = composite_signal_grid_hp\n",
        "    for component in composite_signal_grid_hp.components:\n",
        "      if component.grid_shape != self.grid_shape:\n",
        "        raise GridShapeMismatchError\n",
        "\n",
        "class PatternGrid:\n",
        "  def __init__(self, hp:PatternGridHP):\n",
        "    self.hp = hp\n",
        "    self.composite_signal_grid = CompositeSignalGrid(hp.composite_signal_grid_hp)\n",
        "    self.alpha = torch.ones((hp.grid_size,)).to(device)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class PatternSimilarityHP:\n",
        "  def __init__(self, enable_precision_weighted_distance=True):\n",
        "    self.enable_precision_weighted_distance = enable_precision_weighted_distance\n",
        "\n",
        "class PatternSimilarity:\n",
        "  def __init__(self, x:CompositeSignalGrid, y:CompositeSignalGrid, hp:PatternSimilarityHP=None):\n",
        "    \"\"\"\n",
        "    Find similarity between each item in x with each item in y.\n",
        "    grid_sizes (i.e. number of items) for x and y may differ.\n",
        "    signal shapes of x and y must match.\n",
        "    \"\"\"\n",
        "    if hp:\n",
        "      self.hp = hp\n",
        "    else:\n",
        "      self.hp = PatternSimilarityHP()\n",
        "\n",
        "    assert x.component_count == y.component_count, f\"x.component_count {x.component_count} != y.component_count {y.component_count}\"\n",
        "    assert x.signal_shape == y.signal_shape, f\"x.signal_shape {x.signal_shape} != y.signal_shape {y.signal_shape}\"\n",
        "\n",
        "    self.dist_1 = []\n",
        "    self.dist_d = []\n",
        "    self.dist = []\n",
        "    self.sim_components = []\n",
        "\n",
        "    # find similarity based on each signal component\n",
        "    for component_index in range(x.component_count):\n",
        "      x_component = x.components[component_index]\n",
        "      y_component = y.components[component_index]\n",
        "      dist_1_component, dist_d_component, dist_component = self.l2_distance(\n",
        "          x=x_component.pixels,\n",
        "          x_precision=x_component.precision,\n",
        "          y=y_component.pixels,\n",
        "          y_precision=y_component.precision)\n",
        "      sim_component = torch.exp(-dist_component)\n",
        "\n",
        "      self.dist_1.append(dist_1_component)\n",
        "      self.dist_d.append(dist_d_component)\n",
        "      self.dist.append(dist_component)\n",
        "      self.sim_components.append(sim_component)\n",
        "\n",
        "    # final similarity is mean of signal component similarities\n",
        "    # this equalizes class weights for all components (e.g. modalities)\n",
        "    self.sim = torch.stack(self.sim_components).mean(dim=0)\n",
        "\n",
        "  def l2_distance(self, x, x_precision, y, y_precision):\n",
        "    xs = x.shape\n",
        "    assert len(xs) == 2\n",
        "    assert (x_precision is None) or (x_precision.shape == xs), \"Precision, if specified, must be same shape as patterns\"\n",
        "\n",
        "    ys = y.shape\n",
        "    assert len(ys) == 2\n",
        "    assert (y_precision is None) or (y_precision.shape == ys), \"Precision, if specified, must be same shape as patterns\"\n",
        "\n",
        "    assert xs[1] == ys[1], \"Patch size, i.e. dim 1, must match\"\n",
        "\n",
        "    n = xs[0]\n",
        "    m = ys[0]\n",
        "    d = xs[1]\n",
        "\n",
        "    x = x.unsqueeze(1).expand(n, m, d)\n",
        "    y = y.unsqueeze(0).expand(n, m, d)\n",
        "\n",
        "    dist_1 = (x - y).abs()\n",
        "    dist_d = torch.pow(dist_1, 2)\n",
        "\n",
        "    if self.hp.enable_precision_weighted_distance:\n",
        "      if x_precision is not None:\n",
        "        dist_d = dist_d * x_precision.unsqueeze(1).expand(n, m, d)\n",
        "\n",
        "      if y_precision is not None:\n",
        "        dist_d = dist_d * y_precision.unsqueeze(0).expand(n, m, d)\n",
        "\n",
        "    dist = dist_d.sum(2).sqrt()\n",
        "    return dist_1, dist_d, dist\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting pattern.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ7AetD9sXXx"
      },
      "source": [
        "%aimport pattern"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFBqB6E_8Xrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb58af0-1937-47ff-9141-cc9a5c0a834f"
      },
      "source": [
        "%%writefile convoluation_utils.py\n",
        "import math\n",
        "from pattern import *\n",
        "from typing import List, Tuple\n",
        "\n",
        "class ConvolutionUtils:\n",
        "  @staticmethod\n",
        "  def make_afferent_patches(signal:CompositeSignalGrid, grid_shape:Tuple, coverage_factor:float=1.0):\n",
        "    # print(\"make_afferent_patches\")\n",
        "    # print(\"  signal\", signal.signal_shape)\n",
        "    # print(\"  grid_shape\", grid_shape)\n",
        "    # print(\"  coverage_factor\", coverage_factor)\n",
        "\n",
        "    assert signal.grid_shape == (1,)\n",
        "    for grid_shape_i in grid_shape:\n",
        "      assert grid_shape_i > 1\n",
        "\n",
        "    patch_signal_grids = []\n",
        "\n",
        "    for component_index in range(len(signal.components)):\n",
        "      # print(\"  component\", component_index)\n",
        "      component = signal.components[component_index]\n",
        "\n",
        "      patch_shape = tuple([int(coverage_factor *  component.signal_shape[i] / grid_shape[i]) for i in range(len(grid_shape))])\n",
        "      # print(\"    patch_shape\", patch_shape)\n",
        "      stride = tuple([math.floor((component.signal_shape[i]-patch_shape[i])/(grid_shape[i]-1)) for i in range(len(grid_shape))])\n",
        "      # print(\"    stride\", stride)\n",
        "\n",
        "      patches = ConvolutionUtil.conv_slice(component.pixels.view((1,) + component.hp.signal_shape), patch_shape, stride=stride).squeeze(dim=0)\n",
        "      sghp = SignalGridHP(grid_shape=grid_shape, signal_shape=patch_shape)\n",
        "      patch_signal_grid = SignalGrid(hp=sghp, alloc_pixels=False, pixels = patches)\n",
        "               \n",
        "      # print(\"  patch_signal_grid\", patch_signal_grid)\n",
        "      patch_signal_grids.append(patch_signal_grid)\n",
        "\n",
        "    patches = CompositeSignalGrid.from_signal_grids(patch_signal_grids)\n",
        "    return patches\n",
        "\n",
        "  def make_neighborhood_patches(signal:SignalGrid, patch_shape:Tuple):\n",
        "    # print(\"make_neighborhood_patches\")\n",
        "    # print(\"  signal\", signal)\n",
        "    # print(\"  patch_shape\", patch_shape)\n",
        "\n",
        "    assert signal.hp.grid_shape == (1,)\n",
        "\n",
        "    stride = 1 #(1,) * len(signal.signal_shape)\n",
        "    # print(\"  stride\", stride)\n",
        "\n",
        "    padding = tuple([int((i-1)/2) for i in patch_shape])\n",
        "    # print(\"  padding\", padding)\n",
        "\n",
        "    patches = ConvolutionUtil.conv_slice(signal.pixels.view((1,) + signal.hp.signal_shape), patch_shape, stride=stride, padding=padding).squeeze(dim=0)\n",
        "    sghp = SignalGridHP(grid_shape=signal.signal_shape, signal_shape=patch_shape)\n",
        "    patch_signal_grid = SignalGrid(hp=sghp, alloc_pixels=False, pixels = patches)\n",
        "              \n",
        "    # print(\"  patch_signal_grid\", patch_signal_grid)\n",
        "\n",
        "    return patch_signal_grid\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def conv_slice(images, kernel_shape, stride, padding=0):\n",
        "    assert len(images.shape) == 3, \"Must be (image count, image height, image width)\"\n",
        "    images = images.unsqueeze(1)\n",
        "\n",
        "    fold_params = dict(kernel_size=kernel_shape, dilation=1, padding=padding, stride=stride)\n",
        "    unfold = torch.nn.Unfold(**fold_params)\n",
        "    # print(\"images\", images.shape)\n",
        "    unfolded = unfold(images)\n",
        "    unfolded = unfolded.view(images.shape[0], -1, unfolded.shape[-1])\n",
        "    unfolded = unfolded.transpose(1, 2)\n",
        "    return unfolded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting convoluation_utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ptRk9z86rb"
      },
      "source": [
        "%aimport convoluation_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnMru_ABTjKx"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test SignalGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "import pdb\n",
        "from pattern import *\n",
        "\n",
        "def test_signal_grid_invalid_grid_size1():\n",
        "  with pytest.raises(ValueError):\n",
        "    SignalGridHP(\n",
        "      grid_shape=(0,4),     # <-- zero\n",
        "      signal_shape=(5,6,2)\n",
        "    )\n",
        "\n",
        "def test_signal_grid_invalid_grid_size2():\n",
        "  with pytest.raises(ValueError):\n",
        "    SignalGridHP(\n",
        "      grid_shape=(1,4),\n",
        "      signal_shape=(5,-1,2) # <-- negative\n",
        "    )\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid_hp1():\n",
        "  return SignalGridHP(\n",
        "      grid_shape=(3,4),\n",
        "      signal_shape=(5,6,2))\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid1(signal_grid_hp1):\n",
        "  return SignalGrid(hp=signal_grid_hp1)\n",
        "\n",
        "def test_create_signal_grid(signal_grid_hp1):\n",
        "  signal_grid = SignalGrid(hp=signal_grid_hp1)\n",
        "  assert signal_grid.pixels.shape == (3*4, 5*6*2)\n",
        "  assert signal_grid.variance.shape == signal_grid.pixels.shape\n",
        "  assert signal_grid.precision.shape == signal_grid.pixels.shape\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid_hp_degenerate():\n",
        "  return SignalGridHP(\n",
        "      grid_shape=(1),\n",
        "      signal_shape=(1))\n",
        "\n",
        "def test_create_signal_grid_degenerate(signal_grid_hp_degenerate):\n",
        "  signal_grid = SignalGrid(hp=signal_grid_hp_degenerate)\n",
        "  assert signal_grid.pixels.shape == (1, 1)\n",
        "  assert signal_grid.variance.shape == signal_grid.pixels.shape\n",
        "  assert signal_grid.precision.shape == signal_grid.pixels.shape\n",
        "\n",
        "def test_composite_signal_grid_from_tensors():\n",
        "  csg = CompositeSignalGrid.from_tensors([torch.ones((10,10)), torch.ones((5,5))])\n",
        "  assert csg.grid_shape == (1,)\n",
        "  assert len(csg.components) == 2\n",
        "\n",
        "  c0 = csg.components[0]\n",
        "  assert c0.hp.grid_shape == (1,)\n",
        "  assert c0.signal_shape == (10,10)\n",
        "\n",
        "  c1 = csg.components[1]\n",
        "  assert c1.hp.grid_shape == (1,)\n",
        "  assert c1.signal_shape == (5,5)\n",
        "\n",
        "def test_composite_signal_grid_from_signal_grids_error1():\n",
        "  grid_shape0 = (3,4)\n",
        "  signal_shape0 = (5,3,2)\n",
        "  grid_shape1 = (1,2)\n",
        "  signal_shape1 = (12)\n",
        "\n",
        "  sgs = [\n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape0, signal_shape=signal_shape0)), \n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape1, signal_shape=signal_shape1))\n",
        "  ]\n",
        "  with pytest.raises(GridShapeMismatchError):\n",
        "    CompositeSignalGrid.from_signal_grids(sgs)\n",
        "\n",
        "def test_composite_signal_grid_from_signal_grids():\n",
        "  grid_shape = (3,4)\n",
        "  signal_shape0 = (5,3,2)\n",
        "  signal_shape1 = (12)\n",
        "\n",
        "  sgs = [\n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape, signal_shape=signal_shape0)), \n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape, signal_shape=signal_shape1))\n",
        "  ]\n",
        "  csg = CompositeSignalGrid.from_signal_grids(sgs)\n",
        "  \n",
        "  assert csg.hp.grid_shape == grid_shape\n",
        "  assert len(csg.components) == 2\n",
        "\n",
        "  c0 = csg.components[0]\n",
        "  assert c0.hp.grid_shape == grid_shape\n",
        "  assert c0.signal_shape == signal_shape0\n",
        "\n",
        "  c1 = csg.components[1]\n",
        "  assert c1.hp.grid_shape == grid_shape\n",
        "  assert c1.signal_shape == signal_shape1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqW9IrAqxHv"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test CompositeSignalGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "\n",
        "def test_csg_zero_components():\n",
        "  \"\"\"\n",
        "  Must have at least 1 component\n",
        "  \"\"\"\n",
        "  with pytest.raises(NoComponentsError):\n",
        "    CompositeSignalGridHP([])\n",
        "\n",
        "def test_csg_different_grid_shapes():\n",
        "  \"\"\"\n",
        "  Components may not have different grid shapes\n",
        "  \"\"\"\n",
        "  with pytest.raises(GridShapeMismatchError):\n",
        "    CompositeSignalGridHP([\n",
        "      SignalGridHP(grid_shape=(1,2), signal_shape=(3,4)),\n",
        "      SignalGridHP(grid_shape=(2,2), signal_shape=(3,4))\n",
        "    ])\n",
        "\n",
        "@pytest.fixture\n",
        "def composite_signal_grid1():\n",
        "  return CompositeSignalGrid(CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=(1,2), signal_shape=(3,4)),\n",
        "    SignalGridHP(grid_shape=(1,2), signal_shape=(3,2,1))\n",
        "  ]))\n",
        "\n",
        "def test_csg_different_signal_shapes(composite_signal_grid1):\n",
        "  \"\"\"\n",
        "  Components may have different signal shapes\n",
        "  \"\"\"\n",
        "  assert composite_signal_grid1.component_count == 2\n",
        "  assert composite_signal_grid1.components[0].signal_shape == (3,4)\n",
        "  assert composite_signal_grid1.components[1].signal_shape == (3,2,1)\n",
        "  assert composite_signal_grid1.signal_shape == [(3,4), (3,2,1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4lPXN94vHcU"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test PatternGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "\n",
        "@pytest.fixture\n",
        "def pg1():\n",
        "  grid_shape = (1,2)\n",
        "  csg_hp = CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,4)),\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,2,1))\n",
        "  ])\n",
        "\n",
        "  pg_hp = PatternGridHP(\n",
        "      grid_shape=grid_shape,\n",
        "      composite_signal_grid_hp= csg_hp\n",
        "  )\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_pg_create(pg1):\n",
        "  pg1.alpha.shape == (1,2)\n",
        "\n",
        "@pytest.fixture\n",
        "def pg2():\n",
        "  grid_shape = (1,)\n",
        "  csg_hp = CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(1,)),\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(1,))\n",
        "  ])\n",
        "\n",
        "  pg_hp = PatternGridHP(\n",
        "      grid_shape=grid_shape,\n",
        "      composite_signal_grid_hp= csg_hp\n",
        "  )\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_pg_create_2(pg2):\n",
        "  pg2.alpha.shape == (1,)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQ4WOe3WpLi"
      },
      "source": [
        "%%run_pytest[clean] -s\n",
        "\"\"\"\n",
        "Test Similarity\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "from utils import *\n",
        "\n",
        "def make_pg():\n",
        "  grid_shape = (2,4)\n",
        "  csg_hp = CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,4)),\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,2,1))\n",
        "  ])\n",
        "\n",
        "  pg_hp = PatternGridHP(\n",
        "      grid_shape=grid_shape,\n",
        "      composite_signal_grid_hp= csg_hp\n",
        "  )\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def make_pg2():\n",
        "  grid_shape = (3,2)\n",
        "  csg_hp = CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,4)),\n",
        "    SignalGridHP(grid_shape=grid_shape, signal_shape=(3,2,1))\n",
        "  ])\n",
        "\n",
        "  pg_hp = PatternGridHP(\n",
        "      grid_shape=grid_shape,\n",
        "      composite_signal_grid_hp= csg_hp\n",
        "  )\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_sim_low_precision():\n",
        "  # By default, very low precision, so equal even when pixels are random\n",
        "  pgs = [make_pg(), make_pg2()]\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid)\n",
        "  assert sim.sim.shape == (pgs[0].hp.grid_size, pgs[1].hp.grid_size)\n",
        "  assert torch.allclose(sim.sim, torch.ones_like(sim.sim))\n",
        "\n",
        "def test_sim_disable_precision_weighting():\n",
        "  # If disabled precision weighting, then unequal because pixels are random\n",
        "  pgs = [make_pg(), make_pg2()]\n",
        "  hp = PatternSimilarityHP(enable_precision_weighted_distance=False)\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid, hp=hp)\n",
        "  assert sim.sim.shape == (pgs[0].hp.grid_size, pgs[1].hp.grid_size)\n",
        "  assert not torch.allclose(sim.sim, torch.ones_like(sim.sim))\n",
        "\n",
        "def test_sim_high_precision():\n",
        "  # If high precision, then unequal given pixels are random\n",
        "  pgs = [make_pg(), make_pg2()]\n",
        "\n",
        "  # force high precisions\n",
        "  for pg in pgs:\n",
        "    for component in pg.composite_signal_grid.components:\n",
        "      component.precision = torch.ones_like(component.precision)\n",
        "\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid)\n",
        "  assert sim.sim.shape == (pgs[0].hp.grid_size, pgs[1].hp.grid_size)\n",
        "  assert not torch.allclose(sim.sim, torch.ones_like(sim.sim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvisc3G4cvFB"
      },
      "source": [
        "%%writefile layer.py\n",
        "\n",
        "import torch\n",
        "import numpy\n",
        "import pdb\n",
        "from typing import List, Tuple\n",
        "from pattern import *\n",
        "import math\n",
        "from utils import *\n",
        "from convoluation_utils import ConvolutionUtils\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CompositeSignalPatchGrid:\n",
        "  def __init__(self, signal:CompositeSignalGrid, grid_shape:Tuple, coverage_factor=1.0):\n",
        "    # signal, i.e. composite image, must be a single composite signal, i.e. its grid shape must be (1,)\n",
        "    assert signal.grid_shape == (1,)\n",
        "\n",
        "    self.patches:CompositeSignalGrid = ConvolutionUtils.make_afferent_patches(signal=signal, grid_shape=grid_shape, coverage_factor=coverage_factor)\n",
        "\n",
        "class NeighborhoodPatchGrid:\n",
        "  def __init__(self, signal:SignalGrid, patch_shape:Tuple):\n",
        "    # signal must be a single signal, i.e. its grid shape must be (1,)\n",
        "    assert signal.grid_shape == (1,)\n",
        "\n",
        "    # makes one patch per element of the image using neighborhood around the element, i.e. output grid shape = image shape\n",
        "    self.patches:SignalGrid = ConvolutionUtils.make_neighborhood_patches(signal=signal, patch_shape=patch_shape)\n",
        "\n",
        "class InputOutputPatchGrid:\n",
        "  def __init__(self, input:CompositeSignalGrid, output:SignalGrid, output_patch_shape:Tuple, input_coverage_factor=1.0):\n",
        "    input_grid_shape = output.signal_shape\n",
        "\n",
        "    self.input_patches = CompositeSignalPatchGrid(signal=input, grid_shape=input_grid_shape, coverage_factor=input_coverage_factor)\n",
        "    self.output_patches = NeighborhoodPatchGrid(signal=output, patch_shape=output_patch_shape)\n",
        "    \n",
        "    self.patches = self.input_patches.patches\n",
        "    self.patches.add_component(self.output_patches.patches)\n",
        "\n",
        "# A grid of patterns for each patch in a grid of patches\n",
        "class PatchGridPatterns:\n",
        "  def __init__(self, patch_grid_shape:Tuple, per_patch_pattern_grid_hp:PatternGridHP):\n",
        "    self.patterns = make_ndarray(patch_grid_shape, lambda multi_index: PatternGrid(hp=per_patch_pattern_grid_hp))\n",
        "\n",
        "class LayerHP:\n",
        "  def __init__(self, input_signal_shapes:List[Tuple], input_coverage_factor:float, output_shape:Tuple, per_patch_pattern_grid_shape:Tuple, output_neighborhood_shape:Tuple, output_tau=0.5):\n",
        "    self.input_signal_shapes = input_signal_shapes\n",
        "    self.input_coverage_factor = input_coverage_factor\n",
        "    self.output_shape = output_shape\n",
        "    self.per_patch_pattern_grid_shape = per_patch_pattern_grid_shape\n",
        "    self.output_neighborhood_shape = output_neighborhood_shape\n",
        "    self.output_tau = output_tau\n",
        "\n",
        "    for size in self.output_neighborhood_shape:\n",
        "      assert size % 2 == 1, \"Output neighborhood shape must be odd, so can be centered around specific output activation\"\n",
        "\n",
        "    self.output_hp = SignalGridHP(grid_shape=(1,), signal_shape=output_shape, init_pixel_scale=0.0)\n",
        "\n",
        "    # sample_input_signal = [torch.ones(shape) for shape in input_signal_shapes]\n",
        "    # self.convolve_input = convolve_input\n",
        "    # sample_input = CompositeSignalGrid.from_tensors(sample_input_signal)\n",
        "    # patches = LayerUtils.make_input_patches(input=sample_input, output_shape=output_shape)\n",
        "\n",
        "    # # input grid HP\n",
        "    # hps = [\n",
        "    #   SignalGridHP(\n",
        "    #       grid_shape=output_shape, # Each grid element in input grid produces 1 pixel of output\n",
        "    #       signal_shape=input_component.signal_shape)\n",
        "    #   for input_component in patches.components # each component of input\n",
        "    # ]\n",
        "    # self.input_grid_hp = CompositeSignalGridHP(hps=hps.copy())\n",
        "\n",
        "    # # pattern HP\n",
        "    # hps.append(SignalGridHP(\n",
        "    #     grid_shape=output_shape,\n",
        "    #     signal_shape=output_neighborhood_shape))\n",
        "\n",
        "    # self.pattern_grid_hp = PatternGridHP(\n",
        "    #     grid_shape=pattern_grid_shape,\n",
        "    #     composite_signal_grid_hp=CompositeSignalGridHP(hps=[\n",
        "    #       SignalGridHP(grid_shape=pattern_grid_shape, signal_shape=component.signal_shape)\n",
        "    #      for component in hps]))\n",
        "\n",
        "class Layer:\n",
        "  def __init__(self, hp:LayerHP):\n",
        "    self.hp = hp\n",
        "    self.patterns = PatchGridPatterns(patch_grid_shape=self.hp.output_shape, per_patch_pattern_grid_hp=self.hp.per_patch_pattern_grid_hp)\n",
        "    self.output = SignalGrid(hp.output_hp)\n",
        "\n",
        "  def forward(self, input:CompositeSignalGrid):\n",
        "    assert input.grid_shape == (1,) # single signal input\n",
        "\n",
        "    input_output_patch_grid = InputOutputPatchGrid(input=input, output=self.output, output_patch_shape=self.hp.output_neighborhood_shape, input_coverage_factor=1.0)\n",
        "    # patches = LayerUtils.make_input_output_composite_patches(input=input, output=self.output, output_shape=self.hp.output_shape, output_neighborhood_shape=self.hp.output_neighborhood_shape, convolve_input=self.hp.convolve_input)\n",
        "\n",
        "    pattern_similarity = PatternSimilarity(x=input_output_patch_grid.patches, y=self.patterns.patterns.composite_signal_grid)\n",
        "    \n",
        "    activation = pattern_similarity.sim\n",
        "    activation = activation.max(dim=-1)[0].unsqueeze(dim=0)\n",
        "    assert self.output.pixels.shape == activation.shape \n",
        "\n",
        "    self.output.pixels = soft_add(self.output.pixels, activation, tau=self.hp.output_tau)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozYdg-Q-q_aU"
      },
      "source": [
        "%aimport layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzMn4q-FrA9K"
      },
      "source": [
        "\n",
        "%%run_pytest[clean] -s\n",
        "\"\"\"\n",
        "Test Layer\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from utils import *\n",
        "from pattern import *\n",
        "from layer import *\n",
        "\n",
        "def test_layer_create():\n",
        "  hp = LayerHP(pattern_grid_shape=(2,2), output_shape=(5,5), output_neighborhood_shape=(3,3), input_signal_shapes=[(10,15),(20,10)])\n",
        "  layer = Layer(hp=hp)\n",
        "  # pretty_print(\"Layer\", layer)\n",
        "  assert(True)\n",
        "\n",
        "def test_layer_forward():\n",
        "  input_signal_shapes = [(10,10), (20,20)]\n",
        "  input_signals = [torch.ones(shape) for shape in input_signal_shapes]\n",
        "  input = CompositeSignalGrid.from_tensors(input_signals)\n",
        "  hp = LayerHP(pattern_grid_shape=(2,3), output_shape=(5,5), output_neighborhood_shape=(3,3), input_signal_shapes=input_signal_shapes)\n",
        "  layer = Layer(hp=hp)\n",
        "  #pretty_print(\"Layer\", layer)\n",
        "\n",
        "  for _ in range(10):\n",
        "    layer.forward(input)\n",
        "\n",
        "  assert torch.allclose(layer.output.pixels, torch.ones_like(layer.output.pixels), atol=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGs1sDJ4BaU9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.datasets import load_boston\n",
        "from utils import *\n",
        "from layer import *\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def normalize(df):\n",
        "  df1 = (df - df.mean())/df.std()\n",
        "  return df1\n",
        "\n",
        "def scale(df):\n",
        "  min = df.min()\n",
        "  max = df.max()\n",
        "\n",
        "  df1 = (df - min) / (max - min)\n",
        "  return df1\n",
        "\n",
        "dataset = load_boston()\n",
        "dataset = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "dataset = pd.DataFrame(np.c_[scale(normalize(dataset['LSTAT'])), scale(normalize(dataset['RM']))], columns = ['LSTAT','RM'])\n",
        "dataset = torch.tensor(dataset.to_numpy()).float().to(device)\n",
        "dataset\n",
        "\n",
        "input_signal_shapes = [(1,)]\n",
        "hp = LayerHP(pattern_grid_shape=(10,10), output_shape=(1,), output_neighborhood_shape=(1,), input_signal_shapes=input_signal_shapes, convolve_input=False)\n",
        "layer = Layer(hp=hp)\n",
        "\n",
        "plot_patterns(patterns=None, pattern_lr=None, dataset=dataset, voronoi=False, annotate=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VoWZ-OfsGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f84e60-6cc1-43f3-aee6-87cdd2507c3f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def make_ndarray(shape, fn):\n",
        "  a = np.empty(shape, dtype=object)\n",
        "  with np.nditer(a, flags=['refs_ok', 'multi_index'], op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      a[it.multi_index] = fn(it.multi_index)\n",
        "\n",
        "  return a\n",
        "\n",
        "make_ndarray((2,3), lambda multi_index:multi_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[(0, 0), (0, 1), (0, 2)],\n",
              "       [(1, 0), (1, 1), (1, 2)]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXW2KE0yPV4j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa4LHN3uHaoX"
      },
      "source": [
        "We have patch grid of composite signal. Each composite signal gets its own grid of patterns."
      ]
    }
  ]
}