{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern Machine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOkejSGQ1T671zhYTh2mRt1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amolk/AGI-experiments/blob/master/Pattern%20Machine/03_Pattern_Machine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH0h1CpkBIIc"
      },
      "source": [
        "Pattern machine\n",
        "- continuous, i.e. activation changes over time as decaying history of instantaneous activation\n",
        "- modular, i.e. connect up more flexibly,\n",
        "- use multi-patterns, i.e. pattern contains more than 1 weights tensor. This is to represent input and output jointly.\n",
        "\n",
        "Architectural decisions\n",
        "- Signal, SignalGrid, CompositeSignalGrid\n",
        "- input patches may overlap when utility factor > 1, fixed number (a grid) of patterns per patch\n",
        "- output neighborhood is the patterns corresponding to a neighborhood of patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4SBcILxqTNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad89052-d7cc-496d-9a09-ea7ded71b98f"
      },
      "source": [
        "!pip install ipytest"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ipytest\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/d6/1797c114d57ec1c93b8078d81bd09b9f82d5f3a989c11fd1c575ff2846e7/ipytest-0.9.1-py3-none-any.whl\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ipytest) (20.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipytest) (5.5.0)\n",
            "Collecting pytest>=5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/ee/53945d50284906adb1e613fabf2e1b8b25926e8676854bb25b93564c0ce7/pytest-6.1.2-py3-none-any.whl (272kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (1.15.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.4.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (50.3.2)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (20.2.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n",
            "Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (0.10.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipytest) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipytest) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipytest) (0.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.4->ipytest) (3.4.0)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pluggy, pytest, ipytest\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "Successfully installed ipytest-0.9.1 pluggy-0.13.1 pytest-6.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQhsjAS1XKB5"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 1\n",
        "import ipytest\n",
        "ipytest.autoconfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WI0DQENlMSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb32d25-74c7-435c-c019-aba3e43d8877"
      },
      "source": [
        "%%writefile utils.py\n",
        "import pdb\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "\n",
        "def pretty_s(name, clas, indent=0):\n",
        "  if type(clas).__name__ == 'Tensor':\n",
        "    return ' ' * indent + name + \":\" + type(clas).__name__ + \" size\" + str(tuple(clas.shape))\n",
        "\n",
        "  strs = []\n",
        "  strs.append(' ' * indent + name + \":\" + type(clas).__name__)\n",
        "\n",
        "  indent += 2\n",
        "  for k,v in clas.__dict__.items():\n",
        "    if '__dict__' in dir(v):\n",
        "      strs.append(pretty_s(k, v,indent))\n",
        "    elif '__iter__' in dir(v):\n",
        "      if type(v) is tuple:\n",
        "        strs.append(' ' * indent + k + ' = ' + str(v))\n",
        "      else:\n",
        "        strs.append(' ' * indent +  k + ' = [')\n",
        "        for index, item in enumerate(v):\n",
        "          if '__dict__' in dir(item):\n",
        "            strs.append(pretty_s(str(index), item, indent+2))\n",
        "          else:\n",
        "            strs.append(' ' * (indent+2) + str(item))\n",
        "        strs.append(' ' * indent +  ']')\n",
        "    else:\n",
        "      strs.append(' ' * indent +  k + ' = ' + str(v))\n",
        "\n",
        "  return \"\\n\".join(strs)\n",
        "          \n",
        "def pretty_print(name, clas, indent=0):\n",
        "  print(pretty_s(name, clas, indent))\n",
        "\n",
        "def soft_add(a, b, tau):\n",
        "  return a * (1 - tau) + b * tau\n",
        "\n",
        "def add_gaussian_noise(tensor, mean=0., std=1.):\n",
        "    t = tensor + torch.randn(tensor.size()).to(device) * std + mean\n",
        "    t.to(device)\n",
        "    return t\n",
        "\n",
        "def plot_patterns(patterns, pattern_lr, dataset, voronoi=False, annotate=False, figsize=(7,7), dpi=100):\n",
        "  patterns = patterns.cpu()\n",
        "  dataset = dataset.cpu()\n",
        "  assert len(patterns.shape) == 2 # (pattern count, 2)\n",
        "  assert patterns.shape[1] == 2 # 2D\n",
        "\n",
        "  rgba_colors = torch.zeros((patterns.shape[0], 4))\n",
        "\n",
        "  # for blue the last column needs to be one\n",
        "  rgba_colors[:,2] = 1.0\n",
        "  # the fourth column needs to be your alphas\n",
        "  if pattern_lr is not None:\n",
        "    alpha = (1.1 - pattern_lr.cpu()).clamp(0, 1) * 0.9\n",
        "    rgba_colors[:, 3] = alpha\n",
        "  else:\n",
        "    rgba_colors[:, 3] = 1.0\n",
        "\n",
        "  plt.figure(figsize=figsize, dpi=dpi)\n",
        "  ax = plt.gca()\n",
        "  ax.cla() # clear things for fresh plot\n",
        "\n",
        "  if annotate:\n",
        "    for i in range(patterns.shape[0]):\n",
        "      ax.annotate(str(i), (patterns[i][0], patterns[i][1]), xytext=(5,-3), textcoords='offset points')\n",
        "\n",
        "  ax.scatter(patterns[:, 0], patterns[:, 1], marker='.', c=rgba_colors, s=50)\n",
        "  ax.scatter(dataset[:, 0], dataset[:, 1], marker='.', c='r', s=10)\n",
        "\n",
        "  if voronoi:\n",
        "    vor = Voronoi(patterns)\n",
        "    vor_fig = voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='gray',\n",
        "                              line_width=1, line_alpha=0.2, point_size=0)\n",
        "\n",
        "  ax.set_xlim(0, 1)\n",
        "  ax.set_ylim(0, 1)\n",
        "  plt.show()\n",
        "\n",
        "\"\"\"\n",
        "Create a numpy array of given shape, each element initialized using supplied function\n",
        "Example: make_ndarray((2,3), lambda multi_index:multi_index)\n",
        "\"\"\"\n",
        "def make_ndarray(shape, fn):\n",
        "  a = np.empty(shape, dtype=object)\n",
        "  with np.nditer(a, flags=['refs_ok', 'multi_index'], op_flags=['readwrite']) as it:\n",
        "    for x in it:\n",
        "      a[it.multi_index] = fn(it.multi_index)\n",
        "\n",
        "  return a"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFuOT8nFZ9pl"
      },
      "source": [
        "%aimport utils"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lbp81xkiBF_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c4d487-e2df-4aab-b1a8-3d9242a993bf"
      },
      "source": [
        "%%writefile pattern.py\n",
        "\n",
        "import torch\n",
        "import numpy\n",
        "import pdb\n",
        "from typing import List, Tuple\n",
        "from utils import pretty_s\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GridShapeMismatchError(Exception): pass\n",
        "class NoComponentsError(Exception): pass\n",
        "\n",
        "class SignalUtils:\n",
        "  @staticmethod\n",
        "  def compute_precision(variance):\n",
        "    return torch.exp(-variance)\n",
        "\n",
        "class SignalGridHP:\n",
        "  def __init__(self, grid_shape:Tuple, signal_shape:Tuple, init_pixel_scale:float=0.1, init_variance:float=10):\n",
        "    self.grid_shape = grid_shape\n",
        "    self.grid_size = np.prod(self.grid_shape)\n",
        "    if self.grid_size <= 0:\n",
        "      raise ValueError(\"Invalid grid size\")\n",
        "\n",
        "    self.signal_shape = tuple(signal_shape)\n",
        "    self.signal_size = np.prod(self.signal_shape)\n",
        "    if self.signal_size <= 0:\n",
        "      raise ValueError(\"Invalid signal size\")\n",
        "\n",
        "    self.init_pixel_scale = init_pixel_scale\n",
        "    self.init_variance = init_variance\n",
        "\n",
        "class SignalGrid:\n",
        "  def __init__(self, hp:SignalGridHP, alloc_pixels=True, pixels=None):\n",
        "    self.hp = hp\n",
        "    if pixels is not None:\n",
        "      self.pixels = pixels\n",
        "    elif alloc_pixels:\n",
        "      self.pixels = torch.rand((hp.grid_size, hp.signal_size)).to(device) * hp.init_pixel_scale\n",
        "    else:\n",
        "      self.pixels = None\n",
        "\n",
        "    self.variance = torch.ones((hp.grid_size, hp.signal_size)).to(device) * hp.init_variance\n",
        "    self.refresh_precision()\n",
        "\n",
        "  def refresh_precision(self):\n",
        "    self.precision = SignalUtils.compute_precision(self.variance)\n",
        "\n",
        "  @property\n",
        "  def signal_shape(self):\n",
        "    return self.hp.signal_shape\n",
        "\n",
        "  @property\n",
        "  def __dict__(self):\n",
        "    return {\n",
        "        'grid_shape': self.hp.grid_shape,\n",
        "        'signal_shape': self.hp.signal_shape,\n",
        "        'pixels': self.pixels,\n",
        "        'precision': self.precision\n",
        "    }\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class CompositeSignalGridHP:\n",
        "  def __init__(self, hps:List[SignalGridHP]):\n",
        "    if len(hps) == 0:\n",
        "      raise NoComponentsError(\"Must specify at least one component\")\n",
        "\n",
        "    self.components = hps\n",
        "    self.grid_shape = hps[0].grid_shape\n",
        "\n",
        "    # all components must have same grid size\n",
        "    for component_hp in hps:\n",
        "      if component_hp.grid_shape != hps[0].grid_shape:\n",
        "        raise GridShapeMismatchError\n",
        "\n",
        "class CompositeSignalGrid:\n",
        "  @staticmethod\n",
        "  def from_tensors(signals:List[torch.Tensor], variance:float=0.0):\n",
        "    signal_hps = [SignalGridHP(grid_shape=(1,1), signal_shape=signal.shape, init_variance=variance) for signal in signals]\n",
        "    hp = CompositeSignalGridHP(hps=signal_hps)\n",
        "    result = CompositeSignalGrid(hp=hp, alloc=False)\n",
        "    for index, component in enumerate(result.components):\n",
        "      component.pixels = signals[index]\n",
        "    return result\n",
        "\n",
        "  def from_signal_grids(signal_grids:List[SignalGrid]):\n",
        "    result = CompositeSignalGrid(hp=None)\n",
        "    hp = CompositeSignalGridHP(hps=[sg.hp for sg in signal_grids])\n",
        "    result.hp = hp\n",
        "    result.components = signal_grids\n",
        "    return result\n",
        "\n",
        "  def __init__(self, hp:CompositeSignalGridHP=None, alloc=True):\n",
        "    self.hp = hp\n",
        "    if hp:\n",
        "      self.components = [SignalGrid(component_hp, alloc_pixels=alloc) for component_hp in hp.components]\n",
        "\n",
        "  # add a SignalGrid as a component  \n",
        "  def add_component(self, o:SignalGrid):\n",
        "    assert self.hp.grid_shape == o.hp.grid_shape, f\"{self.hp.grid_shape} != {o.hp.grid_shape}\"\n",
        "\n",
        "    self.hp.components.append(o.hp)\n",
        "    self.components.append(o)\n",
        "\n",
        "  @property\n",
        "  def signal_shape(self):\n",
        "    return [c.hp.signal_shape for c in self.components]\n",
        "\n",
        "  @property\n",
        "  def grid_shape(self):\n",
        "    return self.hp.grid_shape\n",
        "\n",
        "  @property\n",
        "  def component_count(self):\n",
        "    return len(self.components)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class PatternGridHP:\n",
        "  def __init__(self, grid_shape, pattern_composite_signal_shape:Tuple):\n",
        "    self.grid_shape = grid_shape\n",
        "    self.grid_size = np.prod(self.grid_shape)\n",
        "\n",
        "    self.composite_signal_grid_hp =  CompositeSignalGridHP(hps=[SignalGridHP(grid_shape=grid_shape, signal_shape=signal_shape) for signal_shape in pattern_composite_signal_shape])\n",
        "\n",
        "class PatternGrid:\n",
        "  def __init__(self, hp:PatternGridHP):\n",
        "    self.hp = hp\n",
        "    self.composite_signal_grid = CompositeSignalGrid(hp.composite_signal_grid_hp)\n",
        "    self.alpha = torch.ones((hp.grid_size,)).to(device)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return pretty_s(\"\", self)\n",
        "\n",
        "class PatternSimilarityHP:\n",
        "  def __init__(self, enable_precision_weighted_distance=True):\n",
        "    self.enable_precision_weighted_distance = enable_precision_weighted_distance\n",
        "\n",
        "class PatternSimilarity:\n",
        "  def __init__(self, signal:CompositeSignalGrid, patterns:CompositeSignalGrid, hp:PatternSimilarityHP=None):\n",
        "    \"\"\"\n",
        "    signal must be        grid_shape=(grid_shape)                               signal_shape=(composite_signal_shapes)\n",
        "    patterns must be      grid_shape=(grid_shape, per_item_pattern_grid_shape)  signal_shape=(composite_signal_shapes)\n",
        "\n",
        "    Each signal is compared with corresponding per_x_pattern_grid_shape patterns.\n",
        "    Each comparison is done across composite signal components\n",
        "    \"\"\"\n",
        "    if hp:\n",
        "      self.hp = hp\n",
        "    else:\n",
        "      self.hp = PatternSimilarityHP()\n",
        "\n",
        "    assert signal.component_count == patterns.component_count, f\"signal.component_count {signal.component_count} != patterns.component_count {patterns.component_count}\"\n",
        "    assert signal.signal_shape == patterns.signal_shape, f\"signal.signal_shape {signal.signal_shape} != patterns.signal_shape {patterns.signal_shape}\"\n",
        "    assert patterns.grid_shape[0:len(signal.grid_shape)] == signal.grid_shape, f\"patterns.grid_shape {patterns.grid_shape} must match 0-n dimensions with signal.grid_shape {signal.grid_shape}\"\n",
        "    per_item_pattern_grid_shape = patterns.grid_shape[len(signal.grid_shape):]\n",
        "    per_item_pattern_grid_size = np.prod(per_item_pattern_grid_shape)\n",
        "\n",
        "    self.dist_1 = []\n",
        "    self.dist_d = []\n",
        "    self.dist = []\n",
        "    self.sim_components = []\n",
        "\n",
        "    # find similarity based on each signal component\n",
        "    for component_index in range(signal.component_count):\n",
        "      x_component = signal.components[component_index]\n",
        "      y_component = patterns.components[component_index]\n",
        "\n",
        "      xs = x_component.pixels.shape\n",
        "      x_component_pixels_expanded = x_component.pixels \\\n",
        "                                    .unsqueeze(dim=1) \\\n",
        "                                    .expand((xs[0], per_item_pattern_grid_size, xs[1])) \\\n",
        "                                    .reshape(-1, xs[1]) # expensive to reshape. How to vectorize better?\n",
        "      assert x_component_pixels_expanded.shape == y_component.pixels.shape\n",
        "      x_component_precision_expanded = x_component.precision \\\n",
        "                                    .unsqueeze(dim=1) \\\n",
        "                                    .expand((xs[0], per_item_pattern_grid_size, xs[1])) \\\n",
        "                                    .reshape(-1, xs[1]) # expensive to reshape. How to vectorize better?\n",
        "      assert x_component_precision_expanded.shape == y_component.precision.shape\n",
        "\n",
        "      dist_1_component, dist_d_component, dist_component = self.l2_distance(\n",
        "          x=x_component_pixels_expanded,\n",
        "          x_precision=x_component_precision_expanded,\n",
        "          y=y_component.pixels,\n",
        "          y_precision=y_component.precision)\n",
        "      \n",
        "      sim_component = torch.exp(-dist_component)\n",
        "\n",
        "      self.dist_1.append(dist_1_component)\n",
        "      self.dist_d.append(dist_d_component)\n",
        "      self.dist.append(dist_component)\n",
        "      self.sim_components.append(sim_component)\n",
        "\n",
        "    # final similarity is mean of signal component similarities\n",
        "    # this equalizes class weights for all components (e.g. modalities)\n",
        "    self.sim = torch.stack(self.sim_components).mean(dim=0)\n",
        "\n",
        "  def l2_cross_distance(self, x, x_precision, y, y_precision):\n",
        "    xs = x.shape\n",
        "    assert len(xs) == 2\n",
        "    assert (x_precision is None) or (x_precision.shape == xs), \"Precision, if specified, must be same shape as patterns\"\n",
        "\n",
        "    ys = y.shape\n",
        "    assert len(ys) == 2\n",
        "    assert (y_precision is None) or (y_precision.shape == ys), \"Precision, if specified, must be same shape as patterns\"\n",
        "\n",
        "    assert xs[1] == ys[1], \"Patch size, i.e. dim 1, must match\"\n",
        "\n",
        "    n = xs[0]\n",
        "    m = ys[0]\n",
        "    d = xs[1]\n",
        "\n",
        "    x = x.unsqueeze(1).expand(n, m, d)\n",
        "    x_precision = x_precision.unsqueeze(1).expand(n, m, d)\n",
        "\n",
        "    y = y.unsqueeze(0).expand(n, m, d)\n",
        "    y_precision = y_precision.unsqueeze(0).expand(n, m, d)\n",
        "\n",
        "    return self.l2_distance(x, x_precision, y, y_precision)\n",
        "\n",
        "  def l2_distance(self, x, x_precision, y, y_precision):\n",
        "    dist_1 = (x - y).abs()\n",
        "    dist_d = torch.pow(dist_1, 2)\n",
        "\n",
        "    if self.hp.enable_precision_weighted_distance:\n",
        "      if x_precision is not None:\n",
        "        dist_d = dist_d * x_precision\n",
        "\n",
        "      if y_precision is not None:\n",
        "        dist_d = dist_d * y_precision\n",
        "\n",
        "    dist = dist_d.sum(-1).sqrt()\n",
        "    return dist_1, dist_d, dist\n"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting pattern.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ7AetD9sXXx"
      },
      "source": [
        "%aimport pattern"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFBqB6E_8Xrm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c7b9f6-513d-4902-8c98-83d0c1514909"
      },
      "source": [
        "%%writefile convoluation_utils.py\n",
        "import math\n",
        "from pattern import *\n",
        "from typing import List, Tuple\n",
        "import numpy as np\n",
        "import pdb\n",
        "\n",
        "class ConvolutionUtils:\n",
        "  @staticmethod\n",
        "  def make_afferent_patches(signal:CompositeSignalGrid, grid_shape:Tuple, coverage_factor:float=1.0):\n",
        "    # print(\"make_afferent_patches\")\n",
        "    # print(\"  signal\", signal.signal_shape)\n",
        "    # print(\"  grid_shape\", grid_shape)\n",
        "    # print(\"  coverage_factor\", coverage_factor)\n",
        "\n",
        "    assert signal.grid_shape == (1,1)\n",
        "\n",
        "    if grid_shape == (1,1):\n",
        "      # no convoluation\n",
        "      return signal\n",
        "\n",
        "    for grid_shape_i in grid_shape:\n",
        "      assert grid_shape_i > 1\n",
        "\n",
        "    patch_signal_grids = []\n",
        "\n",
        "    for component_index in range(len(signal.components)):\n",
        "      # print(\"  component\", component_index)\n",
        "      component = signal.components[component_index]\n",
        "\n",
        "      patch_shape = tuple([int(coverage_factor *  component.signal_shape[i] / grid_shape[i]) for i in range(len(grid_shape))])\n",
        "      # print(\"    patch_shape\", patch_shape)\n",
        "      stride = tuple([math.floor((component.signal_shape[i]-patch_shape[i])/(grid_shape[i]-1)) for i in range(len(grid_shape))])\n",
        "      # print(\"    stride\", stride)\n",
        "\n",
        "      patches = ConvolutionUtils.conv_slice(component.pixels.view((1,) + component.hp.signal_shape), patch_shape, stride=stride).squeeze(dim=0)\n",
        "      sghp = SignalGridHP(grid_shape=grid_shape, signal_shape=patch_shape)\n",
        "      patch_signal_grid = SignalGrid(hp=sghp, alloc_pixels=False, pixels = patches)\n",
        "               \n",
        "      # print(\"  patch_signal_grid\", patch_signal_grid)\n",
        "      patch_signal_grids.append(patch_signal_grid)\n",
        "\n",
        "    patches = CompositeSignalGrid.from_signal_grids(patch_signal_grids)\n",
        "    return patches\n",
        "\n",
        "  @staticmethod\n",
        "  def conv_slice(images, kernel_shape, stride, padding=0):\n",
        "    assert len(images.shape) == 3, \"Must be (image count, image height, image width)\"\n",
        "    images = images.unsqueeze(1)\n",
        "\n",
        "    fold_params = dict(kernel_size=kernel_shape, dilation=1, padding=padding, stride=stride)\n",
        "    unfold = torch.nn.Unfold(**fold_params)\n",
        "    # print(\"images\", images.shape)\n",
        "    unfolded = unfold(images)\n",
        "    unfolded = unfolded.view(images.shape[0], -1, unfolded.shape[-1])\n",
        "    unfolded = unfolded.transpose(1, 2)\n",
        "    return unfolded"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting convoluation_utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1ptRk9z86rb"
      },
      "source": [
        "%aimport convoluation_utils"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnMru_ABTjKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556f11ad-3c47-40ed-acea-0cc3cceb4d9d"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test SignalGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "import pdb\n",
        "from pattern import *\n",
        "\n",
        "def test_signal_grid_invalid_grid_size1():\n",
        "  with pytest.raises(ValueError):\n",
        "    SignalGridHP(\n",
        "      grid_shape=(0,4),     # <-- zero\n",
        "      signal_shape=(5,6,2)\n",
        "    )\n",
        "\n",
        "def test_signal_grid_invalid_grid_size2():\n",
        "  with pytest.raises(ValueError):\n",
        "    SignalGridHP(\n",
        "      grid_shape=(1,4),\n",
        "      signal_shape=(5,-1,2) # <-- negative\n",
        "    )\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid_hp1():\n",
        "  return SignalGridHP(\n",
        "      grid_shape=(3,4),\n",
        "      signal_shape=(5,6,2))\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid1(signal_grid_hp1):\n",
        "  return SignalGrid(hp=signal_grid_hp1)\n",
        "\n",
        "def test_create_signal_grid(signal_grid_hp1):\n",
        "  signal_grid = SignalGrid(hp=signal_grid_hp1)\n",
        "  assert signal_grid.pixels.shape == (3*4, 5*6*2)\n",
        "  assert signal_grid.variance.shape == signal_grid.pixels.shape\n",
        "  assert signal_grid.precision.shape == signal_grid.pixels.shape\n",
        "\n",
        "@pytest.fixture\n",
        "def signal_grid_hp_degenerate():\n",
        "  return SignalGridHP(\n",
        "      grid_shape=(1,1),\n",
        "      signal_shape=(1,1))\n",
        "\n",
        "def test_create_signal_grid_degenerate(signal_grid_hp_degenerate):\n",
        "  signal_grid = SignalGrid(hp=signal_grid_hp_degenerate)\n",
        "  assert signal_grid.pixels.shape == (1, 1)\n",
        "  assert signal_grid.variance.shape == signal_grid.pixels.shape\n",
        "  assert signal_grid.precision.shape == signal_grid.pixels.shape\n",
        "\n",
        "def test_composite_signal_grid_from_tensors():\n",
        "  csg = CompositeSignalGrid.from_tensors([torch.ones((10,10)), torch.ones((5,5))])\n",
        "  assert csg.grid_shape == (1,1)\n",
        "  assert len(csg.components) == 2\n",
        "\n",
        "  c0 = csg.components[0]\n",
        "  assert c0.hp.grid_shape == (1,1)\n",
        "  assert c0.signal_shape == (10,10)\n",
        "\n",
        "  c1 = csg.components[1]\n",
        "  assert c1.hp.grid_shape == (1,1)\n",
        "  assert c1.signal_shape == (5,5)\n",
        "\n",
        "def test_composite_signal_grid_from_signal_grids_error1():\n",
        "  grid_shape0 = (3,4)\n",
        "  signal_shape0 = (5,3,2)\n",
        "  grid_shape1 = (1,2)\n",
        "  signal_shape1 = (12,)\n",
        "\n",
        "  sgs = [\n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape0, signal_shape=signal_shape0)), \n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape1, signal_shape=signal_shape1))\n",
        "  ]\n",
        "  with pytest.raises(GridShapeMismatchError):\n",
        "    CompositeSignalGrid.from_signal_grids(sgs)\n",
        "\n",
        "def test_composite_signal_grid_from_signal_grids():\n",
        "  grid_shape = (3,4)\n",
        "  signal_shape0 = (5,3,2)\n",
        "  signal_shape1 = (12,)\n",
        "\n",
        "  sgs = [\n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape, signal_shape=signal_shape0)), \n",
        "         SignalGrid(hp=SignalGridHP(grid_shape=grid_shape, signal_shape=signal_shape1))\n",
        "  ]\n",
        "  csg = CompositeSignalGrid.from_signal_grids(sgs)\n",
        "  \n",
        "  assert csg.hp.grid_shape == grid_shape\n",
        "  assert len(csg.components) == 2\n",
        "\n",
        "  c0 = csg.components[0]\n",
        "  assert c0.hp.grid_shape == grid_shape\n",
        "  assert c0.signal_shape == signal_shape0\n",
        "\n",
        "  c1 = csg.components[1]\n",
        "  assert c1.hp.grid_shape == grid_shape\n",
        "  assert c1.signal_shape == signal_shape1\n"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".......                                                                  [100%]\n",
            "7 passed in 0.05s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBqW9IrAqxHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752222fa-bbd0-44ea-ace6-b30db182403f"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test CompositeSignalGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "\n",
        "def test_csg_zero_components():\n",
        "  \"\"\"\n",
        "  Must have at least 1 component\n",
        "  \"\"\"\n",
        "  with pytest.raises(NoComponentsError):\n",
        "    CompositeSignalGridHP([])\n",
        "\n",
        "def test_csg_different_grid_shapes():\n",
        "  \"\"\"\n",
        "  Components may not have different grid shapes\n",
        "  \"\"\"\n",
        "  with pytest.raises(GridShapeMismatchError):\n",
        "    CompositeSignalGridHP([\n",
        "      SignalGridHP(grid_shape=(1,2), signal_shape=(3,4)),\n",
        "      SignalGridHP(grid_shape=(2,2), signal_shape=(3,4))\n",
        "    ])\n",
        "\n",
        "@pytest.fixture\n",
        "def composite_signal_grid1():\n",
        "  return CompositeSignalGrid(CompositeSignalGridHP([\n",
        "    SignalGridHP(grid_shape=(1,2), signal_shape=(3,4)),\n",
        "    SignalGridHP(grid_shape=(1,2), signal_shape=(3,2,1))\n",
        "  ]))\n",
        "\n",
        "def test_csg_different_signal_shapes(composite_signal_grid1):\n",
        "  \"\"\"\n",
        "  Components may have different signal shapes\n",
        "  \"\"\"\n",
        "  assert composite_signal_grid1.component_count == 2\n",
        "  assert composite_signal_grid1.components[0].signal_shape == (3,4)\n",
        "  assert composite_signal_grid1.components[1].signal_shape == (3,2,1)\n",
        "  assert composite_signal_grid1.signal_shape == [(3,4), (3,2,1)]"
      ],
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...                                                                      [100%]\n",
            "3 passed in 0.02s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4lPXN94vHcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8f1696-effd-4ba4-9e35-5ed0ed0254c9"
      },
      "source": [
        "%%run_pytest[clean]\n",
        "\"\"\"\n",
        "Test PatternGrid\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "\n",
        "@pytest.fixture\n",
        "def pg1():\n",
        "  pg_hp = PatternGridHP(grid_shape=(1,2), pattern_composite_signal_shape=[(3,4),(3,2,1)])\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_pg_create(pg1):\n",
        "  pg1.alpha.shape == (1,2)\n",
        "\n",
        "@pytest.fixture\n",
        "def pg2():\n",
        "  pg_hp = PatternGridHP(grid_shape=(1,), pattern_composite_signal_shape=[(1,),(1,)])\n",
        "\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_pg_create_2(pg2):\n",
        "  pg2.alpha.shape == (1,)\n"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..                                                                       [100%]\n",
            "2 passed in 0.02s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcQ4WOe3WpLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c6d4f4-63c3-4df3-9522-9a428aa94c38"
      },
      "source": [
        "%%run_pytest[clean] -s\n",
        "\"\"\"\n",
        "Test Similarity\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from pattern import *\n",
        "from utils import *\n",
        "\n",
        "def make_signal():\n",
        "  pg_hp = PatternGridHP(grid_shape=(2,4), pattern_composite_signal_shape=[(3,4),(3,2,1)])\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def make_patterns():\n",
        "  pg_hp = PatternGridHP(grid_shape=(2,4,3,2), pattern_composite_signal_shape=[(3,4),(3,2,1)])\n",
        "  return PatternGrid(hp=pg_hp)\n",
        "\n",
        "def test_sim_low_precision():\n",
        "  # By default, very low precision, so equal even when pixels are random\n",
        "  pgs = [make_signal(), make_patterns()]\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid)\n",
        "  assert sim.sim.shape == pgs[1].hp.grid_size\n",
        "  assert torch.allclose(sim.sim, torch.ones_like(sim.sim))\n",
        "\n",
        "def test_sim_disable_precision_weighting():\n",
        "  # If disabled precision weighting, then unequal because pixels are random\n",
        "  pgs = [make_signal(), make_patterns()]\n",
        "  hp = PatternSimilarityHP(enable_precision_weighted_distance=False)\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid, hp=hp)\n",
        "  assert sim.sim.shape == pgs[1].hp.grid_size\n",
        "  assert not torch.allclose(sim.sim, torch.ones_like(sim.sim))\n",
        "\n",
        "def test_sim_high_precision():\n",
        "  # If high precision, then unequal given pixels are random\n",
        "  pgs = [make_signal(), make_patterns()]\n",
        "\n",
        "  # force high precisions\n",
        "  for pg in pgs:\n",
        "    for component in pg.composite_signal_grid.components:\n",
        "      component.precision = torch.ones_like(component.precision)\n",
        "\n",
        "  sim = PatternSimilarity(pgs[0].composite_signal_grid, pgs[1].composite_signal_grid)\n",
        "  assert sim.sim.shape == pgs[1].hp.grid_size\n",
        "  assert not torch.allclose(sim.sim, torch.ones_like(sim.sim))"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...\n",
            "3 passed in 0.03s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvisc3G4cvFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901e2c42-e537-484b-d144-57424ea9bfee"
      },
      "source": [
        "%%writefile layer.py\n",
        "\n",
        "import torch\n",
        "import numpy\n",
        "import pdb\n",
        "from typing import List, Tuple\n",
        "from pattern import *\n",
        "import math\n",
        "from utils import *\n",
        "from convoluation_utils import ConvolutionUtils\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CompositeSignalPatchGrid:\n",
        "  def __init__(self, signal:CompositeSignalGrid, grid_shape:Tuple, coverage_factor=1.0):\n",
        "    # signal, i.e. composite image, must be a single composite signal, i.e. its grid shape must be (1,)\n",
        "    assert signal.hp.grid_shape == (1,1), f\"{signal.hp.grid_shape} != (1,1)\"\n",
        "    self.patches:CompositeSignalGrid = ConvolutionUtils.make_afferent_patches(signal=signal, grid_shape=grid_shape, coverage_factor=coverage_factor)\n",
        "\n",
        "class NeighborhoodPatchGrid:\n",
        "  def __init__(self, signal:SignalGrid, patch_grid_shape:Tuple, per_patch_grid_shape:Tuple, patch_neighborhood_shape:Tuple):\n",
        "    # signal must be a single signal, i.e. its grid shape must be (1,)\n",
        "    assert signal.hp.grid_shape == (1,1), f\"{signal.hp.grid_shape} != (1,1)\"\n",
        "\n",
        "    # signal shape must be flattend combination of patch_grid_shape and per_patch_grid_shape\n",
        "    assert tuple(signal.hp.signal_shape) == tuple(np.multiply(patch_grid_shape, per_patch_grid_shape))\n",
        "\n",
        "    stride = per_patch_grid_shape\n",
        "    # print(\"  stride\", stride)\n",
        "\n",
        "    padding_patches = tuple([int((i-1)/2) for i in patch_neighborhood_shape])\n",
        "    padding = tuple(np.multiply(padding_patches, per_patch_grid_shape))\n",
        "    # print(\"  padding\", padding)\n",
        "\n",
        "    patch_shape = tuple(np.multiply(patch_neighborhood_shape, per_patch_grid_shape))\n",
        "    patches = ConvolutionUtils.conv_slice(signal.pixels.view(signal.signal_shape).unsqueeze(dim=0), patch_shape, stride=stride, padding=padding).squeeze(dim=0)\n",
        "    sghp = SignalGridHP(grid_shape=patch_grid_shape, signal_shape=patch_shape)\n",
        "    self.patches:SignalGrid = SignalGrid(hp=sghp, alloc_pixels=False, pixels = patches)\n",
        "\n",
        "class InputOutputPatchGrid:\n",
        "  def __init__(self, patch_grid_shape:Tuple, input:CompositeSignalGrid, output:SignalGrid, output_patch_neighborhood_shape:Tuple, per_patch_pattern_grid_shape:Tuple, input_coverage_factor=1.0):\n",
        "    input_grid_shape = output.signal_shape\n",
        "\n",
        "    self.input_patches = CompositeSignalPatchGrid(signal=input, grid_shape=patch_grid_shape, coverage_factor=input_coverage_factor)\n",
        "    self.output_patches = NeighborhoodPatchGrid(signal=output, patch_grid_shape=patch_grid_shape, per_patch_grid_shape=per_patch_pattern_grid_shape, patch_neighborhood_shape=output_patch_neighborhood_shape)\n",
        "    \n",
        "    self.patches = self.input_patches.patches\n",
        "    self.patches.add_component(self.output_patches.patches)\n",
        "\n",
        "class LayerHP:\n",
        "  def __init__(self, input_signal_shapes:List[Tuple], input_coverage_factor:float, patch_grid_shape:Tuple, per_patch_pattern_grid_shape:Tuple, output_patch_neighborhood_shape:Tuple, output_tau=0.5):\n",
        "    assert len(patch_grid_shape) == len(per_patch_pattern_grid_shape), \"This is so that output can be flattened\"\n",
        "    assert len(patch_grid_shape) == len(output_patch_neighborhood_shape), \"Output patch neighborhood is a subset of patch grid, so number of dimensions must match\"\n",
        "    # assert len(patch_grid_shape) == 2, \"Currently support for 2D\"\n",
        "\n",
        "    self.input_signal_shapes:List[Tuple] = input_signal_shapes\n",
        "    self.input_coverage_factor:float = input_coverage_factor\n",
        "    self.patch_grid_shape:Tuple = patch_grid_shape\n",
        "    self.per_patch_pattern_grid_shape:Tuple = per_patch_pattern_grid_shape\n",
        "    self.output_patch_neighborhood_shape = output_patch_neighborhood_shape\n",
        "    self.output_neighborhood_shape:Tuple = np.multiply(output_patch_neighborhood_shape, per_patch_pattern_grid_shape)\n",
        "    self.output_tau:float = output_tau\n",
        "\n",
        "    for size in self.output_patch_neighborhood_shape:\n",
        "      assert size % 2 == 1, \"Output patch neighborhood shape must be odd, so can be centered around specific output activation\"\n",
        "\n",
        "    # Get input patch shapes\n",
        "    sample_input_signal = [torch.ones(shape) for shape in input_signal_shapes]\n",
        "    sample_input = CompositeSignalGrid.from_tensors(sample_input_signal)\n",
        "    patches = ConvolutionUtils.make_afferent_patches(signal=sample_input, grid_shape=patch_grid_shape, coverage_factor=input_coverage_factor)\n",
        "\n",
        "    # Patterns -\n",
        "    # each patch in the patch grid will get per_patch_pattern_grid_shape patterns, so patterns will be of shape -\n",
        "    # (patch_grid_shape,) + (per_patch_pattern_grid_shape shape,) + (pattern_composite_signal_shape,)\n",
        "    pattern_composite_signal_shape = patches.signal_shape + [self.output_neighborhood_shape] # input signals + output signal\n",
        "    patch_grid_shape = patch_grid_shape\n",
        "    pattern_grid_shape = patch_grid_shape + per_patch_pattern_grid_shape # 2D, 2D = 4D\n",
        "    self.pattern_grid_hp:PatternGridHP = PatternGridHP(grid_shape=pattern_grid_shape, pattern_composite_signal_shape=pattern_composite_signal_shape)\n",
        "\n",
        "    # Output is flattened 2D version of the 4D pattern_grid_shape\n",
        "    output_shape = np.multiply(patch_grid_shape, per_patch_pattern_grid_shape) # height1*height2, width1*width2\n",
        "    self.output_hp:SignalGridHP = SignalGridHP(grid_shape=(1,1), signal_shape=output_shape, init_pixel_scale=0.0)\n",
        "\n",
        "    # print(\"Output shape\", output_shape)\n",
        "\n",
        "    # # input grid HP\n",
        "    # hps = [\n",
        "    #   SignalGridHP(\n",
        "    #       grid_shape=output_shape, # Each grid element in input grid produces 1 pixel of output\n",
        "    #       signal_shape=input_component.signal_shape)\n",
        "    #   for input_component in patches.components # each component of input\n",
        "    # ]\n",
        "    # self.input_grid_hp = CompositeSignalGridHP(hps=hps.copy())\n",
        "\n",
        "    # # pattern HP\n",
        "    # hps.append(SignalGridHP(\n",
        "    #     grid_shape=output_shape,\n",
        "    #     signal_shape=output_neighborhood_shape))\n",
        "\n",
        "    # self.pattern_grid_hp = PatternGridHP(\n",
        "    #     grid_shape=pattern_grid_shape,\n",
        "    #     composite_signal_grid_hp=CompositeSignalGridHP(hps=[\n",
        "    #       SignalGridHP(grid_shape=pattern_grid_shape, signal_shape=component.signal_shape)\n",
        "    #      for component in hps]))\n",
        "\n",
        "class Layer:\n",
        "  def __init__(self, hp:LayerHP):\n",
        "    self.hp = hp\n",
        "    self.patterns = PatternGrid(hp=self.hp.pattern_grid_hp)\n",
        "    self.output = SignalGrid(hp.output_hp)\n",
        "\n",
        "  def forward(self, input:CompositeSignalGrid):\n",
        "    assert input.grid_shape == (1,1) # single signal input\n",
        "\n",
        "    input_output_patch_grid = InputOutputPatchGrid(patch_grid_shape=self.hp.patch_grid_shape,\n",
        "                                                   input=input,\n",
        "                                                   output=self.output,\n",
        "                                                   output_patch_neighborhood_shape=self.hp.output_patch_neighborhood_shape,\n",
        "                                                   per_patch_pattern_grid_shape=self.hp.per_patch_pattern_grid_shape,\n",
        "                                                   input_coverage_factor=1.0)\n",
        "    # patches = LayerUtils.make_input_output_composite_patches(input=input, output=self.output, output_shape=self.hp.output_shape, output_neighborhood_shape=self.hp.output_neighborhood_shape, convolve_input=self.hp.convolve_input)\n",
        "    # print(\"input_output_patch_grid.patches\", input_output_patch_grid.patches)\n",
        "    pattern_similarity = PatternSimilarity(signal=input_output_patch_grid.patches, patterns=self.patterns.composite_signal_grid)\n",
        "    \n",
        "    activation = pattern_similarity.sim.unsqueeze(dim=0)\n",
        "    assert self.output.pixels.shape == activation.shape \n",
        "\n",
        "    self.output.pixels = soft_add(self.output.pixels, activation, tau=self.hp.output_tau)\n",
        "\n"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting layer.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozYdg-Q-q_aU"
      },
      "source": [
        "%aimport layer"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzMn4q-FrA9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eabf67-e3e5-4b43-f64a-d9760d7bfd36"
      },
      "source": [
        "\n",
        "%%run_pytest[clean] -s\n",
        "\"\"\"\n",
        "Test Layer\n",
        "\"\"\"\n",
        "\n",
        "import pytest\n",
        "from utils import *\n",
        "from pattern import *\n",
        "from layer import *\n",
        "import pdb\n",
        "\n",
        "def test_layer_create():\n",
        "  hp = LayerHP(\n",
        "      input_signal_shapes=[(10,15),(20,10)],\n",
        "      input_coverage_factor=1.0, \n",
        "      patch_grid_shape=(5,5),\n",
        "      per_patch_pattern_grid_shape=(4,4),\n",
        "      output_patch_neighborhood_shape=(3,3),\n",
        "      output_tau=0.5)\n",
        "  layer = Layer(hp=hp)\n",
        "  # pretty_print(\"Layer\", layer)\n",
        "  assert(True)\n",
        "\n",
        "def test_layer_forward():\n",
        "\n",
        "\n",
        "  input_signal_shapes = [(10,10), (20,20)]\n",
        "  input_signals = [torch.ones(shape) for shape in input_signal_shapes]\n",
        "  input = CompositeSignalGrid.from_tensors(input_signals)\n",
        "\n",
        "  hp = LayerHP(\n",
        "      input_signal_shapes=input_signal_shapes,\n",
        "      input_coverage_factor=1.0, \n",
        "      patch_grid_shape=(5,5),\n",
        "      per_patch_pattern_grid_shape=(2,3),\n",
        "      output_patch_neighborhood_shape=(3,3),\n",
        "      output_tau=0.5)\n",
        "\n",
        "  layer = Layer(hp=hp)\n",
        "  #pretty_print(\"Layer\", layer)\n",
        "\n",
        "  for _ in range(10):\n",
        "    layer.forward(input)\n",
        "\n",
        "  assert torch.allclose(layer.output.pixels, torch.ones_like(layer.output.pixels), atol=0.01)"
      ],
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "..\n",
            "2 passed in 0.03s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGs1sDJ4BaU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d1b3a4-61e6-48d6-addc-7f3b458a42a0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.datasets import load_boston\n",
        "from utils import *\n",
        "from layer import *\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def normalize(df):\n",
        "  df1 = (df - df.mean())/df.std()\n",
        "  return df1\n",
        "\n",
        "def scale(df):\n",
        "  min = df.min()\n",
        "  max = df.max()\n",
        "\n",
        "  df1 = (df - min) / (max - min)\n",
        "  return df1\n",
        "\n",
        "dataset = load_boston()\n",
        "dataset = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
        "dataset = pd.DataFrame(np.c_[scale(normalize(dataset['LSTAT'])), scale(normalize(dataset['RM']))], columns = ['LSTAT','RM'])\n",
        "dataset = torch.tensor(dataset.to_numpy()).float().to(device)\n",
        "dataset\n",
        "X = dataset[:,0]\n",
        "Y = dataset[:,1]\n",
        "\n",
        "input_signal_shapes = [(1,1)]\n",
        "hp = LayerHP(\n",
        "      input_signal_shapes=input_signal_shapes,\n",
        "      input_coverage_factor=1.0, \n",
        "      patch_grid_shape=(1,1),\n",
        "      per_patch_pattern_grid_shape=(3,3),\n",
        "      output_patch_neighborhood_shape=(1,1),\n",
        "      output_tau=1.0) # set output_tau=1.0 for IID data\n",
        "\n",
        "layer = Layer(hp=hp)\n",
        "\n",
        "print(\"Patterns - input\", layer.patterns.composite_signal_grid.components[0].pixels)\n",
        "print(\"Patterns - output\", layer.patterns.composite_signal_grid.components[1].pixels)\n",
        "\n",
        "for i in range(4):\n",
        "  input = CompositeSignalGrid.from_tensors([X[i].view(1,1)])\n",
        "  input.components[0].variance *= 0\n",
        "  input.components[0].refresh_precision()\n",
        "\n",
        "  print(\"input\", input.components[0].pixels)\n",
        "  print(\"input precision\", input.components[0].precision)\n",
        "  layer.forward(input)\n",
        "  print(\"layer output\", layer.output.pixels.view(layer.hp.per_patch_pattern_grid_shape))\n"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patterns - input tensor([[0.0568],\n",
            "        [0.0924],\n",
            "        [0.0050],\n",
            "        [0.0421],\n",
            "        [0.0626],\n",
            "        [0.0544],\n",
            "        [0.0305],\n",
            "        [0.0190],\n",
            "        [0.0041]])\n",
            "Patterns - output tensor([[0.0551, 0.0436, 0.0352, 0.0922, 0.0324, 0.0941, 0.0655, 0.0490, 0.0027],\n",
            "        [0.0535, 0.0140, 0.0247, 0.0504, 0.0445, 0.0132, 0.0997, 0.0914, 0.0151],\n",
            "        [0.0665, 0.0057, 0.0794, 0.0664, 0.0135, 0.0837, 0.0761, 0.0268, 0.0602],\n",
            "        [0.0207, 0.0104, 0.0917, 0.0187, 0.0495, 0.0341, 0.0995, 0.0287, 0.0372],\n",
            "        [0.0425, 0.0891, 0.0590, 0.0542, 0.0410, 0.0714, 0.0523, 0.0034, 0.0196],\n",
            "        [0.0617, 0.0197, 0.0477, 0.0752, 0.0346, 0.0600, 0.0478, 0.0420, 0.0594],\n",
            "        [0.0103, 0.0025, 0.0477, 0.0020, 0.0194, 0.0233, 0.0774, 0.0024, 0.0316],\n",
            "        [0.0258, 0.0003, 0.0343, 0.0699, 0.0032, 0.0932, 0.0136, 0.0096, 0.0352],\n",
            "        [0.0802, 0.0898, 0.0496, 0.0359, 0.0917, 0.0596, 0.0006, 0.0602, 0.0656]])\n",
            "input tensor([[0.0897]])\n",
            "input precision tensor([[1.]])\n",
            "layer output tensor([[0.9999, 1.0000, 0.9997],\n",
            "        [0.9998, 0.9999, 0.9999],\n",
            "        [0.9998, 0.9998, 0.9997]])\n",
            "input tensor([[0.2045]])\n",
            "input precision tensor([[1.]])\n",
            "layer output tensor([[0.9994, 0.9996, 0.9993],\n",
            "        [0.9994, 0.9995, 0.9994],\n",
            "        [0.9993, 0.9993, 0.9993]])\n",
            "input tensor([[0.0635]])\n",
            "input precision tensor([[1.]])\n",
            "layer output tensor([[0.9999, 0.9998, 0.9997],\n",
            "        [0.9999, 0.9999, 0.9999],\n",
            "        [0.9998, 0.9998, 0.9997]])\n",
            "input tensor([[0.0334]])\n",
            "input precision tensor([[1.]])\n",
            "layer output tensor([[0.9999, 0.9997, 0.9998],\n",
            "        [0.9999, 0.9998, 0.9999],\n",
            "        [0.9999, 0.9999, 0.9998]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_VoWZ-OfsGr"
      },
      "source": [
        "CompositeSignalGrid.from_tensors([X[0].unsqueeze(dim=0)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXW2KE0yPV4j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa4LHN3uHaoX"
      },
      "source": [
        "We have patch grid of composite signal. Each composite signal gets its own grid of patterns."
      ]
    }
  ]
}