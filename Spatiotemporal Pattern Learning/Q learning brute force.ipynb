{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ i _\n",
      "_ z z\n",
      "_ _ c\n",
      "\n",
      "_ i _\n",
      "_ z z\n",
      "_ c _\n",
      "\n",
      "0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "BOARD_WIDTH = 3\n",
    "BOARD_HEIGHT = 3\n",
    "\n",
    "ZOMBIE = 'z'\n",
    "ICECREAM = 'i'\n",
    "EMPTY = '_'\n",
    "CAR = 'c'\n",
    "\n",
    "UP = 0\n",
    "DOWN = 1\n",
    "LEFT = 2\n",
    "RIGHT = 3\n",
    "ACTIONS = [UP, DOWN, LEFT, RIGHT]\n",
    "\n",
    "class State:\n",
    "    def __init__(self, state = None, car_pos = None):\n",
    "        if state is None:\n",
    "            self.state = self.initial_state()\n",
    "        else:\n",
    "            self.state = state\n",
    "\n",
    "        assert len(self.state) == BOARD_HEIGHT\n",
    "        assert len(self.state[0]) == BOARD_WIDTH\n",
    "\n",
    "        if car_pos is None:\n",
    "            self.car_pos = [2, 2]\n",
    "        else:\n",
    "            self.car_pos = car_pos\n",
    "\n",
    "        self.state[self.car_pos[0]][self.car_pos[1]] = CAR\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([' '.join(s) for s in self.state])\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, State) and self.state == other.state and self.car_pos == other.car_pos\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(str(self.state) + str(self.car_pos))\n",
    "        \n",
    "    def initial_state(self):\n",
    "        return [\n",
    "            [EMPTY,  ICECREAM, EMPTY ],\n",
    "            [EMPTY,  ZOMBIE,   ZOMBIE],\n",
    "            [EMPTY,  EMPTY,    EMPTY ],\n",
    "        ]\n",
    "\n",
    "def act(state, action):\n",
    "    new_car_pos = deepcopy(state.car_pos)\n",
    "\n",
    "    if action == UP:\n",
    "        new_car_pos[0] = max(new_car_pos[0] - 1, 0)\n",
    "    elif action == DOWN:\n",
    "        new_car_pos[0] = min(new_car_pos[0] + 1, BOARD_HEIGHT - 1)\n",
    "    elif action == LEFT:\n",
    "        new_car_pos[1] = max(new_car_pos[1] - 1, 0)\n",
    "    elif action == RIGHT:\n",
    "        new_car_pos[1] = min(new_car_pos[1] + 1, BOARD_WIDTH - 1)\n",
    "    else:\n",
    "        raise Exception(f\"Unknown action {action}\")\n",
    "\n",
    "    item = state.state[new_car_pos[0]][new_car_pos[1]]\n",
    "    \n",
    "    if item == ZOMBIE:\n",
    "        finished = True\n",
    "        reward = -100\n",
    "    elif item == ICECREAM:\n",
    "        finished = True\n",
    "        reward = 1000\n",
    "    elif item == CAR:\n",
    "        finished = False\n",
    "        reward = -1\n",
    "    elif item == EMPTY:\n",
    "        finished = False\n",
    "        reward = 0\n",
    "    else:\n",
    "        raise Exception(f\"Unknown item {item}\")\n",
    "\n",
    "    new_state = deepcopy(state.state)\n",
    "    new_state[state.car_pos[0]][state.car_pos[1]] = EMPTY\n",
    "    \n",
    "    return (State(new_state, new_car_pos), reward, finished)\n",
    "\n",
    "\n",
    "s = State()\n",
    "print(s)\n",
    "print()\n",
    "(s, reward, finished) = act(s, LEFT)\n",
    "print(s)\n",
    "print()\n",
    "print(reward)\n",
    "print(finished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42) # for reproducibility\n",
    "\n",
    "N_STATES = BOARD_WIDTH * BOARD_HEIGHT\n",
    "N_EPISODES = 100\n",
    "\n",
    "MAX_EPISODE_STEPS = 20\n",
    "\n",
    "MIN_ALPHA = 0.02\n",
    "\n",
    "alphas = np.linspace(1.0, MIN_ALPHA, N_EPISODES)\n",
    "gamma = 1.0\n",
    "eps = 0.2\n",
    "\n",
    "q_table = dict()\n",
    "\n",
    "def q(state, action=None):\n",
    "    if state not in q_table:\n",
    "        q_table[state] = np.zeros(len(ACTIONS))\n",
    "\n",
    "    if action is None:\n",
    "        return q_table[state]\n",
    "    else:\n",
    "        return q_table[state][action]\n",
    "    \n",
    "def select_action(state):\n",
    "    if random.uniform(0, 1) < eps:\n",
    "        return random.choice(ACTIONS)\n",
    "    else:\n",
    "        return np.argmax(q(state))\n",
    "\n",
    "for episode in range(N_EPISODES):\n",
    "    alpha = alphas[episode]\n",
    "\n",
    "    state = State()\n",
    "    total_reward = 0\n",
    "    \n",
    "    for step in range(MAX_EPISODE_STEPS):\n",
    "        action = select_action(state)\n",
    "        (next_state, reward, finished) = act(state, action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        q(state)[action] = q(state, action) + \\\n",
    "                alpha * (reward + gamma * np.max(q(next_state)) - q(state, action))\n",
    "        state = next_state\n",
    "        \n",
    "        if finished:\n",
    "            break;\n",
    "            \n",
    "        state = next_state\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{_ i _\n",
       " _ z z\n",
       " _ _ c: array([-100.        ,  985.06682263, 1000.        ,  997.24436367]),\n",
       " _ i _\n",
       " _ z c\n",
       " _ _ _: array([0., 0., 0., 0.]),\n",
       " _ i _\n",
       " _ z z\n",
       " _ c _: array([ -99.99319012,  930.28312257, 1000.        ,  804.0024769 ]),\n",
       " _ i _\n",
       " _ c z\n",
       " _ _ _: array([0., 0., 0., 0.]),\n",
       " _ i _\n",
       " _ z z\n",
       " c _ _: array([1000.        ,  995.49240845,  734.69157025,  564.19748783]),\n",
       " _ i _\n",
       " c z z\n",
       " _ _ _: array([1000.        ,  451.25599429,  995.84493831,  -99.99490517]),\n",
       " c i _\n",
       " _ z z\n",
       " _ _ _: array([ 989.26600403,  952.06598488,  987.87413408, 1000.        ]),\n",
       " _ c _\n",
       " _ z z\n",
       " _ _ _: array([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ i _\n",
      "_ z z\n",
      "_ _ c\n",
      "\n",
      "_ i _\n",
      "_ z z\n",
      "_ c _\n",
      "\n",
      "_ i _\n",
      "_ z z\n",
      "c _ _\n",
      "\n",
      "_ i _\n",
      "c z z\n",
      "_ _ _\n",
      "\n",
      "c i _\n",
      "_ z z\n",
      "_ _ _\n",
      "\n",
      "_ c _\n",
      "_ z z\n",
      "_ _ _\n"
     ]
    }
   ],
   "source": [
    "state = State()\n",
    "finished = False\n",
    "\n",
    "while not finished:\n",
    "    print(state)\n",
    "    print('')\n",
    "    action = np.argmax(q_table[state])\n",
    "    (state, reward, finished) = act(state, action)\n",
    "    \n",
    "print(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
