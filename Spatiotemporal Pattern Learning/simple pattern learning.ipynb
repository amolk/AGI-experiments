{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 4\n",
      "1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA\n",
      "\n",
      "Train...\n",
      "Epoch 0\n",
      "[0.42280588 0.39942846 0.5162581  0.5425595 ]\n",
      "[0.42820886 0.4082968  0.53545856 0.5490054 ]\n",
      "[0.43102825 0.41355804 0.54747415 0.55258894]\n",
      "[0.43242717 0.4168458  0.555225   0.5544641 ]\n",
      "[0.425959   0.4000515  0.52349854 0.5477318 ]\n",
      "[0.4257907  0.40410972 0.54003847 0.5529325 ]\n",
      "[0.42883432 0.41009712 0.55042315 0.5552099 ]\n",
      "[0.43047953 0.41397747 0.55720615 0.5562902 ]\n",
      "[0.43143383 0.41672286 0.56177336 0.55665094]\n",
      "[0.4320142  0.41878125 0.5649444  0.55660814]\n",
      "[0.4275025  0.40290517 0.53307176 0.55105364]\n",
      "[0.42551526 0.40493217 0.54560673 0.55440897]\n",
      "[0.42838275 0.41063428 0.55417424 0.5558825 ]\n",
      "[0.42359778 0.39577606 0.52295774 0.5492631 ]\n",
      "[0.42365983 0.40072373 0.53982234 0.554063  ]\n",
      "[0.42716038 0.4074757  0.5503247  0.55611455]\n",
      "[0.42914093 0.4119059  0.5571759  0.5570319 ]\n",
      "[0.42442244 0.39683723 0.5255548  0.550424  ]\n",
      "[0.4238982  0.40105304 0.5412493  0.55474216]\n",
      "[0.41916078 0.3878787  0.51137555 0.547037  ]\n",
      "ABABA1AABBAAB => BBBABBBBBABBABBBABAB\n",
      "accuracy training = 0.6378504633903503\n",
      "loss training = 0.6653459072113037\n",
      "___________________________________\n",
      "Epoch 1\n",
      "[0.28879833 0.2520604  0.45608345 0.5315929 ]\n",
      "[0.2950312  0.2615281  0.47872478 0.5387404 ]\n",
      "[0.30022663 0.2691138  0.4947959  0.54345065]\n",
      "[0.30403608 0.27489766 0.50612766 0.5463125 ]\n",
      "[0.30687833 0.2794498  0.5141767  0.5478867 ]\n",
      "[0.30906737 0.2831736  0.52002156 0.5486146 ]\n",
      "[0.31081507 0.28632778 0.52438766 0.5488051 ]\n",
      "[0.31225938 0.28907448 0.5277506  0.5486656 ]\n",
      "[0.31348965 0.29151556 0.53042024 0.5483315 ]\n",
      "[0.31456366 0.29371566 0.53259915 0.54789084]\n",
      "[0.3155191  0.29571688 0.534421   0.54739964]\n",
      "[0.31638077 0.29754764 0.5359752  0.5468931 ]\n",
      "[0.31716543 0.299228   0.5373225  0.5463931 ]\n",
      "[0.31788447 0.3007729  0.5385049  0.5459124 ]\n",
      "[0.3185461  0.30219415 0.53955233 0.54545826]\n",
      "[0.31915623 0.3035017  0.54048663 0.54503417]\n",
      "[0.3058456  0.27551827 0.48642674 0.5351701 ]\n",
      "[0.30342636 0.2774728  0.50621957 0.54120904]\n",
      "[0.3070507  0.28299072 0.51550925 0.5434797 ]\n",
      "[0.30995655 0.2874828  0.5221795  0.5447767 ]\n",
      "ABABA1AABBAAB => BBBBBBBBBBBBBBBABBBB\n",
      "accuracy training = 0.7453271150588989\n",
      "loss training = 0.5682957172393799\n",
      "___________________________________\n",
      "Epoch 2\n",
      "[0.1856672  0.15290919 0.3932369  0.5035715 ]\n",
      "[0.19105113 0.16020206 0.40874502 0.50760317]\n",
      "[0.19726329 0.1676982  0.42250398 0.51155037]\n",
      "[0.20311211 0.17466271 0.43453455 0.5149821 ]\n",
      "[0.2083915  0.18094037 0.44475454 0.5177857 ]\n",
      "[0.21306743 0.18654412 0.45336327 0.5199883 ]\n",
      "[0.21718061 0.19154514 0.46061257 0.52166355]\n",
      "[0.22079965 0.1960297  0.4667479  0.52290016]\n",
      "[0.2239975  0.20007955 0.47198424 0.5237848 ]\n",
      "[0.22684166 0.2037651  0.4764995  0.5243942 ]\n",
      "[0.22939003 0.207144   0.48043603 0.5247922 ]\n",
      "[0.2316908  0.21026248 0.48390588 0.5250306 ]\n",
      "[0.23378313 0.213157   0.48699614 0.52515024]\n",
      "[0.23569871 0.21585628 0.48977435 0.5251828 ]\n",
      "[0.23746277 0.21838313 0.4922928  0.5251525 ]\n",
      "[0.2390956  0.22075564 0.49459207 0.52507794]\n",
      "[0.24061349 0.22298826 0.49670386 0.52497286]\n",
      "[0.24202956 0.22509311 0.49865323 0.5248476 ]\n",
      "[0.24335448 0.22707996 0.50045997 0.52470994]\n",
      "[0.24459709 0.22895727 0.5021401  0.5245655 ]\n",
      "ABABA1AABBAAB => BBBBBBBBBBBBBBBBBBBB\n",
      "accuracy training = 0.7149532437324524\n",
      "loss training = 0.4922291040420532\n",
      "___________________________________\n",
      "Epoch 3\n",
      "[0.1385428  0.11586485 0.38743532 0.48689383]\n",
      "[0.14310709 0.12215576 0.3994681  0.4887815 ]\n",
      "[0.14838707 0.12871602 0.41070056 0.49115068]\n",
      "[0.15369299 0.13516192 0.42116708 0.4935381 ]\n",
      "[0.15883169 0.14132372 0.43067443 0.49578044]\n",
      "[0.16370766 0.14713895 0.4392341  0.49780408]\n",
      "[0.16828397 0.15259951 0.4469126  0.49957418]\n",
      "[0.17255782 0.15772498 0.4538021  0.5010858 ]\n",
      "[0.17654407 0.16254622 0.46000212 0.50235313]\n",
      "[0.18026607 0.16709687 0.46560884 0.5034008 ]\n",
      "[0.18374965 0.17140862 0.47070864 0.50425786]\n",
      "[0.18702014 0.17550942 0.47537667 0.50495344]\n",
      "[0.19010086 0.17942275 0.47967604 0.50551504]\n",
      "[0.19301225 0.18316783 0.4836589  0.50596684]\n",
      "[0.19577195 0.18676013 0.4873678  0.5063297 ]\n",
      "[0.19839479 0.19021183 0.4908372  0.5066211 ]\n",
      "[0.20089318 0.19353259 0.49409497 0.5068555 ]\n",
      "[0.20327741 0.19673002 0.4971635  0.5070445 ]\n",
      "[0.20555595 0.19980995 0.5000611  0.5071976 ]\n",
      "[0.17737913 0.15911102 0.42893276 0.4909131 ]\n",
      "ABABA1AABBAAB => BBBBBBBBBBBBBBBBBBAB\n",
      "accuracy training = 0.7266355156898499\n",
      "loss training = 0.4645251929759979\n",
      "___________________________________\n",
      "Epoch 4\n",
      "[0.11566244 0.10130381 0.40184823 0.47679266]\n",
      "[0.12092387 0.10871795 0.4147409  0.47786295]\n",
      "[0.1267835  0.11645734 0.42703512 0.4795728 ]\n",
      "[0.1327675  0.12421001 0.43856615 0.48144162]\n",
      "[0.13872625 0.13181838 0.44920814 0.4833447 ]\n",
      "[0.14457409 0.13921437 0.45898917 0.48519826]\n",
      "[0.15026611 0.14637752 0.4679675  0.4869377 ]\n",
      "[0.15578164 0.1533119  0.47621623 0.48852298]\n",
      "[0.13504834 0.12127594 0.40999535 0.4752886 ]\n",
      "[0.13673496 0.12800533 0.44296658 0.48307878]\n",
      "[0.14214998 0.13542892 0.4536309  0.48451602]\n",
      "[0.14804143 0.14308366 0.46342942 0.4861312 ]\n",
      "[0.15379032 0.1504996  0.47241467 0.48766804]\n",
      "[0.15933938 0.15763465 0.48062843 0.4890816 ]\n",
      "[0.16468608 0.16450685 0.48816517 0.49035844]\n",
      "[0.16983663 0.1711395  0.49510947 0.49149576]\n",
      "[0.14520733 0.1337315  0.42574254 0.4772746 ]\n",
      "[0.14582005 0.13949288 0.45662954 0.48448747]\n",
      "[0.1511058  0.14688708 0.46672723 0.48587424]\n",
      "[0.1569339  0.15457587 0.4759449  0.4873737 ]\n",
      "ABABA1AABBAAB => BBBBBBBABBBBBBBABBBB\n",
      "accuracy training = 0.7546728849411011\n",
      "loss training = 0.45362648367881775\n",
      "___________________________________\n",
      "Epoch 5\n",
      "[0.10339443 0.09601723 0.4217512  0.4693191 ]\n",
      "[0.11018746 0.10608685 0.43795073 0.46976513]\n",
      "[0.11776915 0.11688812 0.4535536  0.47098652]\n",
      "[0.12563418 0.1279285  0.46804318 0.47247753]\n",
      "[0.11154635 0.10229851 0.40739593 0.46496922]\n",
      "[0.11482586 0.11205019 0.44710895 0.47154605]\n",
      "[0.12208612 0.12260964 0.46178526 0.47248977]\n",
      "[0.13004364 0.13369152 0.47557303 0.4740177 ]\n",
      "[0.11453696 0.10607132 0.41302645 0.46570593]\n",
      "[0.11757965 0.11561408 0.45197904 0.472224  ]\n",
      "[0.12491134 0.1262777  0.46645048 0.47323206]\n",
      "[0.13294917 0.13746484 0.47998568 0.47476912]\n",
      "[0.11656927 0.10863    0.41650856 0.46604145]\n",
      "[0.11946352 0.1180652  0.45503992 0.47251725]\n",
      "[0.12684959 0.12882635 0.46943164 0.47356075]\n",
      "[0.13495335 0.14011554 0.48285037 0.47510317]\n",
      "[0.11801354 0.11047535 0.41886836 0.46616948]\n",
      "[0.12080981 0.11984715 0.45713753 0.47262394]\n",
      "[0.12823884 0.13068897 0.4714939  0.47369462]\n",
      "[0.11314348 0.10407446 0.41004816 0.46547267]\n",
      "ABABA1AABBAAB => BBBABBBABBBABBBABBAB\n",
      "accuracy training = 0.75\n",
      "loss training = 0.4475474953651428\n",
      "___________________________________\n",
      "Epoch 6\n",
      "[0.09892505 0.09917511 0.4477508  0.46257323]\n",
      "[0.10866282 0.1147239  0.47028288 0.4623279 ]\n",
      "[0.09857343 0.09289145 0.4127395  0.4590495 ]\n",
      "[0.10337541 0.10649098 0.46022442 0.46313   ]\n",
      "[0.1135035  0.12249049 0.48137698 0.46310556]\n",
      "[0.10226024 0.09825423 0.42130545 0.4593313 ]\n",
      "[0.10679214 0.11163191 0.4674185  0.46349487]\n",
      "[0.1170186  0.12777698 0.48790866 0.46364063]\n",
      "[0.10492394 0.10200033 0.42668873 0.45949426]\n",
      "[0.109289   0.11526037 0.4719956  0.46371305]\n",
      "[0.09829019 0.09259541 0.41344723 0.4596047 ]\n",
      "[0.10304067 0.10603468 0.4604821  0.46360746]\n",
      "[0.11317941 0.1219586  0.48143774 0.46359843]\n",
      "[0.10189079 0.09775282 0.42113277 0.459642  ]\n",
      "[0.10643795 0.11109079 0.46716192 0.463785  ]\n",
      "[0.09614295 0.08969594 0.40952945 0.4597879 ]\n",
      "[0.10100323 0.10310514 0.45689696 0.46371803]\n",
      "[0.09214815 0.08431572 0.4016858  0.46000794]\n",
      "[0.09723726 0.09768167 0.44970518 0.4637902 ]\n",
      "[0.1070373  0.11292955 0.47098967 0.4635216 ]\n",
      "ABABA1AABBAAB => BABBABBABABBABABABBB\n",
      "accuracy training = 0.75\n",
      "loss training = 0.44304946064949036\n",
      "___________________________________\n",
      "Epoch 7\n",
      "[0.09775589 0.10636244 0.47351018 0.45555162]\n",
      "[0.08921808 0.08577632 0.4159367  0.45524904]\n",
      "[0.09517895 0.10324748 0.47206923 0.4559962 ]\n",
      "[0.08737179 0.08356427 0.41415048 0.45576233]\n",
      "[0.09337191 0.10077381 0.47000068 0.45641375]\n",
      "[0.10656124 0.12324651 0.49913058 0.45481008]\n",
      "[0.09776073 0.09931924 0.43819904 0.45479903]\n",
      "[0.10335251 0.11687811 0.49044028 0.45576286]\n",
      "[0.09399573 0.09349669 0.42983824 0.45524982]\n",
      "[0.09967089 0.11092698 0.48341712 0.456044  ]\n",
      "[0.09094717 0.08901326 0.4234408  0.45560834]\n",
      "[0.09675612 0.1063232  0.4779021  0.45632365]\n",
      "[0.0885814  0.08561046 0.41855085 0.45595387]\n",
      "[0.09445971 0.10274115 0.47353017 0.45659485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08673203 0.08298995 0.4147549  0.4562708 ]\n",
      "[0.09264392 0.09993163 0.47003993 0.456844  ]\n",
      "[0.08527734 0.08095062 0.41177702 0.4565502 ]\n",
      "[0.09120397 0.09771588 0.46724275 0.45706394]\n",
      "[0.08412819 0.07935224 0.40942553 0.45679006]\n",
      "[0.09005972 0.09596194 0.4649972  0.45725304]\n",
      "ABABA1AABBAAB => ABABBABABABABABABABA\n",
      "accuracy training = 0.75\n",
      "loss training = 0.439412921667099\n",
      "___________________________________\n",
      "Epoch 8\n",
      "[0.09941653 0.11802431 0.49991608 0.44777223]\n",
      "[0.09121526 0.09426983 0.4388718  0.4509119 ]\n",
      "[0.09824883 0.11734154 0.50187886 0.44781372]\n",
      "[0.09067785 0.09402269 0.44019607 0.45112568]\n",
      "[0.09771203 0.11692058 0.5025577  0.44798526]\n",
      "[0.09026922 0.09365388 0.44051465 0.45133042]\n",
      "[0.09724046 0.11636438 0.5025504  0.44814196]\n",
      "[0.08985832 0.09315258 0.4402741  0.45150408]\n",
      "[0.09678167 0.11571771 0.50218815 0.44828174]\n",
      "[0.08944161 0.09258055 0.43974283 0.45165464]\n",
      "[0.09633291 0.11503129 0.50164586 0.44840786]\n",
      "[0.08902869 0.09198284 0.4390698  0.45178843]\n",
      "[0.0958988  0.11433945 0.5010198  0.44852304]\n",
      "[0.08862789 0.09138732 0.4383381  0.4519094 ]\n",
      "[0.0954837  0.11366298 0.5003634  0.4486291 ]\n",
      "[0.08824462 0.09081001 0.43759447 0.45202014]\n",
      "[0.09509018 0.11301361 0.49970722 0.4487274 ]\n",
      "[0.08788177 0.09025943 0.4368646  0.45212236]\n",
      "[0.09471946 0.11239737 0.49906796 0.44881877]\n",
      "[0.08754052 0.08973971 0.43616247 0.4522171 ]\n",
      "ABABA1AABBAAB => ABABABABABABABABABAB\n",
      "accuracy training = 0.75\n",
      "loss training = 0.43590694665908813\n",
      "___________________________________\n",
      "Epoch 9\n",
      "[0.10482363 0.13707247 0.5294201  0.43835095]\n",
      "[0.09880116 0.11262959 0.47146872 0.44498882]\n",
      "[0.08033822 0.08043492 0.4234104  0.45189694]\n",
      "[0.08625163 0.10465682 0.4974074  0.4427681 ]\n",
      "[0.08022898 0.08236764 0.4311383  0.45040724]\n",
      "[0.08825755 0.10932963 0.50553274 0.44215366]\n",
      "[0.08273721 0.08679955 0.43942076 0.44982556]\n",
      "[0.09084551 0.11440232 0.51231587 0.44159186]\n",
      "[0.08541354 0.09138494 0.4470006  0.44915777]\n",
      "[0.09350246 0.11946706 0.5182928  0.44093156]\n",
      "[0.08818096 0.09612572 0.4542089  0.44838908]\n",
      "[0.07205719 0.06881698 0.40732157 0.45524207]\n",
      "[0.07747225 0.0898967  0.48008144 0.44582826]\n",
      "[0.07199205 0.07004386 0.41222546 0.45365602]\n",
      "[0.07930411 0.09368655 0.4870163  0.44524807]\n",
      "[0.07402354 0.07328042 0.4186226  0.45313048]\n",
      "[0.08150053 0.09774559 0.4931151  0.4447488 ]\n",
      "[0.07610433 0.07656469 0.4246084  0.4525678 ]\n",
      "[0.08366551 0.10171913 0.49859703 0.44418806]\n",
      "[0.07818791 0.07988454 0.4303253  0.45194516]\n",
      "ABABA1AABBAAB => AABABABABAABABABABAB\n",
      "accuracy training = 0.7476635575294495\n",
      "loss training = 0.4323902428150177\n",
      "___________________________________\n",
      "Epoch 10\n",
      "[0.10061411 0.13937525 0.53960764 0.4293227 ]\n",
      "[0.09667931 0.11527873 0.48091576 0.44019732]\n",
      "[0.07639609 0.07755657 0.42259282 0.45091015]\n",
      "[0.08145398 0.10346033 0.50359064 0.4359659 ]\n",
      "[0.07567137 0.07897726 0.4305709  0.44881782]\n",
      "[0.08347557 0.10865432 0.5129085  0.4348391 ]\n",
      "[0.07861783 0.08438362 0.4410262  0.44762993]\n",
      "[0.0867482  0.11545888 0.52189916 0.43366665]\n",
      "[0.08234981 0.09105212 0.45222932 0.4461474 ]\n",
      "[0.06512748 0.06115695 0.39653885 0.4568649 ]\n",
      "[0.0689569  0.08085679 0.47342515 0.4419596 ]\n",
      "[0.06348178 0.06021957 0.3978425  0.45533186]\n",
      "[0.06945986 0.08244675 0.47796136 0.44157606]\n",
      "[0.06437964 0.06173147 0.4017465  0.45503005]\n",
      "[0.07059008 0.08468553 0.4822534  0.44126526]\n",
      "[0.06546441 0.0634392  0.4056033  0.45465508]\n",
      "[0.0718165  0.08705166 0.486348   0.44084316]\n",
      "[0.06663867 0.06528196 0.40949646 0.4541735 ]\n",
      "[0.07314232 0.08959616 0.49045518 0.44031966]\n",
      "[0.06793174 0.06732173 0.41359857 0.45359126]\n",
      "ABABA1AABBAAB => AABABABAABABABABABAB\n",
      "accuracy training = 0.764018714427948\n",
      "loss training = 0.42986300587654114\n",
      "___________________________________\n",
      "Epoch 11\n",
      "[0.05621815 0.0624387  0.4486543  0.44389185]\n",
      "[0.07268479 0.09678311 0.5150616  0.43124193]\n",
      "[0.0675065  0.07119188 0.42913768 0.44799626]\n",
      "[0.07326214 0.09671488 0.51110226 0.43132114]\n",
      "[0.06693619 0.07010716 0.42680553 0.44854337]\n",
      "[0.07251088 0.09515208 0.5090208  0.43191284]\n",
      "[0.06615541 0.06876718 0.4243255  0.44918698]\n",
      "[0.07168361 0.09344606 0.5067179  0.43255165]\n",
      "[0.06532544 0.06734859 0.42161927 0.44986466]\n",
      "[0.07080199 0.09162759 0.5041673  0.43322694]\n",
      "[0.06445093 0.06586383 0.4187137  0.45057622]\n",
      "[0.06986688 0.08970359 0.50137687 0.43394005]\n",
      "[0.06353533 0.06432294 0.41563198 0.45132223]\n",
      "[0.06888039 0.0876824  0.49835214 0.4346916 ]\n",
      "[0.06258306 0.0627366  0.41239518 0.4521018 ]\n",
      "[0.06784607 0.08557424 0.49509823 0.43548134]\n",
      "[0.0615995  0.06111636 0.4090246  0.45291308]\n",
      "[0.06676865 0.08339153 0.49162287 0.43630776]\n",
      "[0.0605909  0.0594746  0.40554377 0.4537529 ]\n",
      "[0.0656543  0.08114918 0.4879375  0.43716815]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7476635575294495\n",
      "loss training = 0.45294803380966187\n",
      "___________________________________\n",
      "Epoch 12\n",
      "[0.05551113 0.06290358 0.45967132 0.4450848 ]\n",
      "[0.05069811 0.04478323 0.3760362  0.46592984]\n",
      "[0.05521667 0.06266678 0.46103692 0.44559094]\n",
      "[0.0506294  0.04474869 0.37655413 0.46614665]\n",
      "[0.0552058  0.06267823 0.46140292 0.44574487]\n",
      "[0.05061307 0.04473975 0.37672982 0.46624836]\n",
      "[0.05519018 0.06265761 0.46149862 0.44583645]\n",
      "[0.05059247 0.04471563 0.3767609  0.46631777]\n",
      "[0.05516792 0.06261518 0.46146283 0.4459055 ]\n",
      "[0.0505669  0.04468105 0.37671936 0.4663737 ]\n",
      "[0.05514074 0.06255911 0.46135634 0.44596478]\n",
      "[0.05053764 0.04463967 0.37663797 0.4664236 ]\n",
      "[0.05511024 0.06249448 0.46120903 0.4460195 ]\n",
      "[0.05050582 0.04459394 0.37653312 0.4664704 ]\n",
      "[0.05507749 0.06242432 0.46103692 0.44607177]\n",
      "[0.05047229 0.04454535 0.37641397 0.46651563]\n",
      "[0.05504324 0.06235056 0.46084908 0.44612283]\n",
      "[0.0504376  0.04449493 0.3762857  0.4665599 ]\n",
      "[0.05500802 0.06227453 0.46065122 0.44617307]\n",
      "[0.0504022  0.04444337 0.3761518  0.46660355]\n",
      "ABABA1AABBAAB => ABABABABABABABABABAB\n",
      "accuracy training = 0.764018714427948\n",
      "loss training = 0.43073570728302\n",
      "___________________________________\n",
      "Epoch 13\n",
      "[0.04847696 0.04969905 0.42646545 0.45571437]\n",
      "[0.0624478  0.08003917 0.5050338  0.43636695]\n",
      "[0.05678953 0.05463863 0.40451685 0.46207094]\n",
      "[0.06222371 0.07854143 0.49903744 0.4373926 ]\n",
      "[0.05579882 0.05295841 0.4001689  0.4633688 ]\n",
      "[0.06093503 0.07582077 0.49406716 0.43883288]\n",
      "[0.05462753 0.05109842 0.3956595  0.46480808]\n",
      "[0.05955834 0.07296231 0.48867473 0.44037622]\n",
      "[0.05342174 0.04921649 0.39097443 0.4663062 ]\n",
      "[0.05813006 0.07002924 0.4828755  0.4420023 ]\n",
      "[0.05219933 0.04734306 0.38618973 0.467848  ]\n",
      "[0.05666858 0.06706604 0.47673553 0.44369718]\n",
      "[0.05097719 0.04550588 0.38138425 0.46941602]\n",
      "[0.05519538 0.06412071 0.47033906 0.44544193]\n",
      "[0.04977315 0.04373164 0.37663755 0.47098953]\n",
      "[0.05400332 0.06150919 0.46346995 0.44721916]\n",
      "[0.04865083 0.04209368 0.37206596 0.4725052 ]\n",
      "[0.05288401 0.05905132 0.45657828 0.4489734 ]\n",
      "[0.04759603 0.04058152 0.36774966 0.47395974]\n",
      "[0.05181315 0.05674187 0.44985402 0.4506763 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7593457698822021\n",
      "loss training = 0.4309217631816864\n",
      "___________________________________\n",
      "Epoch 14\n",
      "[0.05375489 0.06194317 0.4690023  0.4457789 ]\n",
      "[0.04871115 0.04218508 0.37559628 0.47478592]\n",
      "[0.05425851 0.0632223  0.47352868 0.4452328 ]\n",
      "[0.0492391  0.04302113 0.37846455 0.4740478 ]\n",
      "[0.05483555 0.0645974  0.4774859  0.4443003 ]\n",
      "[0.04981674 0.04390466 0.38114527 0.4732154 ]\n",
      "[0.05542647 0.06599666 0.48128065 0.44331372]\n",
      "[0.05041822 0.04482589 0.38381943 0.47233492]\n",
      "[0.05606236 0.06746683 0.48500457 0.44229478]\n",
      "[0.0510505  0.04579942 0.38656247 0.4714102 ]\n",
      "[0.05685861 0.06914102 0.48860016 0.44124866]\n",
      "[0.05173726 0.04685695 0.3894309  0.47042367]\n",
      "[0.05769723 0.07091293 0.49227667 0.44015908]\n",
      "[0.05246783 0.04799441 0.39246362 0.4693831 ]\n",
      "[0.05858133 0.07279497 0.4960663  0.43902382]\n",
      "[0.05324886 0.04922551 0.395694   0.4682817 ]\n",
      "[0.05951788 0.07480425 0.49999106 0.43783724]\n",
      "[0.05408854 0.0505665  0.3991559  0.46711126]\n",
      "[0.06051434 0.07695938 0.5040704  0.43659332]\n",
      "[0.05499616 0.05203634 0.40288585 0.46586245]\n",
      "ABABA1AABBAAB => ABABABABABABABABABAB\n",
      "accuracy training = 0.7616822719573975\n",
      "loss training = 0.42946621775627136\n",
      "___________________________________\n",
      "Epoch 15\n",
      "[0.04480398 0.04377909 0.41313484 0.46483162]\n",
      "[0.0578442  0.07346305 0.50267214 0.4372613 ]\n",
      "[0.0520485  0.04759337 0.39165208 0.47280198]\n",
      "[0.05715607 0.07136466 0.49638724 0.43888173]\n",
      "[0.05103084 0.04594613 0.3869677  0.47459853]\n",
      "[0.05586763 0.06855369 0.49048415 0.44091174]\n",
      "[0.04990377 0.04420669 0.38214824 0.47652414]\n",
      "[0.05479246 0.06593887 0.48380837 0.44308984]\n",
      "[0.04880304 0.04252087 0.37725124 0.47846898]\n",
      "[0.0536871  0.06329501 0.47676447 0.4453561 ]\n",
      "[0.04770776 0.04087756 0.37236688 0.4804368 ]\n",
      "[0.05256559 0.06066161 0.4694515  0.44769022]\n",
      "[0.04663214 0.03929795 0.36757246 0.48240244]\n",
      "[0.05144491 0.05808099 0.46198177 0.4500609 ]\n",
      "[0.04559071 0.03780108 0.36294022 0.484339  ]\n",
      "[0.05034306 0.05559422 0.45448157 0.45243222]\n",
      "[0.04459697 0.03640277 0.35853451 0.486219  ]\n",
      "[0.04927764 0.05323802 0.44708294 0.45476586]\n",
      "[0.06564036 0.09232715 0.53887004 0.42570266]\n",
      "[0.06015617 0.06152686 0.42731288 0.46029133]\n",
      "ABABA1AABBAAB => BABABABABABABABABBAB\n",
      "accuracy training = 0.7593457698822021\n",
      "loss training = 0.42919492721557617\n",
      "___________________________________\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0501008  0.05567765 0.4582932  0.4509814 ]\n",
      "[0.04465743 0.0363815  0.36120924 0.4883212 ]\n",
      "[0.05064261 0.05703592 0.46334708 0.4498882 ]\n",
      "[0.04518256 0.03717414 0.36412984 0.48719808]\n",
      "[0.05126785 0.05852711 0.46800512 0.4484121 ]\n",
      "[0.04576358 0.03802578 0.36696142 0.48599315]\n",
      "[0.05191018 0.06005938 0.4725661  0.4469005 ]\n",
      "[0.04637059 0.03892022 0.36983898 0.4847437 ]\n",
      "[0.05256766 0.061641   0.47712085 0.44536403]\n",
      "[0.04700381 0.03986328 0.37281373 0.48345158]\n",
      "[0.05324268 0.06328234 0.48171505 0.44380012]\n",
      "[0.04766683 0.04086328 0.37591946 0.48211178]\n",
      "[0.05393851 0.06499422 0.48637846 0.44220325]\n",
      "[0.04836445 0.04193    0.37918493 0.480717  ]\n",
      "[0.05465877 0.06678786 0.49113423 0.44056696]\n",
      "[0.04910223 0.04307464 0.3826386  0.4792588 ]\n",
      "[0.05540707 0.06867482 0.49600205 0.4388842 ]\n",
      "[0.04988642 0.04431002 0.38631046 0.4777276 ]\n",
      "[0.05618724 0.07066753 0.50099945 0.43714827]\n",
      "[0.05072407 0.04565099 0.39023295 0.4761128 ]\n",
      "ABABA1AABBAAB => ABABABABABABABABABAB\n",
      "accuracy training = 0.7757009267807007\n",
      "loss training = 0.4268876612186432\n",
      "___________________________________\n",
      "Epoch 17\n",
      "[0.04212804 0.0393316  0.39983457 0.47397465]\n",
      "[0.05509635 0.06927694 0.49906418 0.43742192]\n",
      "[0.04883232 0.04267401 0.3798174  0.4832916 ]\n",
      "[0.05422276 0.06701989 0.49293604 0.43943137]\n",
      "[0.0479046  0.041216   0.3752935  0.48540196]\n",
      "[0.05326881 0.06459899 0.48650724 0.44190606]\n",
      "[0.04694401 0.03974246 0.37065634 0.48759684]\n",
      "[0.05227371 0.06211097 0.47962046 0.44453216]\n",
      "[0.04597159 0.03827964 0.3659471  0.48985407]\n",
      "[0.05124506 0.05958475 0.47233525 0.44729155]\n",
      "[0.04499674 0.03684379 0.36122972 0.49215266]\n",
      "[0.05019395 0.05705389 0.46472827 0.45015994]\n",
      "[0.04403046 0.03545145 0.35656792 0.49446696]\n",
      "[0.04913406 0.0545547  0.45689547 0.4531051 ]\n",
      "[0.04308446 0.03411831 0.3520242  0.49676868]\n",
      "[0.04808056 0.05212412 0.4489507  0.45608798]\n",
      "[0.06445631 0.0945264  0.5523522  0.41705826]\n",
      "[0.05952116 0.06146907 0.43166658 0.4614224 ]\n",
      "[0.0656227  0.09526569 0.5476609  0.4173342 ]\n",
      "[0.05937501 0.06101412 0.42994624 0.4619937 ]\n",
      "ABABA1AABBAAB => BABABABABABABABBABAB\n",
      "accuracy training = 0.7827102541923523\n",
      "loss training = 0.42613112926483154\n",
      "___________________________________\n",
      "Epoch 18\n",
      "[0.04799454 0.0523281  0.45292747 0.45397902]\n",
      "[0.0653718  0.09943712 0.56573653 0.40862396]\n",
      "[0.06199246 0.06679042 0.4479284  0.45477182]\n",
      "[0.06886763 0.10613494 0.56879383 0.40518805]\n",
      "[0.06449014 0.07178633 0.4586354  0.4502496 ]\n",
      "[0.04691662 0.03862938 0.36493462 0.4913628 ]\n",
      "[0.05179152 0.06172771 0.4825907  0.4423187 ]\n",
      "[0.04610115 0.03832765 0.36893702 0.4908365 ]\n",
      "[0.05267506 0.06403548 0.48962796 0.43996274]\n",
      "[0.04700036 0.03972566 0.37364966 0.4885273 ]\n",
      "[0.05363916 0.0665632  0.49654892 0.43720087]\n",
      "[0.04798442 0.04127182 0.37865794 0.48607087]\n",
      "[0.05464599 0.06924957 0.5036015  0.43435538]\n",
      "[0.04904578 0.04297681 0.3840541  0.48346126]\n",
      "[0.05569855 0.07210994 0.5108043  0.43142444]\n",
      "[0.0501948  0.04486721 0.3898966  0.4806828 ]\n",
      "[0.05679935 0.07515791 0.518159   0.42840594]\n",
      "[0.05144263 0.04697317 0.39624178 0.477719  ]\n",
      "[0.0579496  0.07840386 0.5256534  0.42530015]\n",
      "[0.05280097 0.04932847 0.40314442 0.4745544 ]\n",
      "ABABA1AABBAAB => BABAABABABABABABABAB\n",
      "accuracy training = 0.7920560836791992\n",
      "loss training = 0.42585843801498413\n",
      "___________________________________\n",
      "Epoch 19\n",
      "[0.04060194 0.03674028 0.39063555 0.4815295 ]\n",
      "[0.05391683 0.06865354 0.50282556 0.43384776]\n",
      "[0.04775907 0.04079193 0.3741145  0.4907854 ]\n",
      "[0.05346818 0.06741653 0.49913794 0.43502825]\n",
      "[0.04726672 0.03999947 0.37147716 0.49219763]\n",
      "[0.05294329 0.06600083 0.49534816 0.43670815]\n",
      "[0.04671901 0.03913507 0.36858568 0.4937502 ]\n",
      "[0.05236365 0.06444645 0.4910655  0.4385906 ]\n",
      "[0.0461246  0.03820686 0.36542445 0.49545464]\n",
      "[0.05172397 0.06274867 0.4862566  0.4406924 ]\n",
      "[0.04548179 0.03721682 0.36200014 0.49731678]\n",
      "[0.05102097 0.06090688 0.4808871  0.4430301 ]\n",
      "[0.04479074 0.03616932 0.35832268 0.4993396 ]\n",
      "[0.05025299 0.05892501 0.47492754 0.44561717]\n",
      "[0.04405346 0.03507132 0.35440952 0.5015218 ]\n",
      "[0.04942048 0.05681269 0.46835944 0.44846272]\n",
      "[0.04327391 0.03393237 0.35028753 0.5038567 ]\n",
      "[0.04852631 0.05458646 0.46118185 0.4515681 ]\n",
      "[0.04250903 0.0328537  0.34645948 0.5061414 ]\n",
      "[0.04759258 0.05230693 0.45350495 0.45485082]\n",
      "ABABA1AABBAAB => BABABABABABABABABABB\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.4201165735721588\n",
      "___________________________________\n",
      "Epoch 20\n",
      "[0.04907445 0.05631169 0.47089446 0.4459279 ]\n",
      "[0.0438151  0.03434021 0.3546099  0.5033824 ]\n",
      "[0.05051294 0.06019628 0.48386797 0.44068822]\n",
      "[0.04524257 0.03653183 0.362807   0.49872813]\n",
      "[0.05214095 0.06463116 0.496914   0.43481657]\n",
      "[0.04689618 0.03913146 0.37196133 0.49358055]\n",
      "[0.05388886 0.0695433  0.51027596 0.42871612]\n",
      "[0.04877199 0.04220416 0.38232535 0.48791116]\n",
      "[0.05574746 0.07494856 0.5238725  0.42242485]\n",
      "[0.05089804 0.04585329 0.39408186 0.4816777 ]\n",
      "[0.05770259 0.08083551 0.53752977 0.41599986]\n",
      "[0.05330247 0.05019664 0.40736997 0.4748577 ]\n",
      "[0.06018389 0.08770376 0.5505123  0.4095788 ]\n",
      "[0.05606874 0.05541747 0.42219612 0.46742693]\n",
      "[0.063039   0.0953484  0.56266445 0.40325782]\n",
      "[0.05917509 0.06158791 0.4384316  0.4594999 ]\n",
      "[0.06598289 0.10331676 0.57389075 0.39716405]\n",
      "[0.06255232 0.06869881 0.45578182 0.45126584]\n",
      "[0.04556599 0.03605212 0.35606086 0.5011593 ]\n",
      "[0.05065448 0.0605817  0.4847059  0.43992302]\n",
      "ABABA1AABBAAB => ABABABABABABABABAABA\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.42750996351242065\n",
      "___________________________________\n",
      "Epoch 21\n",
      "[0.04919533 0.05736113 0.4771217  0.44190383]\n",
      "[0.04401029 0.03440876 0.35528216 0.5048509 ]\n",
      "[0.05084743 0.06197752 0.49221894 0.43533647]\n",
      "[0.04567811 0.03701835 0.36513358 0.4989804 ]\n",
      "[0.05270135 0.06724489 0.507319   0.42812607]\n",
      "[0.04761914 0.04016001 0.37627983 0.49246514]\n",
      "[0.05468045 0.07307789 0.52260834 0.4207098 ]\n",
      "[0.04983468 0.04393141 0.3890025  0.4852691 ]\n",
      "[0.05676333 0.07945888 0.537889   0.41316906]\n",
      "[0.05235424 0.04846922 0.4034832  0.47736406]\n",
      "[0.05900605 0.0864246  0.55276155 0.40562904]\n",
      "[0.05521221 0.05392892 0.41979083 0.46876135]\n",
      "[0.06200145 0.09465749 0.5661964  0.39831668]\n",
      "[0.05849409 0.06051145 0.43770602 0.4595267 ]\n",
      "[0.06509136 0.10323591 0.57843006 0.3913357 ]\n",
      "[0.06207051 0.06816327 0.45688167 0.44994292]\n",
      "[0.0451974  0.03525985 0.35359523 0.50449955]\n",
      "[0.05033671 0.06057689 0.4876602  0.43710092]\n",
      "[0.04514204 0.03618305 0.3621385  0.500816  ]\n",
      "[0.05212189 0.06560357 0.50284636 0.43031514]\n",
      "ABABA1AABBAAB => ABABABABABABABAABABA\n",
      "accuracy training = 0.8154205679893494\n",
      "loss training = 0.41939184069633484\n",
      "___________________________________\n",
      "Epoch 22\n",
      "[0.04086099 0.03799747 0.4020518  0.47987333]\n",
      "[0.05593335 0.07840936 0.5367259  0.41244343]\n",
      "[0.05052276 0.04525772 0.39084136 0.48582712]\n",
      "[0.05624007 0.07931577 0.5379274  0.4108861 ]\n",
      "[0.05094174 0.04602639 0.3934653  0.4844068 ]\n",
      "[0.0566016  0.08047704 0.54061604 0.40946624]\n",
      "[0.05139402 0.04686098 0.3962048  0.4828516 ]\n",
      "[0.05697973 0.08169167 0.543361   0.40800273]\n",
      "[0.05187312 0.04775194 0.39908367 0.48122323]\n",
      "[0.05737236 0.08295821 0.54616624 0.40649763]\n",
      "[0.05237878 0.04870206 0.402112   0.4795192 ]\n",
      "[0.0577786  0.0842763  0.54902977 0.40495208]\n",
      "[0.05291154 0.04971472 0.4052968  0.47773805]\n",
      "[0.05828065 0.08574746 0.5518582  0.40337905]\n",
      "[0.05348378 0.05080486 0.40863565 0.47587055]\n",
      "[0.05886859 0.08736109 0.5546546  0.40177912]\n",
      "[0.05409449 0.05197419 0.41213015 0.47391894]\n",
      "[0.0594785  0.08903826 0.55747855 0.40014806]\n",
      "[0.05473487 0.05321648 0.4157857  0.47189152]\n",
      "[0.06010766 0.09077438 0.56032354 0.39849102]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7967289686203003\n",
      "loss training = 0.4215022623538971\n",
      "___________________________________\n",
      "Epoch 23\n",
      "[0.04922723 0.05918027 0.4878744  0.43466598]\n",
      "[0.04412777 0.03428717 0.35417888 0.50971633]\n",
      "[0.05136455 0.06551591 0.50782835 0.42473534]\n",
      "[0.04634763 0.03786957 0.36798584 0.5006796 ]\n",
      "[0.05368624 0.07262593 0.52715486 0.41438472]\n",
      "[0.04893883 0.04229848 0.38392892 0.49063212]\n",
      "[0.05608806 0.08032843 0.5458181  0.4041534 ]\n",
      "[0.05188148 0.04769469 0.40206358 0.47967762]\n",
      "[0.05850666 0.08843786 0.563351   0.39427027]\n",
      "[0.05517487 0.05420847 0.42232633 0.4679411 ]\n",
      "[0.06173046 0.0978101  0.57837456 0.38509968]\n",
      "[0.05889628 0.06202708 0.44414747 0.4556535 ]\n",
      "[0.06500718 0.10729451 0.5911866  0.37677726]\n",
      "[0.0628502  0.07097495 0.46677563 0.4433202 ]\n",
      "[0.04534805 0.03506711 0.35164627 0.50975347]\n",
      "[0.05077647 0.06377705 0.5023671  0.4271676 ]\n",
      "[0.04570697 0.03682599 0.36413044 0.50322217]\n",
      "[0.05304343 0.0706505  0.5220863  0.4171578 ]\n",
      "[0.04820094 0.04101795 0.37948567 0.49342152]\n",
      "[0.05543415 0.07820924 0.54093194 0.40687656]\n",
      "ABABA1AABBAAB => ABABABABABABAABABABA\n",
      "accuracy training = 0.8200934529304504\n",
      "loss training = 0.41590747237205505\n",
      "___________________________________\n",
      "Epoch 24\n",
      "[0.03853438 0.03350985 0.38060626 0.49444702]\n",
      "[0.052958   0.07171712 0.52453405 0.41509306]\n",
      "[0.04712687 0.03913622 0.36807293 0.5027315 ]\n",
      "[0.05297692 0.07171698 0.5236925  0.41472492]\n",
      "[0.04716691 0.03920595 0.36838952 0.50259036]\n",
      "[0.05301557 0.07184976 0.5240669  0.41451854]\n",
      "[0.04721209 0.03928716 0.36871147 0.5023846 ]\n",
      "[0.0530589  0.0719912  0.5244475  0.41430342]\n",
      "[0.04726136 0.03937339 0.369042   0.5021701 ]\n",
      "[0.05310517 0.07213968 0.5248401  0.41408   ]\n",
      "[0.04731373 0.03946415 0.36938465 0.50194615]\n",
      "[0.05315392 0.07229511 0.52524716 0.41384724]\n",
      "[0.0473689  0.03955944 0.3697415  0.5017121 ]\n",
      "[0.05320507 0.07245768 0.5256703  0.41360462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04742679 0.03965937 0.37011403 0.50146735]\n",
      "[0.05325853 0.07262765 0.5261109  0.41335157]\n",
      "[0.04748751 0.03976419 0.37050354 0.50121135]\n",
      "[0.05331447 0.07280542 0.52656996 0.41308758]\n",
      "[0.04755113 0.03987416 0.3709111  0.50094366]\n",
      "[0.05337291 0.0729913  0.5270483  0.4128121 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.41912543773651123\n",
      "___________________________________\n",
      "Epoch 25\n",
      "[0.04890507 0.05992456 0.4948314  0.4282008 ]\n",
      "[0.04412126 0.03388958 0.3515973  0.51520574]\n",
      "[0.05129937 0.06740005 0.5180974  0.41523445]\n",
      "[0.04656613 0.03790316 0.36737195 0.5038224 ]\n",
      "[0.05386813 0.07579304 0.5406019  0.40212193]\n",
      "[0.0495738  0.04326789 0.38730627 0.4903065 ]\n",
      "[0.05652417 0.08492739 0.561906   0.3892525 ]\n",
      "[0.05307709 0.05009219 0.41064268 0.47526625]\n",
      "[0.059323   0.09466583 0.5811457  0.37710002]\n",
      "[0.05705427 0.05857097 0.43681902 0.45913818]\n",
      "[0.06293579 0.10563091 0.59686726 0.36620006]\n",
      "[0.06150325 0.06881808 0.46458468 0.44257748]\n",
      "[0.04430173 0.03294618 0.34159115 0.52057874]\n",
      "[0.04968737 0.06241392 0.5030649  0.42359245]\n",
      "[0.04490025 0.03516649 0.35688046 0.5114087 ]\n",
      "[0.05217129 0.07023517 0.52614033 0.4106223 ]\n",
      "[0.04754132 0.03960293 0.37389705 0.49933746]\n",
      "[0.05478563 0.07891386 0.5482659  0.39757153]\n",
      "[0.05073926 0.04547761 0.39514002 0.48519498]\n",
      "[0.05745137 0.08823431 0.56896496 0.384894  ]\n",
      "ABABA1AABBAAB => ABABABABABAABABABABA\n",
      "accuracy training = 0.8177570104598999\n",
      "loss training = 0.4130542576313019\n",
      "___________________________________\n",
      "Epoch 26\n",
      "[0.03620944 0.02896757 0.3549633  0.5136012 ]\n",
      "[0.04934718 0.06245871 0.50171095 0.42521235]\n",
      "[0.04348077 0.03282116 0.34121427 0.5255604 ]\n",
      "[0.04893847 0.06116169 0.49691042 0.42739034]\n",
      "[0.04308993 0.03221357 0.33868504 0.5275718 ]\n",
      "[0.04850193 0.05985139 0.49272573 0.42992416]\n",
      "[0.04268646 0.0316038  0.3361499  0.52958834]\n",
      "[0.04805576 0.05852288 0.48837692 0.43255347]\n",
      "[0.04228141 0.03099893 0.33361402 0.53162724]\n",
      "[0.04759916 0.05717764 0.4838654  0.4352761 ]\n",
      "[0.04187465 0.03039966 0.331085   0.53368473]\n",
      "[0.04713229 0.05581834 0.47919482 0.4380904 ]\n",
      "[0.04146663 0.02980701 0.32856983 0.5357564 ]\n",
      "[0.04665581 0.05444841 0.4743703  0.44099352]\n",
      "[0.04105809 0.02922224 0.3260755  0.5378377 ]\n",
      "[0.04617058 0.05307174 0.46939933 0.4439819 ]\n",
      "[0.04064995 0.02864666 0.32360932 0.53992337]\n",
      "[0.04567779 0.05169269 0.46429154 0.44705024]\n",
      "[0.0402432  0.02808163 0.32117856 0.5420079 ]\n",
      "[0.04517879 0.05031602 0.45905915 0.45019212]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7943925261497498\n",
      "loss training = 0.4202350080013275\n",
      "___________________________________\n",
      "Epoch 27\n",
      "[0.04572184 0.05204836 0.46983063 0.441275  ]\n",
      "[0.04155032 0.02929534 0.32835022 0.5377994 ]\n",
      "[0.04753551 0.05755017 0.49020228 0.42902592]\n",
      "[0.0432358  0.03184998 0.3395081  0.5284622 ]\n",
      "[0.04959505 0.06406139 0.5114897  0.41590536]\n",
      "[0.04529547 0.03516059 0.3533616  0.5173916 ]\n",
      "[0.05184747 0.07157678 0.53332007 0.4022821 ]\n",
      "[0.04778483 0.03947691 0.3705862  0.5043297 ]\n",
      "[0.05425173 0.08004642 0.55500466 0.38847384]\n",
      "[0.05081404 0.04522172 0.3921706  0.48886746]\n",
      "[0.05674646 0.08928878 0.57566035 0.3748667 ]\n",
      "[0.05441657 0.05274758 0.41814372 0.47121075]\n",
      "[0.05985728 0.09976659 0.59370655 0.36210003]\n",
      "[0.05858307 0.06224006 0.44716042 0.4522458 ]\n",
      "[0.04238408 0.02932802 0.32197434 0.54061806]\n",
      "[0.04676584 0.05523446 0.48192886 0.4339264 ]\n",
      "[0.04250673 0.0307428  0.334799   0.5323797 ]\n",
      "[0.04873925 0.06133484 0.5029197  0.42121205]\n",
      "[0.04441856 0.03373029 0.3474808  0.52203345]\n",
      "[0.05092362 0.06845368 0.5245909  0.40775976]\n",
      "ABABA1AABBAAB => ABABABABABABAABABABA\n",
      "accuracy training = 0.822429895401001\n",
      "loss training = 0.4088897407054901\n",
      "___________________________________\n",
      "Epoch 28\n",
      "[0.03517561 0.0266754  0.3393626  0.5275935 ]\n",
      "[0.04794193 0.05986411 0.49717116 0.42532477]\n",
      "[0.04280988 0.03097429 0.33007854 0.5380817 ]\n",
      "[0.04773156 0.05910359 0.49349788 0.42660677]\n",
      "[0.04259166 0.03062273 0.32847092 0.5394715 ]\n",
      "[0.04746104 0.05826008 0.49064174 0.4284475 ]\n",
      "[0.04234076 0.0302439  0.3268031  0.5409122 ]\n",
      "[0.04717496 0.05737077 0.48757812 0.4304234 ]\n",
      "[0.04207821 0.02985004 0.3250566  0.5424309 ]\n",
      "[0.04687132 0.05643316 0.4842914  0.43254146]\n",
      "[0.04180296 0.02944081 0.3232324  0.5440294 ]\n",
      "[0.04654876 0.0554455  0.4807676  0.4348107 ]\n",
      "[0.0415144  0.02901622 0.32133138 0.5457095 ]\n",
      "[0.04620624 0.0544067  0.4769922  0.43724033]\n",
      "[0.04121225 0.02857661 0.31935495 0.5474724 ]\n",
      "[0.04584289 0.05331621 0.47295085 0.43984002]\n",
      "[0.04089639 0.0281225  0.31730542 0.54931897]\n",
      "[0.04545798 0.052174   0.46862945 0.4426189 ]\n",
      "[0.04056681 0.02765468 0.31518596 0.55124897]\n",
      "[0.04505089 0.05098072 0.4640151  0.44558576]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7920560836791992\n",
      "loss training = 0.41575419902801514\n",
      "___________________________________\n",
      "Epoch 29\n",
      "[0.04362505 0.04697551 0.45282942 0.44950584]\n",
      "[0.04015174 0.02656293 0.3136345  0.5543354 ]\n",
      "[0.04495637 0.05096987 0.4697878  0.43865773]\n",
      "[0.04131939 0.02824255 0.32150608 0.54692996]\n",
      "[0.046531   0.05583991 0.48838136 0.4265229 ]\n",
      "[0.0427637  0.03040599 0.33132362 0.5380154 ]\n",
      "[0.04832342 0.06166407 0.5085391  0.4133318 ]\n",
      "[0.04453088 0.03321785 0.3437296  0.5272495 ]\n",
      "[0.05033615 0.06856664 0.529964   0.399212  ]\n",
      "[0.0466991  0.03692564 0.35946164 0.5142491 ]\n",
      "[0.05255497 0.0766086  0.5520824  0.3844315 ]\n",
      "[0.04935778 0.04186886 0.37931544 0.49866474]\n",
      "[0.05493612 0.08571643 0.57402515 0.36942294]\n",
      "[0.05259058 0.04847938 0.4039558  0.4803124 ]\n",
      "[0.05751862 0.09577369 0.59457344 0.35479176]\n",
      "[0.05647207 0.05727978 0.4336593  0.45929077]\n",
      "[0.06097782 0.10741926 0.61182153 0.3413441 ]\n",
      "[0.06100983 0.06855835 0.4668102  0.43672842]\n",
      "[0.04392546 0.03069626 0.3250022  0.54057974]\n",
      "[0.04773218 0.05968943 0.5017028  0.4175887 ]\n",
      "ABABA1AABBAAB => ABABABABABABABABAABA\n",
      "accuracy training = 0.822429895401001\n",
      "loss training = 0.40721604228019714\n",
      "___________________________________\n",
      "Epoch 30\n",
      "[0.0332737  0.02310657 0.31504786 0.54981893]\n",
      "[0.04411957 0.0493587  0.46173197 0.4466373 ]\n",
      "[0.03954601 0.02572869 0.30425513 0.5659801 ]\n",
      "[0.04332866 0.04699087 0.45090503 0.45316166]\n",
      "[0.05848463 0.10141324 0.6035891  0.34662065]\n",
      "[0.05671614 0.05825747 0.4336296  0.46126962]\n",
      "[0.05872756 0.09984571 0.59548825 0.34986335]\n",
      "[0.05622818 0.05697453 0.42951053 0.46448725]\n",
      "[0.05828755 0.0984098  0.5933721  0.35161248]\n",
      "[0.05568043 0.05569046 0.42534745 0.46744952]\n",
      "[0.05785132 0.09699008 0.59124154 0.35337287]\n",
      "[0.0551423  0.05444615 0.4212453  0.47038335]\n",
      "[0.05741559 0.0955727  0.589059   0.35516033]\n",
      "[0.05461135 0.05323563 0.41719228 0.4733003 ]\n",
      "[0.05697876 0.09415308 0.5868171  0.35698098]\n",
      "[0.05408568 0.05205408 0.41317582 0.47620943]\n",
      "[0.05653936 0.09272709 0.58450764 0.35884133]\n",
      "[0.0535636  0.05089721 0.40918374 0.4791196 ]\n",
      "[0.05611454 0.09131539 0.58210236 0.3607519 ]\n",
      "[0.05304591 0.04976302 0.40519992 0.48203957]\n",
      "ABABA1AABBAAB => BABBABABABABABABABAB\n",
      "accuracy training = 0.7897196412086487\n",
      "loss training = 0.42065370082855225\n",
      "___________________________________\n",
      "Epoch 31\n",
      "[0.04299626 0.04579913 0.4525548  0.44843227]\n",
      "[0.03988626 0.0254683  0.3087583  0.5625992 ]\n",
      "[0.04475151 0.05120503 0.47576475 0.43271074]\n",
      "[0.04140741 0.02764313 0.31922886 0.55216575]\n",
      "[0.04667502 0.05744206 0.49933836 0.41652298]\n",
      "[0.04318061 0.03033563 0.33176267 0.5402661 ]\n",
      "[0.04869239 0.06439301 0.5226183  0.40045258]\n",
      "[0.04520787 0.0336545  0.34669048 0.52683115]\n",
      "[0.05075734 0.07193625 0.5449151  0.38487682]\n",
      "[0.04750023 0.03772958 0.36420858 0.51187986]\n",
      "[0.05281771 0.07987455 0.56557465 0.37015942]\n",
      "[0.05005497 0.04268573 0.38431546 0.4955746 ]\n",
      "[0.05481644 0.08793952 0.5840487  0.3566237 ]\n",
      "[0.05287396 0.04868552 0.40704602 0.47804472]\n",
      "[0.05673524 0.09588414 0.5999322  0.34449163]\n",
      "[0.0558708  0.05565895 0.4313153  0.46010303]\n",
      "[0.05921702 0.10439994 0.61240816 0.33409354]\n",
      "[0.05901236 0.0634534  0.45557657 0.44266546]\n",
      "[0.04271152 0.02814321 0.31414428 0.55393356]\n",
      "[0.04628327 0.05612596 0.49435866 0.41970968]\n",
      "ABABA1AABBAAB => ABABABABABABABABAABA\n",
      "accuracy training = 0.7827102541923523\n",
      "loss training = 0.4155671298503876\n",
      "___________________________________\n",
      "Epoch 32\n",
      "[0.03398559 0.02383659 0.32096657 0.5477741 ]\n",
      "[0.04547156 0.05454429 0.48609966 0.42640078]\n",
      "[0.04156976 0.02749334 0.31090942 0.5619904 ]\n",
      "[0.04517991 0.05348764 0.48105246 0.4290547 ]\n",
      "[0.0412704  0.02702656 0.30851024 0.5643406 ]\n",
      "[0.04479088 0.052223   0.4761132  0.4325902 ]\n",
      "[0.04092483 0.02652453 0.30605733 0.5668217 ]\n",
      "[0.0443771  0.05089335 0.4707889  0.43640852]\n",
      "[0.04056277 0.02600562 0.3035052  0.5694318 ]\n",
      "[0.04393699 0.04949925 0.4650564  0.44052303]\n",
      "[0.04018384 0.0254709  0.30086026 0.57216936]\n",
      "[0.04346959 0.04804252 0.45889676 0.44494894]\n",
      "[0.03978817 0.02492188 0.29813093 0.5750313 ]\n",
      "[0.04297438 0.04652641 0.45229477 0.44969958]\n",
      "[0.05819605 0.10559957 0.6179661  0.32913846]\n",
      "[0.05773696 0.0605941  0.44230548 0.45233583]\n",
      "[0.059128   0.10639002 0.6132684  0.32958865]\n",
      "[0.05827304 0.06188711 0.44649667 0.44968155]\n",
      "[0.04163538 0.02617055 0.29711735 0.5728722 ]\n",
      "[0.04329756 0.04748864 0.45625383 0.4466123 ]\n",
      "ABABA1AABBAAB => BABABABABABABBABAABA\n",
      "accuracy training = 0.8200934529304504\n",
      "loss training = 0.39803144335746765\n",
      "___________________________________\n",
      "Epoch 33\n",
      "[0.04149528 0.04187083 0.4368126  0.45666927]\n",
      "[0.05752321 0.10479057 0.62541395 0.3197253 ]\n",
      "[0.05877793 0.06264201 0.4541267  0.43999317]\n",
      "[0.04309746 0.02747242 0.30798408 0.5622177 ]\n",
      "[0.04520167 0.05369892 0.48893154 0.4189286 ]\n",
      "[0.04267134 0.02840097 0.32020614 0.55301696]\n",
      "[0.04672616 0.05907342 0.5091776  0.40458408]\n",
      "[0.04419064 0.03083839 0.33193755 0.5415907 ]\n",
      "[0.04846425 0.0655092  0.5307273  0.38904193]\n",
      "[0.04604022 0.03400894 0.34660816 0.5278923 ]\n",
      "[0.05040032 0.07310161 0.5533317  0.37263477]\n",
      "[0.04828298 0.03817511 0.36494327 0.51153916]\n",
      "[0.0524928  0.0817851  0.57602155 0.35592288]\n",
      "[0.05097774 0.04366924 0.3876105  0.49230757]\n",
      "[0.05464052 0.09116126 0.5972571  0.33982763]\n",
      "[0.05414333 0.05084448 0.41492942 0.47034138]\n",
      "[0.05726272 0.10165292 0.61595607 0.32483715]\n",
      "[0.05783263 0.06007202 0.44626352 0.44625473]\n",
      "[0.04251438 0.02667169 0.30435315 0.5661255 ]\n",
      "[0.04453647 0.05147658 0.48010898 0.42529073]\n",
      "ABABA1AABBAAB => BAABABABABABABABAABA\n",
      "accuracy training = 0.8130841255187988\n",
      "loss training = 0.41073042154312134\n",
      "___________________________________\n",
      "Epoch 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03319069 0.02214812 0.31000686 0.56018394]\n",
      "[0.04384252 0.05013224 0.47256276 0.43408924]\n",
      "[0.04053096 0.02517303 0.29853472 0.5782163 ]\n",
      "[0.04328349 0.04823871 0.46362883 0.43989953]\n",
      "[0.04001978 0.0244372  0.29465243 0.5823819 ]\n",
      "[0.04264177 0.04621401 0.4547396  0.4465854 ]\n",
      "[0.03948139 0.02370456 0.29088613 0.5865542 ]\n",
      "[0.0419875  0.04419962 0.4455201  0.45354134]\n",
      "[0.05651843 0.10114679 0.61390895 0.32583198]\n",
      "[0.05587569 0.05533607 0.42671874 0.46369135]\n",
      "[0.05651672 0.09889972 0.6050822  0.3300805 ]\n",
      "[0.0553532  0.05396065 0.4221662  0.46771434]\n",
      "[0.05608165 0.09735327 0.60273993 0.33216438]\n",
      "[0.05481621 0.05264955 0.4175481  0.47135115]\n",
      "[0.05566292 0.0958486  0.60037434 0.33424982]\n",
      "[0.05429458 0.05139377 0.41304114 0.47492048]\n",
      "[0.05524835 0.09435993 0.5979686  0.33635238]\n",
      "[0.05378443 0.0501852  0.408633   0.47843546]\n",
      "[0.05483635 0.09288286 0.59551764 0.33847764]\n",
      "[0.05328394 0.04901837 0.40430987 0.4819065 ]\n",
      "ABABA1AABBAAB => BABABABBABABABABABAB\n",
      "accuracy training = 0.7897196412086487\n",
      "loss training = 0.41720157861709595\n",
      "___________________________________\n",
      "Epoch 35\n",
      "[0.0416397  0.04273324 0.44533437 0.44962308]\n",
      "[0.04010266 0.02359646 0.29562128 0.5821852 ]\n",
      "[0.04315734 0.04770315 0.46883988 0.43214867]\n",
      "[0.04144061 0.02549161 0.30547297 0.57122135]\n",
      "[0.04482348 0.05345179 0.4928433  0.41415626]\n",
      "[0.04299073 0.02782318 0.31725174 0.5587029 ]\n",
      "[0.04659293 0.05996168 0.5169913  0.39607474]\n",
      "[0.04475918 0.03068873 0.3312805  0.5444998 ]\n",
      "[0.04844065 0.06720528 0.5407268  0.37823617]\n",
      "[0.04676159 0.03420953 0.34781095 0.528558  ]\n",
      "[0.05033639 0.07509747 0.56346965 0.36098683]\n",
      "[0.04900626 0.03851644 0.36696953 0.5109434 ]\n",
      "[0.05219895 0.08326965 0.5840808  0.34504545]\n",
      "[0.05146558 0.04370312 0.3886599  0.49197415]\n",
      "[0.05395722 0.09131828 0.6018316  0.33088586]\n",
      "[0.05409121 0.04980922 0.41243556 0.47216788]\n",
      "[0.05614017 0.09985563 0.61629206 0.31859607]\n",
      "[0.05690903 0.05687859 0.43737453 0.4521408 ]\n",
      "[0.05829331 0.10805435 0.6278805  0.30814335]\n",
      "[0.05973749 0.06459171 0.46209937 0.43294978]\n",
      "ABABA1AABBAAB => ABABABABABABABABABAA\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.4087482690811157\n",
      "___________________________________\n",
      "Epoch 36\n",
      "[0.03311277 0.02128914 0.30230337 0.57000154]\n",
      "[0.04306241 0.04845022 0.4679511  0.4352048 ]\n",
      "[0.04093087 0.02430454 0.29000273 0.59013945]\n",
      "[0.04252223 0.04653395 0.4585465  0.44173363]\n",
      "[0.04042513 0.02357592 0.28602758 0.5946348 ]\n",
      "[0.04189336 0.04446105 0.44893178 0.44927695]\n",
      "[0.03988407 0.02283959 0.2821022  0.5992144 ]\n",
      "[0.04124019 0.04236578 0.4387753  0.45727783]\n",
      "[0.05523137 0.10056614 0.6179856  0.31669936]\n",
      "[0.05591593 0.05448955 0.4228897  0.46545982]\n",
      "[0.05607245 0.10138417 0.6143028  0.31723967]\n",
      "[0.05600131 0.054432   0.42211425 0.4660741 ]\n",
      "[0.05603476 0.10118121 0.61389863 0.31756252]\n",
      "[0.0559325  0.05424901 0.4214572  0.46661353]\n",
      "[0.05597979 0.10096536 0.6135668  0.3178615 ]\n",
      "[0.05586145 0.05406461 0.42079964 0.46715158]\n",
      "[0.05592443 0.10074862 0.61323345 0.31816202]\n",
      "[0.05579026 0.05388027 0.42014086 0.46769118]\n",
      "[0.05586888 0.10053103 0.6128974  0.31846464]\n",
      "[0.0557189  0.05369594 0.41948053 0.46823248]\n",
      "ABABA1AABBAAB => BABABABBABABABABABAB\n",
      "accuracy training = 0.8177570104598999\n",
      "loss training = 0.3939446806907654\n",
      "___________________________________\n",
      "Epoch 37\n",
      "[0.04340405 0.04917273 0.47960153 0.4201449 ]\n",
      "[0.04286939 0.02613514 0.30778185 0.57038283]\n",
      "[0.04537128 0.05673195 0.5106484  0.39642417]\n",
      "[0.04485217 0.02934459 0.32426664 0.55270433]\n",
      "[0.04749972 0.06550754 0.5411977  0.37284246]\n",
      "[0.04719048 0.0335139  0.3445959  0.53214896]\n",
      "[0.04971004 0.07534047 0.5702859  0.35020784]\n",
      "[0.04988997 0.03889762 0.36915866 0.5087437 ]\n",
      "[0.05194239 0.08598042 0.596929   0.3291268 ]\n",
      "[0.05294466 0.04576258 0.39788893 0.48288852]\n",
      "[0.05465003 0.09779899 0.6198254  0.31023923]\n",
      "[0.05637087 0.05433024 0.4297728  0.4555639 ]\n",
      "[0.05738008 0.10909706 0.63674605 0.2951773 ]\n",
      "[0.05993561 0.06438717 0.46315    0.42849347]\n",
      "[0.04482296 0.02728496 0.30532965 0.5695356 ]\n",
      "[0.04545418 0.05705502 0.5116399  0.39541036]\n",
      "[0.04493007 0.0294768  0.3249261  0.55201054]\n",
      "[0.04757395 0.06583972 0.54227996 0.3720024 ]\n",
      "[0.04727782 0.03368309 0.34541124 0.5313511 ]\n",
      "[0.04978847 0.07570954 0.57129574 0.3494155 ]\n",
      "ABABA1AABBAAB => ABABABABABABAABABABA\n",
      "accuracy training = 0.8084112405776978\n",
      "loss training = 0.4091109037399292\n",
      "___________________________________\n",
      "Epoch 38\n",
      "[0.03451474 0.02373089 0.32480225 0.5525226 ]\n",
      "[0.04589876 0.06043589 0.5198855  0.39234197]\n",
      "[0.04455556 0.02875873 0.31341854 0.5672786 ]\n",
      "[0.04594256 0.06046019 0.5188245  0.39211375]\n",
      "[0.04454466 0.02870063 0.3129492  0.56770074]\n",
      "[0.04589593 0.06027367 0.51817465 0.3926292 ]\n",
      "[0.04449642 0.02862077 0.3125421  0.56813276]\n",
      "[0.04585019 0.06008759 0.5175243  0.39315152]\n",
      "[0.04444896 0.0285415  0.312135   0.5685654 ]\n",
      "[0.04580484 0.05990198 0.5168712  0.39367655]\n",
      "[0.04440186 0.02846258 0.31172785 0.5689986 ]\n",
      "[0.04575955 0.05971634 0.51621515 0.3942041 ]\n",
      "[0.04435489 0.02838388 0.31132087 0.5694321 ]\n",
      "[0.04571424 0.05953061 0.5155561  0.39473417]\n",
      "[0.04430796 0.02830533 0.31091398 0.56986594]\n",
      "[0.04566884 0.05934468 0.5148939  0.39526668]\n",
      "[0.04426104 0.02822694 0.3105073  0.5703003 ]\n",
      "[0.04562328 0.05915849 0.51422846 0.3958018 ]\n",
      "[0.04421406 0.02814865 0.31010067 0.570735  ]\n",
      "[0.04557763 0.05897203 0.5135597  0.39633957]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7873831987380981\n",
      "loss training = 0.41093555092811584\n",
      "___________________________________\n",
      "Epoch 39\n",
      "[0.04037163 0.03943026 0.43373704 0.45627725]\n",
      "[0.05391662 0.10147789 0.63262075 0.29599968]\n",
      "[0.05710728 0.05681    0.43983442 0.44751638]\n",
      "[0.05629225 0.11015744 0.6419765  0.28547257]\n",
      "[0.05947474 0.06365529 0.46216708 0.42879495]\n",
      "[0.04479944 0.02610525 0.29592618 0.5826539 ]\n",
      "[0.04441271 0.05457348 0.50419146 0.39948618]\n",
      "[0.04429502 0.0273761  0.31123903 0.56894946]\n",
      "[0.04588671 0.06086786 0.52797675 0.3807277 ]\n",
      "[0.04587387 0.03012982 0.3256393  0.553503  ]\n",
      "[0.04740795 0.06772055 0.55064183 0.3625555 ]\n",
      "[0.04761678 0.03342409 0.3421309  0.5365751 ]\n",
      "[0.04893169 0.07497898 0.57186335 0.34541056]\n",
      "[0.04950825 0.03732757 0.36070463 0.5183267 ]\n",
      "[0.0504337  0.08249965 0.59130317 0.32951257]\n",
      "[0.05153265 0.04189842 0.3811734  0.4990428 ]\n",
      "[0.05189063 0.09011717 0.60874826 0.31500843]\n",
      "[0.05366358 0.04716388 0.4031634  0.47912726]\n",
      "[0.05357365 0.09808625 0.62377954 0.3020735 ]\n",
      "[0.0559008  0.0531179  0.42596185 0.4591496 ]\n",
      "ABABA1AABBAAB => BABAABABABABABABABAB\n",
      "accuracy training = 0.8154205679893494\n",
      "loss training = 0.40085625648498535\n",
      "___________________________________\n",
      "Epoch 40\n",
      "[0.03399657 0.02210188 0.3109811  0.5680456 ]\n",
      "[0.04441758 0.0560985  0.50648636 0.40033367]\n",
      "[0.04372954 0.02641142 0.2987507  0.5858471 ]\n",
      "[0.04433715 0.0556219  0.5036545  0.40175134]\n",
      "[0.0436034  0.02617023 0.29728103 0.5874372 ]\n",
      "[0.04417919 0.05496681 0.50110024 0.40386534]\n",
      "[0.04344464 0.02591211 0.2958627  0.58904636]\n",
      "[0.04401987 0.0543076  0.49849707 0.40602612]\n",
      "[0.04328561 0.02565499 0.29444322 0.59066486]\n",
      "[0.04385877 0.0536443  0.49584168 0.4082311 ]\n",
      "[0.04312588 0.02539869 0.29302272 0.5922926 ]\n",
      "[0.0436955  0.0529765  0.49313268 0.41048136]\n",
      "[0.04296526 0.02514308 0.2916014  0.59392965]\n",
      "[0.04352999 0.05230416 0.4903685  0.41277814]\n",
      "[0.04280365 0.02488813 0.29017934 0.5955759 ]\n",
      "[0.04336205 0.0516272  0.48754758 0.4151228 ]\n",
      "[0.042641   0.02463383 0.2887569  0.59723157]\n",
      "[0.04319166 0.05094565 0.48466864 0.4175166 ]\n",
      "[0.04247724 0.02438018 0.287334   0.59889644]\n",
      "[0.04301876 0.05025957 0.48173043 0.4199608 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7967289686203003\n",
      "loss training = 0.39651310443878174\n",
      "___________________________________\n",
      "Epoch 41\n",
      "[0.04016155 0.03905305 0.43422565 0.454377  ]\n",
      "[0.05301916 0.1017373  0.6376369  0.2860636 ]\n",
      "[0.05724769 0.0567862  0.44104838 0.444931  ]\n",
      "[0.05539887 0.11120751 0.64865816 0.27421388]\n",
      "[0.05963067 0.06403278 0.4649825  0.42419615]\n",
      "[0.04552756 0.02584242 0.2923607  0.5886454 ]\n",
      "[0.04409942 0.05473692 0.50842565 0.39282104]\n",
      "[0.04493    0.02714834 0.30831453 0.57377124]\n",
      "[0.04551334 0.06119344 0.53299534 0.37290385]\n",
      "[0.0464905  0.02997329 0.323498   0.55704707]\n",
      "[0.04697388 0.06823478 0.55635303 0.35368538]\n",
      "[0.0482152  0.03337371 0.34096417 0.53864545]\n",
      "[0.04843687 0.07569984 0.5781414  0.33563322]\n",
      "[0.05008804 0.03742754 0.36070713 0.5187486 ]\n",
      "[0.04987902 0.08343727 0.5980124  0.31897616]\n",
      "[0.05209275 0.04220191 0.38252178 0.4976837 ]\n",
      "[0.05127817 0.09127405 0.6157594  0.30385736]\n",
      "[0.05420228 0.0477308  0.40599144 0.47591725]\n",
      "[0.05298748 0.09958648 0.630881   0.2904761 ]\n",
      "[0.05642641 0.05401192 0.43027824 0.45413184]\n",
      "ABABA1AABBAAB => BABAABABABABABABABAB\n",
      "accuracy training = 0.8084112405776978\n",
      "loss training = 0.40222227573394775\n",
      "___________________________________\n",
      "Epoch 42\n",
      "[0.03435028 0.0224439  0.31477368 0.56667626]\n",
      "[0.04469556 0.05909178 0.52130497 0.38516843]\n",
      "[0.04503192 0.02735732 0.30233043 0.5838972 ]\n",
      "[0.04474557 0.05916063 0.5205456  0.38487008]\n",
      "[0.04503495 0.02732351 0.30198663 0.5842107 ]\n",
      "[0.0447168  0.05903402 0.5200845  0.3852558 ]\n",
      "[0.04500433 0.02727078 0.30169842 0.58453673]\n",
      "[0.04468888 0.05890803 0.51962495 0.3856466 ]\n",
      "[0.04497446 0.0272186  0.30141062 0.5848627 ]\n",
      "[0.04466141 0.0587827  0.51916504 0.38603824]\n",
      "[0.04494498 0.02716677 0.30112338 0.5851885 ]\n",
      "[0.04463413 0.05865776 0.51870453 0.38643062]\n",
      "[0.04491565 0.02711516 0.30083662 0.5855137 ]\n",
      "[0.04460694 0.05853302 0.5182435  0.38682356]\n",
      "[0.04488645 0.02706373 0.3005505  0.5858387 ]\n",
      "[0.04457975 0.05840843 0.5177817  0.3872172 ]\n",
      "[0.04485733 0.02701247 0.30026492 0.58616316]\n",
      "[0.04455258 0.05828397 0.5173192  0.38761136]\n",
      "[0.04482824 0.02696136 0.29997993 0.5864873 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0445254  0.05815959 0.51685596 0.38800624]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7897196412086487\n",
      "loss training = 0.3982556462287903\n",
      "___________________________________\n",
      "Epoch 43\n",
      "[0.03858037 0.03396346 0.40457186 0.48008195]\n",
      "[0.05058431 0.09240164 0.6221651  0.29487053]\n",
      "[0.05447433 0.0481013  0.40707344 0.4752664 ]\n",
      "[0.05195095 0.09946056 0.63403594 0.28295693]\n",
      "[0.0562514  0.05331398 0.42756474 0.45634645]\n",
      "[0.05325088 0.10607684 0.6446109  0.27311823]\n",
      "[0.05798281 0.05887631 0.44809255 0.4379872 ]\n",
      "[0.04499071 0.0237839  0.27734768 0.6092837 ]\n",
      "[0.04251648 0.04940172 0.4875686  0.40831968]\n",
      "[0.04401889 0.0244355  0.28949785 0.59777707]\n",
      "[0.04355614 0.05413888 0.50821066 0.391081  ]\n",
      "[0.04511171 0.02630419 0.30026743 0.5850096 ]\n",
      "[0.04464903 0.05934294 0.5284621  0.37396714]\n",
      "[0.04631363 0.02849733 0.31254384 0.57096064]\n",
      "[0.0457639  0.0649357  0.5480981  0.35737222]\n",
      "[0.04761647 0.03105884 0.326429   0.5556434 ]\n",
      "[0.04688882 0.07085937 0.5668195  0.3415012 ]\n",
      "[0.04901786 0.03403703 0.3419511  0.5391333 ]\n",
      "[0.04801119 0.07703675 0.58437467 0.32652476]\n",
      "[0.05051131 0.0374755  0.3590553  0.5215803 ]\n",
      "ABABA1AABBAAB => BABABAABABABABABABAB\n",
      "accuracy training = 0.8084112405776978\n",
      "loss training = 0.39670222997665405\n",
      "___________________________________\n",
      "Epoch 44\n",
      "[0.03401601 0.021253   0.30389708 0.5799928 ]\n",
      "[0.04363467 0.05610738 0.51238275 0.39022538]\n",
      "[0.04483984 0.02578958 0.29043478 0.5998402 ]\n",
      "[0.04362006 0.05589423 0.5106683  0.39090824]\n",
      "[0.04478227 0.02565506 0.28952113 0.600854  ]\n",
      "[0.04353877 0.05551505 0.50917023 0.39221206]\n",
      "[0.04469584 0.02550532 0.28865355 0.6018836 ]\n",
      "[0.04345767 0.05513494 0.50765735 0.39353493]\n",
      "[0.04460979 0.02535624 0.28778607 0.60291624]\n",
      "[0.04337635 0.05475384 0.5061274  0.39487347]\n",
      "[0.04452374 0.02520758 0.28691837 0.6039518 ]\n",
      "[0.04329455 0.05437144 0.50457984 0.3962279 ]\n",
      "[0.04443752 0.02505927 0.28605062 0.6049903 ]\n",
      "[0.04321213 0.05398754 0.503014   0.3975986 ]\n",
      "[0.044351   0.0249112  0.2851826  0.60603195]\n",
      "[0.04312905 0.05360199 0.5014292  0.3989862 ]\n",
      "[0.04426417 0.02476338 0.28431427 0.607077  ]\n",
      "[0.04304525 0.05321476 0.49982506 0.40039104]\n",
      "[0.04417697 0.02461573 0.28344545 0.6081255 ]\n",
      "[0.0429607  0.05282573 0.49820083 0.40181383]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8060747385025024\n",
      "loss training = 0.39343321323394775\n",
      "___________________________________\n",
      "Epoch 45\n",
      "[0.03834302 0.03327377 0.40193266 0.4815941 ]\n",
      "[0.04972146 0.09173938 0.6246406  0.287881  ]\n",
      "[0.05458441 0.04730988 0.40367877 0.47770447]\n",
      "[0.05104993 0.09876791 0.6365283  0.2758786 ]\n",
      "[0.05626234 0.05240489 0.42430997 0.45814043]\n",
      "[0.05225097 0.1052619  0.64714485 0.26591662]\n",
      "[0.0578856  0.0578378  0.44502315 0.4391352 ]\n",
      "[0.04555309 0.02318555 0.27128068 0.6185848 ]\n",
      "[0.04201074 0.04836012 0.4857183  0.4072993 ]\n",
      "[0.04448082 0.02380047 0.2833796  0.60666627]\n",
      "[0.04298667 0.05303426 0.50676554 0.38930684]\n",
      "[0.04552161 0.0256078  0.29409957 0.59356743]\n",
      "[0.04401213 0.05816824 0.52740675 0.3714918 ]\n",
      "[0.04666334 0.02772602 0.3063187  0.5791474 ]\n",
      "[0.04505718 0.0636842  0.54740095 0.35425973]\n",
      "[0.04789725 0.03019657 0.32013938 0.5634184 ]\n",
      "[0.0461109  0.06952567 0.56644696 0.33782   ]\n",
      "[0.04922071 0.03306537 0.33559403 0.54645354]\n",
      "[0.04716201 0.07561831 0.5842956  0.32234243]\n",
      "[0.05062757 0.03637439 0.3526365  0.5284    ]\n",
      "ABABA1AABBAAB => BABABAABABABABABABAB\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.3995117247104645\n",
      "___________________________________\n",
      "Epoch 46\n",
      "[0.03432628 0.0216022  0.30770758 0.57779706]\n",
      "[0.04380343 0.05885546 0.52617854 0.37524474]\n",
      "[0.04589772 0.02660256 0.2941284  0.59723985]\n",
      "[0.04388041 0.0591008  0.52625877 0.37439662]\n",
      "[0.04594084 0.02664831 0.29426423 0.59701043]\n",
      "[0.04389307 0.05917334 0.5265322  0.37414566]\n",
      "[0.04595561 0.02667824 0.2944444  0.5967973 ]\n",
      "[0.04390646 0.05924597 0.5268057  0.3739006 ]\n",
      "[0.04597097 0.0267084  0.29462373 0.5965856 ]\n",
      "[0.04392017 0.05931878 0.5270778  0.37365732]\n",
      "[0.04598657 0.02673863 0.29480222 0.596375  ]\n",
      "[0.04393398 0.05939144 0.5273485  0.37341565]\n",
      "[0.04600222 0.0267688  0.29497993 0.5961653 ]\n",
      "[0.0439478  0.05946385 0.5276175  0.3731756 ]\n",
      "[0.04601786 0.02679891 0.29515687 0.5959567 ]\n",
      "[0.04396157 0.05953595 0.5278849  0.37293702]\n",
      "[0.04603346 0.02682891 0.29533306 0.59574896]\n",
      "[0.04397529 0.05960773 0.5281506  0.3727    ]\n",
      "[0.04604901 0.02685881 0.29550856 0.59554225]\n",
      "[0.04398894 0.05967916 0.52841467 0.37246448]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8037382960319519\n",
      "loss training = 0.3931219279766083\n",
      "___________________________________\n",
      "Epoch 47\n",
      "[0.03701966 0.02886774 0.37094688 0.51148385]\n",
      "[0.04750436 0.08210109 0.6046725  0.3018187 ]\n",
      "[0.05230806 0.03986454 0.3680024  0.5137688 ]\n",
      "[0.0483568  0.08745848 0.61647624 0.29027355]\n",
      "[0.0535282  0.04332641 0.3843189  0.49714842]\n",
      "[0.04910765 0.09255425 0.62765974 0.28010258]\n",
      "[0.05474705 0.04712712 0.40153435 0.48015207]\n",
      "[0.04995214 0.09780797 0.6378099  0.2706985 ]\n",
      "[0.05601405 0.05131138 0.41936246 0.46297255]\n",
      "[0.05087481 0.10316926 0.64694667 0.26205355]\n",
      "[0.05730706 0.05582603 0.43738383 0.44598925]\n",
      "[0.04572811 0.02215129 0.26085508 0.6343443 ]\n",
      "[0.04110591 0.04558957 0.4735274  0.41689038]\n",
      "[0.04433129 0.02231026 0.27012086 0.6254698 ]\n",
      "[0.0417722  0.04885293 0.48959276 0.40279403]\n",
      "[0.04502974 0.0234971  0.2774981  0.6159994 ]\n",
      "[0.04248194 0.05242497 0.5056559  0.3885265 ]\n",
      "[0.04579027 0.02484792 0.28573593 0.6056803 ]\n",
      "[0.04321271 0.0562632  0.521648   0.37437785]\n",
      "[0.0466061  0.02638101 0.29492503 0.59447616]\n",
      "ABABA1AABBAAB => BABABABABAABABABABAB\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.39218637347221375\n",
      "___________________________________\n",
      "Epoch 48\n",
      "[0.03400563 0.02044117 0.29670703 0.591483  ]\n",
      "[0.04280582 0.05572438 0.516108   0.38195026]\n",
      "[0.04588142 0.02512202 0.2821469  0.61371577]\n",
      "[0.04284335 0.05580402 0.51577497 0.38164586]\n",
      "[0.04589131 0.02511343 0.28199473 0.6138471 ]\n",
      "[0.04283266 0.05575349 0.51557463 0.38182208]\n",
      "[0.04587981 0.02509332 0.28187528 0.6139935 ]\n",
      "[0.04282272 0.05570323 0.5153749  0.38200295]\n",
      "[0.04586889 0.02507345 0.28175515 0.614141  ]\n",
      "[0.04281311 0.05565321 0.5151744  0.3821851 ]\n",
      "[0.0458582  0.02505364 0.28163454 0.6142892 ]\n",
      "[0.0428036  0.05560319 0.514973   0.38236836]\n",
      "[0.0458476  0.02503384 0.28151345 0.61443806]\n",
      "[0.04279413 0.05555303 0.5147706  0.3825526 ]\n",
      "[0.04583703 0.02501401 0.28139192 0.6145876 ]\n",
      "[0.04278463 0.05550271 0.51456726 0.38273776]\n",
      "[0.0458264  0.02499411 0.2812699  0.61473763]\n",
      "[0.04277512 0.05545219 0.51436293 0.38292396]\n",
      "[0.04581578 0.02497416 0.2811475  0.61488825]\n",
      "[0.04276556 0.05540144 0.5141574  0.38311115]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8060747385025024\n",
      "loss training = 0.39624670147895813\n",
      "___________________________________\n",
      "Epoch 49\n",
      "[0.03670077 0.02773946 0.36284488 0.51945066]\n",
      "[0.04655442 0.07990541 0.60170597 0.30057886]\n",
      "[0.05215551 0.03816039 0.3582624  0.52425474]\n",
      "[0.04730955 0.08488582 0.61327296 0.28928062]\n",
      "[0.0532282  0.04125481 0.3735536  0.50818026]\n",
      "[0.04797805 0.08963341 0.6241954  0.27927157]\n",
      "[0.05429543 0.04462712 0.38963258 0.49177215]\n",
      "[0.04863258 0.09436709 0.63426286 0.269969  ]\n",
      "[0.05538546 0.04830394 0.40629545 0.47518048]\n",
      "[0.04936895 0.09920387 0.64336306 0.2614045 ]\n",
      "[0.05650532 0.05228765 0.42332354 0.45860058]\n",
      "[0.05014949 0.10406245 0.6515627  0.25354898]\n",
      "[0.05763979 0.05655412 0.44050726 0.44222972]\n",
      "[0.05090668 0.10880785 0.65897524 0.24635476]\n",
      "[0.05876847 0.06106433 0.45764166 0.4262508 ]\n",
      "[0.04732528 0.02323671 0.2640713  0.63127387]\n",
      "[0.04161958 0.0495395  0.49447918 0.3959474 ]\n",
      "[0.04581896 0.02347238 0.27440563 0.6211868 ]\n",
      "[0.0422558  0.05303574 0.5104254  0.38178837]\n",
      "[0.04653232 0.02481292 0.28279868 0.6105678 ]\n",
      "ABABA1AABBAAB => BABABABABABABAABABAB\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.3904676139354706\n",
      "___________________________________\n",
      "Epoch 50\n",
      "[0.03398161 0.01993698 0.29162547 0.59820306]\n",
      "[0.04230057 0.05491165 0.5147813  0.38048503]\n",
      "[0.04625057 0.02454705 0.27658358 0.62209994]\n",
      "[0.04235201 0.05511881 0.51519    0.37968802]\n",
      "[0.04628778 0.02460169 0.27686498 0.62171066]\n",
      "[0.04237232 0.05524009 0.5156921  0.37921825]\n",
      "[0.04631136 0.02464952 0.27717063 0.62132883]\n",
      "[0.04239362 0.05536306 0.51619846 0.3787487 ]\n",
      "[0.04633579 0.02469815 0.2774791  0.6209441 ]\n",
      "[0.04241543 0.05548751 0.51670814 0.3782767 ]\n",
      "[0.04636068 0.02474742 0.27779052 0.6205558 ]\n",
      "[0.04243753 0.05561318 0.517221   0.37780204]\n",
      "[0.0463859  0.02479728 0.27810502 0.62016416]\n",
      "[0.04245988 0.05574001 0.5177369  0.37732473]\n",
      "[0.04641143 0.02484769 0.27842265 0.6197689 ]\n",
      "[0.04248241 0.05586795 0.5182559  0.37684464]\n",
      "[0.04643717 0.02489864 0.2787434  0.61937016]\n",
      "[0.04250509 0.05599694 0.51877785 0.3763619 ]\n",
      "[0.04646314 0.02495014 0.27906725 0.6189678 ]\n",
      "[0.04252794 0.05612702 0.51930267 0.37587655]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8037382960319519\n",
      "loss training = 0.3974035382270813\n",
      "___________________________________\n",
      "Epoch 51\n",
      "[0.03586262 0.02477049 0.33816054 0.54508585]\n",
      "[0.04484676 0.07210303 0.5814111  0.3155858 ]\n",
      "[0.05075042 0.03315682 0.32968795 0.5565419 ]\n",
      "[0.04541481 0.07592545 0.59192497 0.30544987]\n",
      "[0.05151102 0.03520777 0.34093502 0.54394275]\n",
      "[0.04593464 0.07966089 0.60207576 0.2961471 ]\n",
      "[0.05227561 0.03743229 0.3528662  0.53090364]\n",
      "[0.04645203 0.08344642 0.611705   0.28728953]\n",
      "[0.0530637  0.03985267 0.36540443 0.5174818 ]\n",
      "[0.04696448 0.08726039 0.6207903  0.27888918]\n",
      "[0.05387186 0.04247416 0.37848717 0.50376076]\n",
      "[0.04746975 0.09108037 0.6293201  0.27095428]\n",
      "[0.05469626 0.04529893 0.39203486 0.48983565]\n",
      "[0.04796585 0.09488427 0.6372913  0.2634871 ]\n",
      "[0.05553269 0.04832529 0.40595144 0.475811  ]\n",
      "[0.04845089 0.09865046 0.6447087  0.25648507]\n",
      "[0.05637661 0.05154708 0.42012757 0.46179694]\n",
      "[0.04892314 0.10235808 0.6515834  0.24994148]\n",
      "[0.05722304 0.05495305 0.4344432  0.44790578]\n",
      "[0.04943537 0.10607672 0.65786546 0.24386923]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8200934529304504\n",
      "loss training = 0.38700759410858154\n",
      "___________________________________\n",
      "Epoch 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03385215 0.01894104 0.28064227 0.6117059 ]\n",
      "[0.04142871 0.05210334 0.5041583  0.38820922]\n",
      "[0.0466195 0.0232643 0.2640926 0.6389127]\n",
      "[0.04141947 0.05201413 0.50354344 0.38857022]\n",
      "[0.04659956 0.0232182  0.26376426 0.63931686]\n",
      "[0.04139584 0.05188223 0.50296295 0.3891129 ]\n",
      "[0.0465734  0.02316868 0.2634436  0.63973093]\n",
      "[0.04137289 0.05175009 0.5023771  0.38966358]\n",
      "[0.04654768 0.02311916 0.2631206  0.64014846]\n",
      "[0.04135004 0.05161727 0.5017852  0.39022064]\n",
      "[0.04652199 0.02306945 0.26279545 0.64056927]\n",
      "[0.04132709 0.05148354 0.5011871  0.3907839 ]\n",
      "[0.04649621 0.0230195  0.26246816 0.6409931 ]\n",
      "[0.041304   0.05134884 0.5005826  0.39135343]\n",
      "[0.04647025 0.02296928 0.2621388  0.6414201 ]\n",
      "[0.0412807  0.05121306 0.4999715  0.39192927]\n",
      "[0.04644411 0.02291878 0.26180726 0.64185035]\n",
      "[0.04125719 0.0510762  0.49935377 0.39251158]\n",
      "[0.04641778 0.02286798 0.26147363 0.6422837 ]\n",
      "[0.04123346 0.05093823 0.49872914 0.39310044]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8084112405776978\n",
      "loss training = 0.3880526125431061\n",
      "___________________________________\n",
      "Epoch 53\n",
      "[0.03574431 0.02400173 0.3317098  0.55172575]\n",
      "[0.04405673 0.07055018 0.57978755 0.31365266]\n",
      "[0.05134798 0.03231847 0.3218618  0.56543225]\n",
      "[0.04458083 0.07436534 0.5908884  0.3030907 ]\n",
      "[0.0520679  0.03434495 0.33332884 0.55228823]\n",
      "[0.04507696 0.07817398 0.60160726 0.29322028]\n",
      "[0.05280237 0.03656623 0.34558433 0.5385715 ]\n",
      "[0.04557422 0.08206207 0.6118217  0.28378856]\n",
      "[0.05356374 0.03900416 0.35857725 0.52433664]\n",
      "[0.04607008 0.0860076  0.62149924 0.27481577]\n",
      "[0.05434897 0.04166922 0.37225667 0.509666  ]\n",
      "[0.04657797 0.0900109  0.6305971  0.26632446]\n",
      "[0.05515729 0.0445705  0.38654447 0.49466112]\n",
      "[0.0471595  0.09414764 0.6390199  0.25835443]\n",
      "[0.05599492 0.04771747 0.4013199  0.4794495 ]\n",
      "[0.04773534 0.09827944 0.64686334 0.25087377]\n",
      "[0.05684443 0.05109913 0.41648203 0.46415785]\n",
      "[0.04830122 0.10237826 0.6541365  0.24387899]\n",
      "[0.0577004  0.05470733 0.43189833 0.44891948]\n",
      "[0.04885468 0.10641944 0.66085225 0.23736209]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8154205679893494\n",
      "loss training = 0.3888082206249237\n",
      "___________________________________\n",
      "Epoch 54\n",
      "[0.03401423 0.0189364  0.28077057 0.6127519 ]\n",
      "[0.0412416  0.05327995 0.5117262  0.37899497]\n",
      "[0.04776194 0.02360019 0.26344308 0.6407313 ]\n",
      "[0.04126942 0.0534455  0.51232404 0.37829718]\n",
      "[0.04778984 0.02365666 0.26380524 0.64025205]\n",
      "[0.04129026 0.05358706 0.5129414  0.3777063 ]\n",
      "[0.04781508 0.02371186 0.26417372 0.63977677]\n",
      "[0.04131199 0.05372978 0.51355886 0.37711793]\n",
      "[0.04784102 0.02376756 0.2645433  0.6393006 ]\n",
      "[0.04133403 0.05387312 0.5141757  0.3765307 ]\n",
      "[0.04786726 0.0238236  0.26491404 0.63882345]\n",
      "[0.04135621 0.05401684 0.5147919  0.37594464]\n",
      "[0.04789361 0.02387991 0.26528594 0.6383452 ]\n",
      "[0.04137843 0.05416081 0.51540715 0.37535954]\n",
      "[0.04792007 0.02393647 0.265659   0.6378659 ]\n",
      "[0.04140067 0.05430498 0.51602143 0.3747756 ]\n",
      "[0.04794655 0.02399324 0.26603326 0.63738567]\n",
      "[0.04142293 0.0544494  0.5166346  0.37419274]\n",
      "[0.04797311 0.02405024 0.2664086  0.6369044 ]\n",
      "[0.04144517 0.05459396 0.51724666 0.37361106]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8084112405776978\n",
      "loss training = 0.39326074719429016\n",
      "___________________________________\n",
      "Epoch 55\n",
      "[0.03514748 0.0217086  0.31020167 0.5760292 ]\n",
      "[0.04257437 0.06364574 0.5583234  0.33095053]\n",
      "[0.05072337 0.02861977 0.29652768 0.596619  ]\n",
      "[0.04292885 0.0663547  0.56770253 0.32214934]\n",
      "[0.05120136 0.02990835 0.30444133 0.587042  ]\n",
      "[0.04328574 0.06914496 0.57693917 0.3135666 ]\n",
      "[0.05169884 0.03131145 0.3128997  0.57697654]\n",
      "[0.04364855 0.07202777 0.58597916 0.30516857]\n",
      "[0.05221716 0.03283885 0.3219094  0.5664292 ]\n",
      "[0.0440157  0.07499405 0.59478617 0.29698184]\n",
      "[0.05275527 0.03449894 0.33147386 0.5554169 ]\n",
      "[0.04438595 0.07803404 0.60332817 0.28903055]\n",
      "[0.0533123  0.03630004 0.34158853 0.54396546]\n",
      "[0.04481167 0.08121204 0.61150086 0.2813654 ]\n",
      "[0.05389592 0.03825441 0.35222137 0.5321185 ]\n",
      "[0.04524639 0.0844556  0.6193423  0.273982  ]\n",
      "[0.05449709 0.04036413 0.36335573 0.5199219 ]\n",
      "[0.04568153 0.08774161 0.62684417 0.2668916 ]\n",
      "[0.05511292 0.04263373 0.37495717 0.5074301 ]\n",
      "[0.04611557 0.09105626 0.633993   0.26010475]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.827102780342102\n",
      "loss training = 0.3828426003456116\n",
      "___________________________________\n",
      "Epoch 56\n",
      "[0.03357911 0.01730417 0.26264402 0.6353695 ]\n",
      "[0.03995514 0.04748459 0.48562542 0.4024585 ]\n",
      "[0.04739244 0.02113931 0.24310386 0.66904324]\n",
      "[0.03984672 0.04689016 0.4829758  0.4052965 ]\n",
      "[0.0472853  0.02094515 0.24180622 0.67082876]\n",
      "[0.03976099 0.0463524  0.48026147 0.4079431 ]\n",
      "[0.04718981 0.02075789 0.24050385 0.6726022 ]\n",
      "[0.0396756  0.04581564 0.4775133  0.41062537]\n",
      "[0.04709481 0.02057234 0.23920862 0.6743724 ]\n",
      "[0.03958986 0.04527887 0.4747303  0.41334537]\n",
      "[0.04699986 0.02038827 0.23792048 0.6761393 ]\n",
      "[0.03950351 0.04474189 0.47191143 0.416104  ]\n",
      "[0.04690475 0.02020558 0.23663937 0.6779033 ]\n",
      "[0.03941651 0.04420455 0.46905574 0.41890234]\n",
      "[0.04680943 0.02002421 0.23536499 0.6796647 ]\n",
      "[0.03932879 0.04366676 0.46616223 0.42174134]\n",
      "[0.04671384 0.01984411 0.23409724 0.6814235 ]\n",
      "[0.03924033 0.04312855 0.46323    0.42462227]\n",
      "[0.04661801 0.01966526 0.23283595 0.68318015]\n",
      "[0.0391511  0.04258981 0.46025836 0.42754608]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8130841255187988\n",
      "loss training = 0.3907943069934845\n",
      "___________________________________\n",
      "Epoch 57\n",
      "[0.03570382 0.02347134 0.32852778 0.55482876]\n",
      "[0.04291976 0.07039109 0.58498317 0.30280906]\n",
      "[0.05261184 0.0319967  0.3170808  0.57157856]\n",
      "[0.04342517 0.07441735 0.5969507  0.29162607]\n",
      "[0.05328384 0.03417677 0.32991192 0.55657905]\n",
      "[0.04394147 0.07854195 0.6082687  0.2810416 ]\n",
      "[0.05398057 0.03657612 0.3435476  0.540992  ]\n",
      "[0.04445659 0.08272836 0.6189169  0.2710596 ]\n",
      "[0.05469666 0.03920402 0.35793287 0.52491426]\n",
      "[0.04496749 0.08694934 0.62887985 0.26168597]\n",
      "[0.05542834 0.04206774 0.3729872  0.50846267]\n",
      "[0.04547186 0.09117833 0.63815457 0.2529182 ]\n",
      "[0.05617181 0.04517084 0.3886061  0.4917707 ]\n",
      "[0.04596761 0.09538919 0.64674884 0.24474695]\n",
      "[0.05692294 0.04851189 0.40466303 0.47498432]\n",
      "[0.04645281 0.09955644 0.65467906 0.23715712]\n",
      "[0.05767726 0.0520836  0.42101294 0.45825654]\n",
      "[0.04692553 0.10365558 0.6619682  0.23012978]\n",
      "[0.05842997 0.05587212 0.43749723 0.4417419 ]\n",
      "[0.05028313 0.02090692 0.23637515 0.67260337]\n",
      "ABABA1AABBAAB => BABABABABABABABABAAB\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.3874989449977875\n",
      "___________________________________\n",
      "Epoch 58\n",
      "[0.03430378 0.01900635 0.28294957 0.61035675]\n",
      "[0.04075653 0.05502846 0.5251188  0.36042637]\n",
      "[0.04965897 0.02415006 0.26436046 0.64074385]\n",
      "[0.04085789 0.05596485 0.52951723 0.3565593 ]\n",
      "[0.04980972 0.02455884 0.2672045  0.63709575]\n",
      "[0.04099308 0.05701324 0.5338549  0.35239962]\n",
      "[0.04998014 0.02499131 0.27011758 0.6333463 ]\n",
      "[0.04113038 0.05808116 0.53817    0.34826547]\n",
      "[0.05015434 0.0254398  0.27311736 0.62950957]\n",
      "[0.04126889 0.05916648 0.54245734 0.3441628 ]\n",
      "[0.05033174 0.02590439 0.27620432 0.62558687]\n",
      "[0.04140826 0.06026806 0.5467117  0.34009573]\n",
      "[0.05051205 0.02638531 0.27937832 0.62157947]\n",
      "[0.04154835 0.06138488 0.5509281  0.3360683 ]\n",
      "[0.05069514 0.02688283 0.2826389  0.6174895 ]\n",
      "[0.04168898 0.06251587 0.55510193 0.3320845 ]\n",
      "[0.05088093 0.02739719 0.28598544 0.6133192 ]\n",
      "[0.04183004 0.06365999 0.5592285  0.32814804]\n",
      "[0.05106925 0.02792863 0.28941694 0.6090711 ]\n",
      "[0.04197139 0.06481609 0.5633037  0.32426247]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7990654110908508\n",
      "loss training = 0.3981499671936035\n",
      "___________________________________\n",
      "Epoch 59\n",
      "[0.03361116 0.0163025  0.251143   0.6485049 ]\n",
      "[0.03889108 0.04301021 0.46525702 0.41766495]\n",
      "[0.04837979 0.01962513 0.2280871  0.6900594 ]\n",
      "[0.03868709 0.04196989 0.46057427 0.42334986]\n",
      "[0.04820071 0.01932967 0.2261332  0.69293094]\n",
      "[0.03855736 0.04110168 0.45554674 0.42837137]\n",
      "[0.04805668 0.01904733 0.22410627 0.69583094]\n",
      "[0.03842397 0.0402138  0.45028433 0.43363717]\n",
      "[0.04790911 0.01876158 0.222047   0.698795  ]\n",
      "[0.03828562 0.03930477 0.4447786  0.4391648 ]\n",
      "[0.04775733 0.01847241 0.21995758 0.70182216]\n",
      "[0.038142   0.03837494 0.4390206  0.44496587]\n",
      "[0.04760109 0.01818001 0.21784002 0.7049107 ]\n",
      "[0.0379929  0.03742498 0.43300217 0.45105174]\n",
      "[0.04507224 0.09758385 0.65099496 0.2399163 ]\n",
      "[0.05740643 0.05094837 0.4116087  0.47212562]\n",
      "[0.04554493 0.09920946 0.65183616 0.23808138]\n",
      "[0.0576238  0.05164441 0.41428778 0.46918282]\n",
      "[0.04563025 0.09989923 0.6530492  0.23686759]\n",
      "[0.05774485 0.05226871 0.4171217  0.46626535]\n",
      "ABABA1AABBAAB => BABABABABABABBABABAB\n",
      "accuracy training = 0.84112149477005\n",
      "loss training = 0.3646487593650818\n",
      "___________________________________\n",
      "Epoch 60\n",
      "[0.0336674  0.01599472 0.24714199 0.65255284]\n",
      "[0.03851642 0.04100645 0.45598617 0.4241295 ]\n",
      "[0.04866637 0.0191638  0.22359776 0.6963416 ]\n",
      "[0.03826599 0.03967526 0.44931227 0.43199798]\n",
      "[0.04844086 0.01878341 0.22102648 0.70019126]\n",
      "[0.03809124 0.03848813 0.44189715 0.43948692]\n",
      "[0.04503371 0.10183828 0.6652454  0.22507383]\n",
      "[0.05823525 0.05460932 0.4288179  0.45148858]\n",
      "[0.0457562  0.10596751 0.67045605 0.21922891]\n",
      "[0.05887066 0.05789135 0.4426381  0.43733034]\n",
      "[0.05156915 0.02078507 0.22644672 0.68954146]\n",
      "[0.0387015  0.04224551 0.464007   0.4170336 ]\n",
      "[0.04885476 0.01959422 0.22681084 0.69176346]\n",
      "[0.03846812 0.04110313 0.45799074 0.42328778]\n",
      "[0.04866891 0.0192442  0.22436209 0.6953326 ]\n",
      "[0.03831027 0.0399962  0.45130333 0.42999864]\n",
      "[0.04849133 0.01888656 0.2217784  0.69909227]\n",
      "[0.03814075 0.03882865 0.44405347 0.43730533]\n",
      "[0.04830246 0.01851452 0.21908288 0.7030462 ]\n",
      "[0.03795871 0.03760047 0.4362042  0.4452568 ]\n",
      "ABABA1AABBAAB => BABABBABAABABABABABB\n",
      "accuracy training = 0.8528037667274475\n",
      "loss training = 0.36011621356010437\n",
      "___________________________________\n",
      "Epoch 61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03253027 0.01346351 0.21382006 0.6994103 ]\n",
      "[0.03640445 0.02969335 0.3737255  0.51441544]\n",
      "[0.04291693 0.08221175 0.61510587 0.27305633]\n",
      "[0.05467819 0.03810063 0.34226033 0.5512607 ]\n",
      "[0.04276148 0.08040565 0.60976136 0.27771765]\n",
      "[0.05436462 0.03669432 0.3340467  0.5605804 ]\n",
      "[0.04253592 0.0782374  0.60394645 0.28340834]\n",
      "[0.05401023 0.03526978 0.32572526 0.5702182 ]\n",
      "[0.04229862 0.0759771  0.5976383  0.28958318]\n",
      "[0.05364419 0.03385374 0.3172802  0.58011746]\n",
      "[0.04204927 0.07362518 0.59078634 0.29628745]\n",
      "[0.05326651 0.03244979 0.30873212 0.5902624 ]\n",
      "[0.04178709 0.07118056 0.5833347  0.30357754]\n",
      "[0.0528772  0.03106153 0.3001047  0.6006345 ]\n",
      "[0.04151133 0.06864296 0.57522225 0.31151634]\n",
      "[0.05247618 0.02969249 0.291424   0.6112116 ]\n",
      "[0.04122119 0.06601302 0.5663824  0.32017362]\n",
      "[0.05206355 0.02834627 0.28271842 0.62196827]\n",
      "[0.04091587 0.06329258 0.5567434  0.32962656]\n",
      "[0.05163939 0.02702634 0.27401832 0.6328754 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7850467562675476\n",
      "loss training = 0.4015016555786133\n",
      "___________________________________\n",
      "Epoch 62\n",
      "[0.03617798 0.02600072 0.3588826  0.51899666]\n",
      "[0.04251539 0.07882854 0.61828756 0.2647289 ]\n",
      "[0.05507438 0.03622021 0.34548378 0.5383641 ]\n",
      "[0.04296628 0.08309015 0.62922573 0.25479198]\n",
      "[0.05568157 0.03893796 0.36092442 0.52090436]\n",
      "[0.04336769 0.08731101 0.639215   0.2454416 ]\n",
      "[0.05629062 0.04183294 0.3766453  0.5035079 ]\n",
      "[0.04375488 0.09142961 0.64826816 0.23693824]\n",
      "[0.05689352 0.04489249 0.3925339  0.4863178 ]\n",
      "[0.04412615 0.09543052 0.6564721  0.22920135]\n",
      "[0.05748747 0.04810665 0.40847296 0.46944562]\n",
      "[0.04448134 0.09930368 0.66390765 0.22215645]\n",
      "[0.05807033 0.05146328 0.42434767 0.45299184]\n",
      "[0.04482064 0.10304175 0.6706494  0.2157364 ]\n",
      "[0.05864028 0.05494761 0.44004843 0.43704432]\n",
      "[0.05239283 0.02038261 0.23343879 0.6786331 ]\n",
      "[0.03901135 0.04507028 0.48941842 0.3864121 ]\n",
      "[0.0503819  0.02083804 0.24545985 0.6640085 ]\n",
      "[0.03939358 0.04896034 0.51010114 0.36667886]\n",
      "[0.0509239  0.02223407 0.25553674 0.6501389 ]\n",
      "ABABA1AABBAAB => BABABABABABABAABABAB\n",
      "accuracy training = 0.7850467562675476\n",
      "loss training = 0.4302886128425598\n",
      "___________________________________\n",
      "Epoch 63\n",
      "[0.03440049 0.01882206 0.2852318  0.60775214]\n",
      "[0.03988528 0.05593005 0.5354116  0.34492353]\n",
      "[0.05183184 0.02406876 0.2613768  0.6461019 ]\n",
      "[0.03993244 0.05644117 0.5383621  0.34292266]\n",
      "[0.05189952 0.02434048 0.263416   0.64351636]\n",
      "[0.04000764 0.05714671 0.5412717  0.34010488]\n",
      "[0.05199656 0.02462984 0.2654225  0.6408967 ]\n",
      "[0.04008702 0.05785237 0.54410285 0.3373578 ]\n",
      "[0.05209421 0.02492059 0.26742426 0.63829225]\n",
      "[0.04016549 0.05855108 0.5468629  0.33468246]\n",
      "[0.0521911  0.02521195 0.26942128 0.63570446]\n",
      "[0.04024272 0.05924213 0.54955304 0.33207732]\n",
      "[0.05228701 0.02550372 0.27141258 0.63313425]\n",
      "[0.04031864 0.05992526 0.55217445 0.32954085]\n",
      "[0.05238186 0.02579572 0.27339715 0.63058263]\n",
      "[0.04039321 0.06060014 0.5547283  0.32707152]\n",
      "[0.05247561 0.02608779 0.27537385 0.6280509 ]\n",
      "[0.04046644 0.06126663 0.557216   0.32466793]\n",
      "[0.05256826 0.02637979 0.27734184 0.62553984]\n",
      "[0.04053831 0.06192453 0.55963874 0.32232848]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8060747385025024\n",
      "loss training = 0.3899957239627838\n",
      "___________________________________\n",
      "Epoch 64\n",
      "[0.03391595 0.0164047  0.25590646 0.64299124]\n",
      "[0.03846988 0.04525425 0.48380467 0.39435282]\n",
      "[0.0507415  0.01992637 0.22850454 0.69109046]\n",
      "[0.03828011 0.04419807 0.47994834 0.39985472]\n",
      "[0.05058418 0.01966001 0.2267946  0.6936671 ]\n",
      "[0.03818043 0.04345896 0.47595772 0.40387678]\n",
      "[0.05048313 0.01942068 0.2250323  0.6961762 ]\n",
      "[0.03808825 0.04272478 0.47185585 0.40800264]\n",
      "[0.05038337 0.01918296 0.22326922 0.69869506]\n",
      "[0.03799798 0.04198877 0.4676481  0.41224307]\n",
      "[0.05028328 0.01894629 0.22150725 0.70122373]\n",
      "[0.03790887 0.04125033 0.4633331  0.41660053]\n",
      "[0.05018265 0.01871064 0.219747   0.7037616 ]\n",
      "[0.03781822 0.04050735 0.4589136  0.4210758 ]\n",
      "[0.05008094 0.0184759  0.21798947 0.70630777]\n",
      "[0.03772603 0.03976015 0.45438763 0.42567173]\n",
      "[0.04997813 0.01824209 0.21623537 0.7088617 ]\n",
      "[0.03763228 0.03900901 0.4497538  0.43039107]\n",
      "[0.04987423 0.01800931 0.21448527 0.7114228 ]\n",
      "[0.0375369  0.03825427 0.4450108  0.43523628]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8621495366096497\n",
      "loss training = 0.3599753975868225\n",
      "___________________________________\n",
      "Epoch 65\n",
      "[0.0341722  0.01668511 0.25950617 0.636814  ]\n",
      "[0.03850048 0.04635805 0.4932076  0.3818514 ]\n",
      "[0.05145172 0.02055596 0.23330764 0.683554  ]\n",
      "[0.03842829 0.04582305 0.4918207  0.3847608 ]\n",
      "[0.05137053 0.02044417 0.23269723 0.6845514 ]\n",
      "[0.03838949 0.04553699 0.4903444  0.38623866]\n",
      "[0.05133362 0.02035042 0.2320133  0.68552434]\n",
      "[0.03835663 0.04524555 0.48877144 0.38779995]\n",
      "[0.05129702 0.0202531  0.2312949  0.68654585]\n",
      "[0.03832251 0.04493993 0.48710746 0.38945353]\n",
      "[0.05125879 0.0201514  0.23054245 0.6876178 ]\n",
      "[0.03828664 0.04461916 0.48534772 0.39120468]\n",
      "[0.05121867 0.02004509 0.22975478 0.688742  ]\n",
      "[0.03824885 0.04428243 0.48348624 0.3930593 ]\n",
      "[0.05117652 0.019934   0.22893068 0.68992054]\n",
      "[0.03820899 0.04392906 0.48151708 0.39502376]\n",
      "[0.0511322  0.01981797 0.22806896 0.69115573]\n",
      "[0.03816694 0.04355834 0.47943395 0.3971048 ]\n",
      "[0.05108562 0.01969684 0.22716829 0.6924496 ]\n",
      "[0.0381226  0.0431696  0.47723013 0.39930966]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8574766516685486\n",
      "loss training = 0.3589800298213959\n",
      "___________________________________\n",
      "Epoch 66\n",
      "[0.03367052 0.01454226 0.22851136 0.68100625]\n",
      "[0.03705681 0.03698282 0.4322383  0.44934687]\n",
      "[0.04251252 0.09477974 0.6488429  0.23470636]\n",
      "[0.05796868 0.04828664 0.39717337 0.49118796]\n",
      "[0.04278983 0.09403252 0.64529824 0.23771514]\n",
      "[0.05783606 0.04697327 0.39018917 0.49860713]\n",
      "[0.0426777  0.09251853 0.6420596  0.24089928]\n",
      "[0.05762139 0.04560405 0.38317057 0.5062312 ]\n",
      "[0.04255249 0.09094188 0.63865    0.24426395]\n",
      "[0.05740013 0.04424154 0.37605846 0.51402634]\n",
      "[0.04242291 0.08932079 0.6350489  0.24781421]\n",
      "[0.05717421 0.04288985 0.36886433 0.5219809 ]\n",
      "[0.04228907 0.08765625 0.6312462  0.2515599 ]\n",
      "[0.05694382 0.04155165 0.36160254 0.5300827 ]\n",
      "[0.04215088 0.08594897 0.6272308  0.2555115 ]\n",
      "[0.05670913 0.04022953 0.3542884  0.538318  ]\n",
      "[0.04200825 0.08419996 0.622992   0.25967968]\n",
      "[0.05647034 0.03892601 0.34693804 0.54667187]\n",
      "[0.04186114 0.08241048 0.6185183  0.26407573]\n",
      "[0.05622767 0.03764349 0.33956796 0.55512834]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7710280418395996\n",
      "loss training = 0.4147924482822418\n",
      "___________________________________\n",
      "Epoch 67\n",
      "[0.03550426 0.02304658 0.33297634 0.5468555 ]\n",
      "[0.04043807 0.07133383 0.599965   0.2764867 ]\n",
      "[0.05510439 0.03126898 0.3131987  0.5781342 ]\n",
      "[0.04062575 0.07462457 0.61137515 0.2670044 ]\n",
      "[0.05546661 0.03329797 0.3263508  0.5624816 ]\n",
      "[0.04092178 0.07839952 0.62196165 0.25712273]\n",
      "[0.05589008 0.0355233  0.3399871  0.54643226]\n",
      "[0.04121584 0.0821704  0.6317991  0.24793412]\n",
      "[0.05631771 0.03791359 0.3541168  0.53013974]\n",
      "[0.04150622 0.08592187 0.64093095 0.23939832]\n",
      "[0.05674769 0.04047374 0.36868632 0.513681  ]\n",
      "[0.04179251 0.08964444 0.64940184 0.2314676 ]\n",
      "[0.05717906 0.04320817 0.38363472 0.4971351 ]\n",
      "[0.04207446 0.09332973 0.65725636 0.22409664]\n",
      "[0.05761085 0.04612006 0.39889398 0.480583  ]\n",
      "[0.04235179 0.09697016 0.6645379  0.21724302]\n",
      "[0.05804209 0.04921094 0.41438985 0.46410722]\n",
      "[0.04262433 0.10055873 0.6712872  0.21086787]\n",
      "[0.05847177 0.05248028 0.4300423  0.4477899 ]\n",
      "[0.04289171 0.10408849 0.6775423  0.2049358 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.4045288860797882\n",
      "___________________________________\n",
      "Epoch 68\n",
      "[0.03487216 0.01891335 0.28412375 0.6098852 ]\n",
      "[0.03881047 0.05618358 0.5352538  0.34254685]\n",
      "[0.05405389 0.02411189 0.25815055 0.65478677]\n",
      "[0.03936798 0.05738163 0.53833145 0.34056285]\n",
      "[0.05422516 0.02458172 0.26138842 0.6507087 ]\n",
      "[0.03946041 0.05838392 0.5422695  0.33665523]\n",
      "[0.05434933 0.02504168 0.26462784 0.6465806 ]\n",
      "[0.03954758 0.05935432 0.5460096  0.33294427]\n",
      "[0.05447    0.02549673 0.26780936 0.6425484 ]\n",
      "[0.03963158 0.06029367 0.5495567  0.3294276 ]\n",
      "[0.05458712 0.02594624 0.27092993 0.63861436]\n",
      "[0.03971231 0.06120214 0.55292094 0.32609415]\n",
      "[0.05470058 0.0263897  0.2739873  0.6347796 ]\n",
      "[0.03978981 0.06208014 0.5561124  0.3229334 ]\n",
      "[0.05481043 0.02682668 0.27697957 0.63104475]\n",
      "[0.03986419 0.06292822 0.5591407  0.31993556]\n",
      "[0.05491667 0.02725681 0.27990538 0.6274102 ]\n",
      "[0.03993558 0.06374706 0.5620147  0.3170911 ]\n",
      "[0.05501945 0.0276798  0.28276357 0.6238758 ]\n",
      "[0.04000408 0.06453732 0.5647432  0.31439137]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7383177280426025\n",
      "loss training = 0.4565008580684662\n",
      "___________________________________\n",
      "Epoch 69\n",
      "[0.03388018 0.01576053 0.24847849 0.65396744]\n",
      "[0.03746067 0.04460184 0.47938254 0.39790636]\n",
      "[0.05217692 0.01895273 0.21850261 0.708644  ]\n",
      "[0.03723441 0.04357865 0.47683537 0.4030464 ]\n",
      "[0.05203045 0.01875519 0.2173743  0.71047   ]\n",
      "[0.03718918 0.04313691 0.47443712 0.4055245 ]\n",
      "[0.05197847 0.01860452 0.21620105 0.7120989 ]\n",
      "[0.03714668 0.04270598 0.47203884 0.4079802 ]\n",
      "[0.05192837 0.01845703 0.21504492 0.71370554]\n",
      "[0.03710459 0.04227941 0.46963874 0.41044107]\n",
      "[0.05187884 0.01831208 0.21390618 0.71529204]\n",
      "[0.03706275 0.04185695 0.4672365  0.41290736]\n",
      "[0.05182975 0.01816957 0.21278447 0.71685886]\n",
      "[0.0370211  0.04143849 0.46483225 0.41537905]\n",
      "[0.05178107 0.01802943 0.21167946 0.7184064 ]\n",
      "[0.03697965 0.04102397 0.46242583 0.41785613]\n",
      "[0.05173275 0.01789158 0.21059066 0.71993506]\n",
      "[0.03693836 0.0406133  0.46001726 0.42033866]\n",
      "[0.05168477 0.01775594 0.20951767 0.72144544]\n",
      "[0.03689724 0.04020639 0.45760658 0.4228268 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8785046935081482\n",
      "loss training = 0.3547649085521698\n",
      "___________________________________\n",
      "Epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03408876 0.0157769  0.24971083 0.64868504]\n",
      "[0.03740486 0.04445551 0.4827265  0.3897463 ]\n",
      "[0.05274075 0.01914113 0.22088365 0.703095  ]\n",
      "[0.03721017 0.04376985 0.48208946 0.39296147]\n",
      "[0.05263226 0.01905905 0.22065592 0.7036694 ]\n",
      "[0.03719777 0.04365706 0.48150125 0.39358258]\n",
      "[0.05261933 0.01902227 0.22037475 0.7040666 ]\n",
      "[0.03718771 0.0435474  0.4808904  0.39419934]\n",
      "[0.05260757 0.01898488 0.22008249 0.7044765 ]\n",
      "[0.03717754 0.04343384 0.4802545  0.3948417 ]\n",
      "[0.05259557 0.01894618 0.21977936 0.70490205]\n",
      "[0.03716703 0.043316   0.47959238 0.395511  ]\n",
      "[0.05258317 0.0189061  0.21946493 0.7053437 ]\n",
      "[0.03715611 0.04319366 0.47890285 0.39620838]\n",
      "[0.05257034 0.01886457 0.21913897 0.7058021 ]\n",
      "[0.03714481 0.04306668 0.47818488 0.396935  ]\n",
      "[0.05255702 0.01882155 0.21880099 0.70627755]\n",
      "[0.03713303 0.04293482 0.4774372  0.397692  ]\n",
      "[0.05254317 0.01877698 0.21845074 0.7067707 ]\n",
      "[0.03712083 0.04279799 0.4766585  0.39848074]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8621495366096497\n",
      "loss training = 0.36063599586486816\n",
      "___________________________________\n",
      "Epoch 71\n",
      "[0.03425338 0.01425871 0.22303133 0.68684375]\n",
      "[0.03639051 0.03703909 0.4334023  0.44480303]\n",
      "[0.04074278 0.09233358 0.6424406  0.2355288 ]\n",
      "[0.05882399 0.04773822 0.3934678  0.49793428]\n",
      "[0.0410331  0.09143384 0.6391163  0.23908214]\n",
      "[0.05873158 0.04659622 0.38746715 0.50447243]\n",
      "[0.04096059 0.09023011 0.636478   0.24171208]\n",
      "[0.05858913 0.0454325  0.38140222 0.51108116]\n",
      "[0.04088245 0.0889851  0.63370615 0.24447465]\n",
      "[0.0584426  0.04426723 0.37522835 0.51785636]\n",
      "[0.0408017  0.08770277 0.63078815 0.24738117]\n",
      "[0.05829244 0.04310291 0.36895448 0.5247907 ]\n",
      "[0.04071827 0.08638337 0.6277168  0.25043815]\n",
      "[0.05813878 0.04194187 0.3625914  0.5318757 ]\n",
      "[0.04063208 0.08502733 0.62448525 0.25365254]\n",
      "[0.05798159 0.04078634 0.3561506  0.5391013 ]\n",
      "[0.04054314 0.08363524 0.6210863  0.25703123]\n",
      "[0.05782108 0.03963876 0.3496449  0.54645616]\n",
      "[0.04045141 0.08220797 0.61751294 0.2605814 ]\n",
      "[0.05765732 0.03850137 0.34308743 0.55392784]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8014018535614014\n",
      "loss training = 0.38093870878219604\n",
      "___________________________________\n",
      "Epoch 72\n",
      "[0.03469135 0.0197701  0.3012348  0.58209705]\n",
      "[0.03844736 0.06119995 0.56518775 0.30432793]\n",
      "[0.05513932 0.02576656 0.27449068 0.62847745]\n",
      "[0.03844812 0.06319724 0.5756191  0.29675752]\n",
      "[0.05529298 0.02702011 0.28389913 0.61679673]\n",
      "[0.03864156 0.06606782 0.5857296  0.2871938 ]\n",
      "[0.05555252 0.02843739 0.29375038 0.60445935]\n",
      "[0.03883896 0.06899604 0.5954186  0.27803695]\n",
      "[0.05581879 0.02996619 0.30412602 0.5916668 ]\n",
      "[0.03903792 0.07196812 0.60468477 0.2692996 ]\n",
      "[0.05609034 0.03161386 0.31503063 0.5784369 ]\n",
      "[0.03923822 0.07497882 0.6135324  0.26097003]\n",
      "[0.05636688 0.03338898 0.32646447 0.56479025]\n",
      "[0.03943968 0.07802342 0.6219689  0.25303447]\n",
      "[0.05664822 0.03530054 0.33842373 0.5507517 ]\n",
      "[0.03964225 0.0810975  0.630004   0.24547794]\n",
      "[0.05693417 0.03735792 0.35089958 0.53635144]\n",
      "[0.03984585 0.08419684 0.6376495  0.23828487]\n",
      "[0.05722456 0.03957072 0.36387762 0.5216254 ]\n",
      "[0.04005036 0.08731718 0.6449177  0.23143958]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7897196412086487\n",
      "loss training = 0.4036185145378113\n",
      "___________________________________\n",
      "Epoch 73\n",
      "[0.03452104 0.01768102 0.2720517  0.62258166]\n",
      "[0.03746405 0.05238481 0.5188005  0.35420612]\n",
      "[0.0551394  0.02199355 0.24123618 0.67862743]\n",
      "[0.03765194 0.05296512 0.52279466 0.3528563 ]\n",
      "[0.0552057  0.02244289 0.24492675 0.6741307 ]\n",
      "[0.03772187 0.05405581 0.5275896  0.34808168]\n",
      "[0.05531921 0.02294027 0.24863215 0.66935205]\n",
      "[0.03779991 0.05514684 0.5321865  0.3434752 ]\n",
      "[0.05543398 0.02344347 0.25233942 0.66459495]\n",
      "[0.03787645 0.05622005 0.5365988  0.33905876]\n",
      "[0.05554706 0.02395075 0.25604653 0.6598664 ]\n",
      "[0.03795107 0.05727443 0.5408336  0.33482447]\n",
      "[0.05565824 0.02446159 0.2597498  0.6551702 ]\n",
      "[0.03802373 0.05830959 0.54489803 0.33076432]\n",
      "[0.05576746 0.02497558 0.26344585 0.65051013]\n",
      "[0.03809448 0.05932534 0.54879916 0.3268703 ]\n",
      "[0.05587476 0.02549232 0.26713142 0.64588946]\n",
      "[0.03816336 0.06032156 0.5525439  0.3231348 ]\n",
      "[0.05598006 0.02601142 0.2708035  0.6413109 ]\n",
      "[0.03823036 0.06129823 0.5561391  0.3195503 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7336448431015015\n",
      "loss training = 0.46138623356819153\n",
      "___________________________________\n",
      "Epoch 74\n",
      "[0.0339373  0.01519777 0.24067076 0.6637458 ]\n",
      "[0.03643912 0.04331129 0.47130936 0.4038964 ]\n",
      "[0.05401556 0.017938   0.20656921 0.72698224]\n",
      "[0.03632424 0.04221069 0.46843582 0.41046053]\n",
      "[0.05387721 0.01775526 0.20558113 0.72871447]\n",
      "[0.03628069 0.04184029 0.46648657 0.41254568]\n",
      "[0.05383666 0.01763087 0.20459652 0.7300756 ]\n",
      "[0.03625329 0.04149825 0.46454138 0.41457123]\n",
      "[0.05380121 0.01751105 0.20363127 0.73140544]\n",
      "[0.03622692 0.04116282 0.4626126  0.41658074]\n",
      "[0.05376659 0.01739416 0.20268714 0.7327085 ]\n",
      "[0.03620094 0.04083313 0.46070102 0.41857457]\n",
      "[0.05373256 0.01728    0.20176376 0.73398554]\n",
      "[0.03617533 0.04050902 0.45880625 0.42055282]\n",
      "[0.05369904 0.01716848 0.2008604  0.7352372 ]\n",
      "[0.03615    0.0401903  0.45692822 0.42251548]\n",
      "[0.05366606 0.01705952 0.19997646 0.7364643 ]\n",
      "[0.03612497 0.03987689 0.45506686 0.42446274]\n",
      "[0.05363354 0.01695302 0.19911137 0.7376675 ]\n",
      "[0.03610023 0.03956863 0.453222   0.42639467]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8598130941390991\n",
      "loss training = 0.35791927576065063\n",
      "___________________________________\n",
      "Epoch 75\n",
      "[0.03393745 0.01501801 0.24060059 0.6596481 ]\n",
      "[0.03635404 0.04271559 0.4723809  0.39748263]\n",
      "[0.05427257 0.0178673  0.20763573 0.7228141 ]\n",
      "[0.03609623 0.04185337 0.47212997 0.40160492]\n",
      "[0.05413585 0.01781078 0.20777047 0.723024  ]\n",
      "[0.03609477 0.04188123 0.4723595  0.40142065]\n",
      "[0.05413687 0.0178237  0.20788547 0.7228687 ]\n",
      "[0.03609751 0.04192307 0.47260305 0.40117064]\n",
      "[0.0541404  0.01783816 0.20800354 0.7227038 ]\n",
      "[0.03610058 0.04196655 0.47285402 0.40091288]\n",
      "[0.05414424 0.01785313 0.2081252  0.7225339 ]\n",
      "[0.03610381 0.04201139 0.47311223 0.40064776]\n",
      "[0.05414826 0.01786859 0.20825061 0.7223588 ]\n",
      "[0.03610716 0.0420576  0.47337785 0.40037516]\n",
      "[0.05415242 0.01788451 0.20837973 0.7221785 ]\n",
      "[0.03611062 0.04210521 0.47365114 0.40009478]\n",
      "[0.05415672 0.01790094 0.20851289 0.7219928 ]\n",
      "[0.03611421 0.04215426 0.47393224 0.3998065 ]\n",
      "[0.05416116 0.01791786 0.20865004 0.7218014 ]\n",
      "[0.03611789 0.04220477 0.47422138 0.39951003]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8644859790802002\n",
      "loss training = 0.35776934027671814\n",
      "___________________________________\n",
      "Epoch 76\n",
      "[0.03416524 0.01306626 0.2081569  0.7043978 ]\n",
      "[0.03532059 0.03289957 0.40533432 0.47111067]\n",
      "[0.03879037 0.0850004  0.6255788  0.24773242]\n",
      "[0.05901091 0.04156988 0.35993215 0.53710955]\n",
      "[0.03895199 0.08349001 0.62195146 0.25264862]\n",
      "[0.05890651 0.04063374 0.35488942 0.54304475]\n",
      "[0.03889515 0.08246174 0.6194536  0.2551696 ]\n",
      "[0.05880912 0.03974278 0.34979695 0.5487992 ]\n",
      "[0.03884172 0.08142084 0.6168332  0.25778908]\n",
      "[0.0587109  0.03884917 0.34461033 0.5546894 ]\n",
      "[0.03878683 0.08034859 0.61407894 0.2605409 ]\n",
      "[0.05861008 0.0379522  0.33933318 0.56071806]\n",
      "[0.03873008 0.0792436  0.61118245 0.26343372]\n",
      "[0.05850651 0.0370527  0.33396906 0.5668837 ]\n",
      "[0.03867139 0.07810501 0.6081349  0.26647645]\n",
      "[0.05840013 0.03615163 0.32852188 0.573184  ]\n",
      "[0.03861069 0.07693215 0.6049269  0.26967862]\n",
      "[0.05829085 0.03524994 0.32299617 0.5796163 ]\n",
      "[0.03854786 0.07572429 0.6015479  0.27305052]\n",
      "[0.05817865 0.03434874 0.3173971  0.5861769 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8317757248878479\n",
      "loss training = 0.36600202322006226\n",
      "___________________________________\n",
      "Epoch 77\n",
      "[0.03419083 0.01795591 0.28294402 0.60110664]\n",
      "[0.03700864 0.05552343 0.54331285 0.32051435]\n",
      "[0.0561079  0.02280864 0.25139493 0.6592842 ]\n",
      "[0.0368889  0.05689205 0.55368173 0.31411204]\n",
      "[0.05615332 0.02381102 0.25966454 0.64887923]\n",
      "[0.0370349  0.05952708 0.564279   0.30401772]\n",
      "[0.05634618 0.02500544 0.26853845 0.637418  ]\n",
      "[0.03718944 0.06228084 0.5746683  0.29412714]\n",
      "[0.05654843 0.02631827 0.27808967 0.62525606]\n",
      "[0.03734885 0.06513494 0.5848117  0.28450918]\n",
      "[0.05675797 0.02776054 0.28835428 0.6123831 ]\n",
      "[0.03751294 0.06808497 0.5946796  0.27518335]\n",
      "[0.05697464 0.02934544 0.2993631  0.598793  ]\n",
      "[0.03768159 0.07112582 0.6042452  0.26616606]\n",
      "[0.05719832 0.03108696 0.31113997 0.58449054]\n",
      "[0.03785463 0.07425129 0.6134848  0.25747126]\n",
      "[0.05742879 0.03299961 0.32369882 0.56949407]\n",
      "[0.03803192 0.07745402 0.6223776  0.24911062]\n",
      "[0.05766581 0.0350981  0.3370409  0.5538382 ]\n",
      "[0.03821319 0.08072522 0.6309058  0.2410938 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7873831987380981\n",
      "loss training = 0.40631020069122314\n",
      "___________________________________\n",
      "Epoch 78\n",
      "[0.034162   0.01558311 0.24892148 0.6475799 ]\n",
      "[0.03602938 0.04515681 0.48433888 0.38386336]\n",
      "[0.05626795 0.01859958 0.21344937 0.7161134 ]\n",
      "[0.03610424 0.04511499 0.48747522 0.38505024]\n",
      "[0.05624932 0.01886412 0.21608794 0.71303076]\n",
      "[0.03614099 0.04598332 0.49213532 0.38038734]\n",
      "[0.05632424 0.01921478 0.21889381 0.7092834 ]\n",
      "[0.03619456 0.04690062 0.4967906  0.37566322]\n",
      "[0.05640578 0.01958282 0.22180316 0.7054079 ]\n",
      "[0.03624952 0.04783859 0.50144196 0.37095213]\n",
      "[0.05648905 0.01996687 0.22482106 0.7014082 ]\n",
      "[0.03630517 0.04879628 0.5060865  0.36625788]\n",
      "[0.05657381 0.02036767 0.2279518  0.6972809 ]\n",
      "[0.03636147 0.04977361 0.5107211  0.36158335]\n",
      "[0.05666006 0.02078606 0.23119953 0.6930224 ]\n",
      "[0.03641836 0.05077052 0.5153422  0.35693124]\n",
      "[0.05674775 0.02122291 0.23456837 0.68862903]\n",
      "[0.03647585 0.05178697 0.5199467  0.35230428]\n",
      "[0.05683692 0.0216792  0.23806262 0.6840973 ]\n",
      "[0.03653392 0.05282285 0.52453125 0.34770522]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7336448431015015\n",
      "loss training = 0.46243980526924133\n",
      "___________________________________\n",
      "Epoch 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03379875 0.01321824 0.2148953  0.69464296]\n",
      "[0.03502495 0.03544115 0.42184827 0.4529335 ]\n",
      "[0.03796334 0.08344041 0.61269045 0.257522  ]\n",
      "[0.05975948 0.04297459 0.3692233  0.5339767 ]\n",
      "[0.03778079 0.08091752 0.6093491  0.2636793 ]\n",
      "[0.0595769  0.04207079 0.36518684 0.5390054 ]\n",
      "[0.03772789 0.0801632  0.60764354 0.26551282]\n",
      "[0.05950736 0.04134083 0.36118084 0.54341227]\n",
      "[0.03769236 0.07945535 0.6058968  0.26732334]\n",
      "[0.05944249 0.04062023 0.35715207 0.5478484 ]\n",
      "[0.03765702 0.07873954 0.60410154 0.2691812 ]\n",
      "[0.05937715 0.03990439 0.3531044  0.5523236 ]\n",
      "[0.03762124 0.07801423 0.60225683 0.2710888 ]\n",
      "[0.05931107 0.03919351 0.34904    0.556836  ]\n",
      "[0.03758494 0.07727931 0.60036117 0.2730477 ]\n",
      "[0.05924423 0.0384879  0.34496123 0.5613836 ]\n",
      "[0.03754813 0.07653484 0.5984131  0.27505922]\n",
      "[0.05917665 0.03778789 0.3408704  0.5659641 ]\n",
      "[0.03751079 0.07578091 0.59641135 0.27712473]\n",
      "[0.05910832 0.03709385 0.33676994 0.5705752 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8247663378715515\n",
      "loss training = 0.37326398491859436\n",
      "___________________________________\n",
      "Epoch 80\n",
      "[0.0338415  0.01553327 0.24998361 0.6446991 ]\n",
      "[0.0356928  0.04603868 0.49106282 0.37399995]\n",
      "[0.05644449 0.01856733 0.21320234 0.71503896]\n",
      "[0.03542848 0.04587919 0.49648613 0.37362245]\n",
      "[0.05635643 0.01893683 0.21701771 0.71046674]\n",
      "[0.03549375 0.04713412 0.5029621  0.36716267]\n",
      "[0.05644712 0.01943567 0.22104977 0.70506823]\n",
      "[0.03556641 0.04844867 0.50943726 0.36064687]\n",
      "[0.05654329 0.01996541 0.2252831  0.69943064]\n",
      "[0.03564097 0.0498006  0.5158854  0.35417774]\n",
      "[0.05664185 0.02052626 0.22972697 0.69355524]\n",
      "[0.03571723 0.05118927 0.5222977  0.34776363]\n",
      "[0.05674265 0.02112026 0.23439115 0.68743396]\n",
      "[0.03579517 0.05261447 0.5286656  0.34141138]\n",
      "[0.05684569 0.02174962 0.2392855  0.68105894]\n",
      "[0.03587481 0.05407596 0.53498095 0.33512753]\n",
      "[0.05695101 0.02241671 0.24441995 0.6744229 ]\n",
      "[0.03595614 0.05557329 0.54123557 0.32891846]\n",
      "[0.05705853 0.02312402 0.24980411 0.667519  ]\n",
      "[0.03603915 0.05710595 0.5474216  0.32279015]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8481308221817017\n",
      "loss training = 0.36451321840286255\n",
      "___________________________________\n",
      "Epoch 81\n",
      "[0.03384643 0.01332144 0.21600042 0.69198734]\n",
      "[0.03479912 0.03639483 0.42831647 0.44384   ]\n",
      "[0.03751056 0.08488608 0.61641353 0.2519625 ]\n",
      "[0.06037337 0.04399722 0.3735651  0.52870107]\n",
      "[0.03737453 0.08245362 0.613671   0.25788206]\n",
      "[0.06022719 0.04354231 0.3721605  0.5309733 ]\n",
      "[0.03734414 0.08216098 0.61313224 0.2585162 ]\n",
      "[0.06020258 0.04329417 0.370858   0.5324078 ]\n",
      "[0.03733312 0.08193444 0.61260015 0.2590674 ]\n",
      "[0.06018401 0.04305176 0.36954612 0.53383744]\n",
      "[0.03732281 0.08170813 0.61206114 0.25962394]\n",
      "[0.06016556 0.04280896 0.36822593 0.53527766]\n",
      "[0.03731249 0.08147996 0.6115151  0.26018766]\n",
      "[0.06014703 0.04256558 0.3668974  0.5367289 ]\n",
      "[0.03730214 0.08124989 0.61096203 0.26075882]\n",
      "[0.06012838 0.04232159 0.36556068 0.5381912 ]\n",
      "[0.03729171 0.08101781 0.6104016  0.2613375 ]\n",
      "[0.06010957 0.04207701 0.36421567 0.53966457]\n",
      "[0.03728118 0.08078368 0.6098337  0.26192364]\n",
      "[0.06009061 0.04183184 0.3628624  0.5411489 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7663551568984985\n",
      "loss training = 0.4095052182674408\n",
      "___________________________________\n",
      "Epoch 82\n",
      "[0.03367295 0.01445634 0.23405288 0.66602886]\n",
      "[0.03503883 0.0421177  0.4674036  0.3983364 ]\n",
      "[0.05685813 0.0167825  0.19474235 0.74121046]\n",
      "[0.03477853 0.04135286 0.46973896 0.40182388]\n",
      "[0.05672381 0.0169165  0.1966768  0.7391773 ]\n",
      "[0.03478398 0.04200391 0.47375602 0.39779496]\n",
      "[0.05676413 0.01716421 0.19876643 0.7363244 ]\n",
      "[0.03481444 0.04271508 0.47779992 0.3936308 ]\n",
      "[0.05681309 0.01742536 0.20093343 0.73336303]\n",
      "[0.03484644 0.04344582 0.48187393 0.3894432 ]\n",
      "[0.05686346 0.01769759 0.20318267 0.73030084]\n",
      "[0.03487905 0.04419517 0.48597652 0.38523594]\n",
      "[0.05691485 0.01798134 0.20551787 0.7271344 ]\n",
      "[0.03491221 0.04496338 0.4901058  0.38101122]\n",
      "[0.05696731 0.01827723 0.20794274 0.7238599 ]\n",
      "[0.03494594 0.04575072 0.4942594  0.3767711 ]\n",
      "[0.05702078 0.01858587 0.21046115 0.7204733 ]\n",
      "[0.03498018 0.04655745 0.49843505 0.37251776]\n",
      "[0.05707531 0.01890795 0.21307713 0.71697044]\n",
      "[0.03502143 0.04739022 0.5026172  0.36826047]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8878504633903503\n",
      "loss training = 0.35093414783477783\n",
      "___________________________________\n",
      "Epoch 83\n",
      "[0.03391914 0.01253514 0.20255381 0.7100239 ]\n",
      "[0.03423624 0.03301581 0.40507147 0.46800125]\n",
      "[0.03675661 0.08187942 0.6117693  0.25600705]\n",
      "[0.06058201 0.0397387  0.3465103  0.5576105 ]\n",
      "[0.03688139 0.07923817 0.6067883  0.26406655]\n",
      "[0.06045997 0.03879786 0.34185106 0.5635811 ]\n",
      "[0.03683401 0.07835288 0.6046396  0.26633766]\n",
      "[0.06039716 0.03802415 0.3373371  0.56869847]\n",
      "[0.0367997  0.07751205 0.6024465  0.2685813 ]\n",
      "[0.06033828 0.03726007 0.33279765 0.5738527 ]\n",
      "[0.03676546 0.07665937 0.6001816  0.27089584]\n",
      "[0.06027872 0.0365013  0.3282356  0.57905704]\n",
      "[0.03673067 0.07579317 0.5978421  0.2732856 ]\n",
      "[0.06021825 0.03574814 0.32365423 0.58430856]\n",
      "[0.03669532 0.07491345 0.59542555 0.27575338]\n",
      "[0.06015689 0.03500107 0.31905693 0.589604  ]\n",
      "[0.03665939 0.07402019 0.592929   0.27830172]\n",
      "[0.06009461 0.03426052 0.31444693 0.5949402 ]\n",
      "[0.03662283 0.07311347 0.59034985 0.28093374]\n",
      "[0.06003138 0.03352697 0.3098278  0.6003135 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.3766673505306244\n",
      "___________________________________\n",
      "Epoch 84\n",
      "[0.03344698 0.01548236 0.25058356 0.6424903 ]\n",
      "[0.03498831 0.0474363  0.50049305 0.36068696]\n",
      "[0.05761186 0.0185277  0.21050364 0.7173793 ]\n",
      "[0.034691   0.0474413  0.50807786 0.35903373]\n",
      "[0.05751216 0.0190879  0.2160468  0.7105792 ]\n",
      "[0.03476695 0.04925721 0.5171103  0.35008663]\n",
      "[0.05761429 0.01982419 0.22202478 0.70258105]\n",
      "[0.03485226 0.05116685 0.5260688  0.3411598 ]\n",
      "[0.05772268 0.02061948 0.22838777 0.6941381 ]\n",
      "[0.03494047 0.05313934 0.5349069  0.33239087]\n",
      "[0.05783368 0.02147639 0.23515548 0.68524796]\n",
      "[0.03503142 0.05517287 0.5436052  0.32379574]\n",
      "[0.0579471  0.02240005 0.24234846 0.6758965 ]\n",
      "[0.03512504 0.05726582 0.5521457  0.3153871 ]\n",
      "[0.0580629  0.02339602 0.24998635 0.6660723 ]\n",
      "[0.03522136 0.05941633 0.560512   0.30717632]\n",
      "[0.05818101 0.02447015 0.25808713 0.6557668 ]\n",
      "[0.03532035 0.06162213 0.56868875 0.29917368]\n",
      "[0.05830136 0.0256286  0.26666665 0.6449753 ]\n",
      "[0.03542197 0.06388052 0.57666165 0.2913881 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.84112149477005\n",
      "loss training = 0.37090668082237244\n",
      "___________________________________\n",
      "Epoch 85\n",
      "[0.03349737 0.01332281 0.2176099  0.68891037]\n",
      "[0.03420176 0.0379569  0.43934968 0.4291259 ]\n",
      "[0.05795991 0.01484123 0.1745045  0.77110416]\n",
      "[0.03424738 0.03674936 0.4371754  0.43838695]\n",
      "[0.03644913 0.08683796 0.6227991  0.24363668]\n",
      "[0.0610284  0.04550777 0.38144967 0.52033263]\n",
      "[0.03615463 0.08441614 0.6215606  0.24836214]\n",
      "[0.06088905 0.04582483 0.38445687 0.51798415]\n",
      "[0.03617487 0.08488845 0.622672   0.24728367]\n",
      "[0.06091823 0.04642937 0.3876366  0.51458657]\n",
      "[0.03620204 0.085423   0.6238223  0.24608992]\n",
      "[0.06095108 0.0470474  0.3908284  0.5111673 ]\n",
      "[0.03622936 0.08595802 0.62496    0.2449069 ]\n",
      "[0.06098399 0.04767264 0.39402714 0.5077506 ]\n",
      "[0.03625667 0.08649189 0.6260839  0.24373752]\n",
      "[0.06101678 0.04830471 0.39723128 0.50433856]\n",
      "[0.03628395 0.08702441 0.6271938  0.24258201]\n",
      "[0.0610495  0.04894345 0.40043902 0.5009332 ]\n",
      "[0.03631116 0.08755534 0.62828946 0.24144053]\n",
      "[0.06108209 0.04958855 0.40364867 0.49753597]\n",
      "ABABA1AABBAAB => BABBABABABABABABABAB\n",
      "accuracy training = 0.7453271150588989\n",
      "loss training = 0.42805948853492737\n",
      "___________________________________\n",
      "Epoch 86\n",
      "[0.03324328 0.01257621 0.2071877  0.70330554]\n",
      "[0.03384623 0.03507067 0.42080513 0.44865623]\n",
      "[0.0360533  0.08471747 0.6193371  0.2463735 ]\n",
      "[0.06047804 0.04155793 0.36017758 0.5428044 ]\n",
      "[0.03568343 0.08139375 0.61669594 0.25324848]\n",
      "[0.06028416 0.04136914 0.36068442 0.5433044 ]\n",
      "[0.03568082 0.08144239 0.6169192  0.2531097 ]\n",
      "[0.06028613 0.04148657 0.36138412 0.5425537 ]\n",
      "[0.03568649 0.08156543 0.6172083  0.25281343]\n",
      "[0.06029267 0.04161246 0.3620961  0.54176754]\n",
      "[0.03569252 0.08169159 0.61750126 0.25251135]\n",
      "[0.06029947 0.04174031 0.36281636 0.5409721 ]\n",
      "[0.03569868 0.08181918 0.6177966  0.25220692]\n",
      "[0.06030637 0.04186987 0.36354482 0.5401683 ]\n",
      "[0.03570493 0.08194815 0.6180943  0.25190017]\n",
      "[0.06031338 0.04200121 0.36428168 0.5393559 ]\n",
      "[0.03571125 0.08207843 0.61839443 0.2515911 ]\n",
      "[0.06032049 0.04213432 0.365027   0.5385348 ]\n",
      "[0.03571767 0.08221009 0.6186968  0.25127965]\n",
      "[0.06032767 0.0422692  0.3657806  0.5377052 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8785046935081482\n",
      "loss training = 0.34521958231925964\n",
      "___________________________________\n",
      "Epoch 87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03327677 0.01320807 0.21612109 0.69001937]\n",
      "[0.03389403 0.03821277 0.44495365 0.4193777 ]\n",
      "[0.05811285 0.01473035 0.17199998 0.7726693 ]\n",
      "[0.03368066 0.03667558 0.44287366 0.4289599 ]\n",
      "[0.0579395  0.01464582 0.17211024 0.7732434 ]\n",
      "[0.03365849 0.03673321 0.44356465 0.4283879 ]\n",
      "[0.05793652 0.01467681 0.17240791 0.7728389 ]\n",
      "[0.03366083 0.03684104 0.44428998 0.42762107]\n",
      "[0.03604622 0.09182122 0.64286256 0.2228901 ]\n",
      "[0.06058941 0.04691968 0.39161727 0.50300145]\n",
      "[0.03579333 0.0900589  0.6433551  0.22566342]\n",
      "[0.0604844  0.04811458 0.39924607 0.49565792]\n",
      "[0.03585048 0.09138843 0.64610606 0.2229751 ]\n",
      "[0.06054302 0.04964888 0.40713513 0.48723295]\n",
      "[0.03591448 0.09278671 0.64884347 0.2202299 ]\n",
      "[0.0606051  0.05123926 0.41509932 0.47877613]\n",
      "[0.0359788  0.09418651 0.65151477 0.21754678]\n",
      "[0.06066711 0.05287686 0.42311096 0.47033566]\n",
      "[0.03604312 0.09558319 0.65411526 0.21493202]\n",
      "[0.06072882 0.05455821 0.43114433 0.46193895]\n",
      "ABABA1AABBAAB => BABABABBABABABABABAB\n",
      "accuracy training = 0.8831775784492493\n",
      "loss training = 0.3420875370502472\n",
      "___________________________________\n",
      "Epoch 88\n",
      "[0.03362136 0.01144117 0.18609565 0.732757  ]\n",
      "[0.03320657 0.02910421 0.37629107 0.4976094 ]\n",
      "[0.03524274 0.07789653 0.60610896 0.25943926]\n",
      "[0.06115541 0.03434128 0.31076455 0.5977793 ]\n",
      "[0.0353656  0.07421383 0.59848213 0.2708915 ]\n",
      "[0.06102558 0.03310541 0.30381146 0.6068916 ]\n",
      "[0.03531157 0.07279943 0.5945547  0.2749623 ]\n",
      "[0.06095595 0.03206682 0.2970666  0.6149087 ]\n",
      "[0.03527038 0.07142191 0.5904656  0.27910167]\n",
      "[0.06088975 0.03104328 0.2902791  0.6230129 ]\n",
      "[0.0352288  0.07001115 0.58615446 0.2834657 ]\n",
      "[0.06082185 0.0300309  0.28345847 0.6312154 ]\n",
      "[0.03518609 0.06856515 0.5816073  0.28807163]\n",
      "[0.06075199 0.02903104 0.2766169  0.639504  ]\n",
      "[0.03514226 0.06708413 0.5768099  0.29293475]\n",
      "[0.0606801  0.02804518 0.26976702 0.6478647 ]\n",
      "[0.03509727 0.06556841 0.5717474  0.2980712 ]\n",
      "[0.0606061  0.02707478 0.26292193 0.6562828 ]\n",
      "[0.03505106 0.06401852 0.5664045  0.30349824]\n",
      "[0.06053002 0.02612121 0.25609517 0.66474265]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.827102780342102\n",
      "loss training = 0.3655485212802887\n",
      "___________________________________\n",
      "Epoch 89\n",
      "[0.03283281 0.01662694 0.27070192 0.61395764]\n",
      "[0.03429795 0.05408755 0.538096   0.31813595]\n",
      "[0.05913121 0.02042325 0.22686848 0.69261754]\n",
      "[0.03398939 0.05479866 0.5500168  0.31311435]\n",
      "[0.05903737 0.02162437 0.2376965  0.6791911 ]\n",
      "[0.0340963  0.05807487 0.56356686 0.30013973]\n",
      "[0.05916176 0.02314802 0.24966083 0.6636596 ]\n",
      "[0.03421663 0.06151992 0.5766257  0.287608  ]\n",
      "[0.05929215 0.02485119 0.2626635  0.64705217]\n",
      "[0.03434278 0.06507856 0.5891129  0.27568623]\n",
      "[0.05942417 0.02674952 0.2767337  0.6294023 ]\n",
      "[0.03447428 0.0687377  0.6009961  0.26438808]\n",
      "[0.05955734 0.02886194 0.29188198 0.6107541 ]\n",
      "[0.03461081 0.07248323 0.6122521  0.2537183 ]\n",
      "[0.05969126 0.03120668 0.30809024 0.59118736]\n",
      "[0.03475192 0.07629874 0.6228656  0.24367705]\n",
      "[0.05982555 0.0337999  0.3253052  0.5708219 ]\n",
      "[0.03489703 0.08016545 0.63282776 0.23426077]\n",
      "[0.0599597  0.03665402 0.34343207 0.5498202 ]\n",
      "[0.03504534 0.08406183 0.64213544 0.22546288]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7920560836791992\n",
      "loss training = 0.40634334087371826\n",
      "___________________________________\n",
      "Epoch 90\n",
      "[0.03302856 0.01456265 0.23920992 0.65816224]\n",
      "[0.03361668 0.04481193 0.48389682 0.3774842 ]\n",
      "[0.06011841 0.01676241 0.19189797 0.74540657]\n",
      "[0.03348495 0.04428613 0.48931918 0.37978715]\n",
      "[0.06003828 0.01726813 0.1971451  0.7393166 ]\n",
      "[0.03351178 0.04595198 0.4983082  0.37076187]\n",
      "[0.06011972 0.01797362 0.2030377  0.7315171 ]\n",
      "[0.03356319 0.04773095 0.50719035 0.36170033]\n",
      "[0.06021   0.018735  0.209287  0.7232946]\n",
      "[0.03361677 0.0495562  0.5159039  0.35284147]\n",
      "[0.06030083 0.01955165 0.21590485 0.71466565]\n",
      "[0.0336716  0.05142365 0.5244334  0.34420016]\n",
      "[0.06039174 0.02042743 0.22290562 0.7056223 ]\n",
      "[0.03372748 0.05333083 0.5327654  0.33578518]\n",
      "[0.0604826  0.02136652 0.23030199 0.6961588 ]\n",
      "[0.03378445 0.05527516 0.54088765 0.32760382]\n",
      "[0.06057342 0.02237322 0.23810463 0.68627286]\n",
      "[0.03384243 0.05725373 0.54878974 0.3196621 ]\n",
      "[0.06066403 0.02345188 0.24632148 0.67596585]\n",
      "[0.03390138 0.05926346 0.5564624  0.31196496]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7313084006309509\n",
      "loss training = 0.4483559727668762\n",
      "___________________________________\n",
      "Epoch 91\n",
      "[0.03288558 0.01238094 0.20698355 0.7037986 ]\n",
      "[0.03290426 0.03584042 0.42452985 0.44494328]\n",
      "[0.0346521  0.08150163 0.6035747  0.2596651 ]\n",
      "[0.06228128 0.04017517 0.34890497 0.56262255]\n",
      "[0.0344595  0.07699224 0.5981333  0.27105242]\n",
      "[0.06210595 0.03993903 0.34951794 0.5635641 ]\n",
      "[0.03443912 0.07703128 0.598504   0.27084258]\n",
      "[0.06210351 0.04014088 0.3507411  0.5622667 ]\n",
      "[0.03444437 0.0772236  0.5989919  0.27033177]\n",
      "[0.06211087 0.04035827 0.35197768 0.56091005]\n",
      "[0.03445081 0.07742079 0.5994802  0.2698153 ]\n",
      "[0.06211868 0.04057712 0.35321566 0.5595519 ]\n",
      "[0.03445734 0.077618   0.5999662  0.26930124]\n",
      "[0.06212651 0.04079695 0.35445482 0.55819416]\n",
      "[0.03446389 0.07781501 0.60044986 0.26878977]\n",
      "[0.06213435 0.04101769 0.35569486 0.55683684]\n",
      "[0.03447046 0.07801181 0.600931   0.26828092]\n",
      "[0.06214221 0.04123936 0.3569358  0.55548024]\n",
      "[0.03447702 0.07820832 0.6014097  0.26777458]\n",
      "[0.06215005 0.0414619  0.3581774  0.5541243 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7920560836791992\n",
      "loss training = 0.4011097252368927\n",
      "___________________________________\n",
      "Epoch 92\n",
      "[0.03261821 0.0123811  0.20748651 0.7018166 ]\n",
      "[0.03279032 0.03637037 0.42921197 0.43682203]\n",
      "[0.05996708 0.01320016 0.15717404 0.7946083 ]\n",
      "[0.03263494 0.03431389 0.4248333  0.4509695 ]\n",
      "[0.03442694 0.08381122 0.6143491  0.24857506]\n",
      "[0.06181975 0.0411288  0.35629892 0.5505206 ]\n",
      "[0.03404307 0.07987557 0.6110922  0.256739  ]\n",
      "[0.0616329  0.04123237 0.35874704 0.54918504]\n",
      "[0.03405248 0.08024645 0.61210424 0.25581485]\n",
      "[0.06164385 0.04173977 0.3616535  0.54603094]\n",
      "[0.03407243 0.08073037 0.6132209  0.25465536]\n",
      "[0.06166009 0.04226413 0.36458322 0.54282445]\n",
      "[0.03409271 0.08121715 0.6143297  0.25350034]\n",
      "[0.06167647 0.04279489 0.36752337 0.5396143 ]\n",
      "[0.034113   0.08170362 0.61542743 0.2523565 ]\n",
      "[0.06169282 0.04333157 0.37047228 0.53640336]\n",
      "[0.0341333  0.08218948 0.61651355 0.25122425]\n",
      "[0.06170905 0.04387399 0.37342831 0.5331932 ]\n",
      "[0.0341536  0.08267457 0.6175879  0.25010377]\n",
      "[0.06172528 0.04442201 0.37639025 0.5299855 ]\n",
      "ABABA1AABBAAB => BABBABABABABABABABAB\n",
      "accuracy training = 0.8761682510375977\n",
      "loss training = 0.3440827429294586\n",
      "___________________________________\n",
      "Epoch 93\n",
      "[0.03256672 0.01188424 0.19955659 0.7121928 ]\n",
      "[0.03256219 0.03418997 0.41584784 0.44966882]\n",
      "[0.03424423 0.08394434 0.6175242  0.24401434]\n",
      "[0.06180887 0.0386656  0.34127527 0.56408656]\n",
      "[0.0337791  0.07890159 0.61281747 0.25449136]\n",
      "[0.06158086 0.03840047 0.34186703 0.56500393]\n",
      "[0.03377426 0.07896495 0.6131555  0.25429443]\n",
      "[0.06158043 0.03857554 0.34296757 0.5638069 ]\n",
      "[0.03378161 0.07916014 0.6136298  0.25381187]\n",
      "[0.0615862  0.03876524 0.34409645 0.5625394 ]\n",
      "[0.03378947 0.0793613  0.6141117  0.25331816]\n",
      "[0.06159225 0.0389585  0.34524134 0.56125426]\n",
      "[0.03379745 0.07956503 0.61459756 0.2528204 ]\n",
      "[0.06159841 0.03915502 0.3464019  0.55995303]\n",
      "[0.03380561 0.07977123 0.6150873  0.25231883]\n",
      "[0.06160468 0.03935484 0.34757826 0.5586356 ]\n",
      "[0.03381387 0.07997986 0.61558074 0.2518134 ]\n",
      "[0.06161104 0.03955802 0.34877047 0.5573019 ]\n",
      "[0.03382224 0.08019091 0.6160779  0.25130424]\n",
      "[0.06161745 0.03976454 0.34997866 0.55595195]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8691588640213013\n",
      "loss training = 0.3425217270851135\n",
      "___________________________________\n",
      "Epoch 94\n",
      "[0.03252965 0.01247741 0.20836143 0.6989067 ]\n",
      "[0.03255826 0.03719979 0.43949994 0.4206932 ]\n",
      "[0.06024603 0.01336618 0.15716852 0.7919166 ]\n",
      "[0.03234354 0.0349815  0.43508628 0.4348707 ]\n",
      "[0.03416976 0.09054385 0.64055604 0.22159505]\n",
      "[0.06168437 0.04336404 0.37087873 0.5257022 ]\n",
      "[0.03383404 0.08734668 0.63965607 0.22687851]\n",
      "[0.06152795 0.04445723 0.37883624 0.51824754]\n",
      "[0.03388058 0.08875178 0.6427177  0.2239484 ]\n",
      "[0.06155726 0.04601238 0.3873497  0.50898266]\n",
      "[0.03393715 0.09027766 0.6458082  0.22088067]\n",
      "[0.06159112 0.04763336 0.39596862 0.49964935]\n",
      "[0.03399422 0.09180845 0.64882183 0.21788554]\n",
      "[0.06162488 0.04930642 0.4046498  0.49032685]\n",
      "[0.03405141 0.09333667 0.65175015 0.21497378]\n",
      "[0.06165834 0.0510269  0.41335842 0.48105356]\n",
      "[0.03410847 0.09485736 0.6545878  0.21215084]\n",
      "[0.06169135 0.05278927 0.42205766 0.47186786]\n",
      "[0.03416521 0.0963656  0.65732986 0.20942171]\n",
      "[0.06172384 0.05458724 0.43070957 0.4628081 ]\n",
      "ABABA1AABBAAB => BABBABABABABABABABAB\n",
      "accuracy training = 0.8831775784492493\n",
      "loss training = 0.3390549421310425\n",
      "___________________________________\n",
      "Epoch 95\n",
      "[0.03292896 0.01072976 0.17854196 0.7418931 ]\n",
      "[0.03199109 0.02810832 0.36936918 0.50168306]\n",
      "[0.03349963 0.0763236  0.6009766  0.2606679 ]\n",
      "[0.06272591 0.0314138  0.29024658 0.6227549 ]\n",
      "[0.03363721 0.07098728 0.5901565  0.2769452 ]\n",
      "[0.06262692 0.0300462  0.28244874 0.63350016]\n",
      "[0.0335921  0.06940342 0.5855907  0.28173745]\n",
      "[0.06258169 0.02898146 0.27517045 0.6423007 ]\n",
      "[0.03355902 0.06789834 0.5808993  0.2865039 ]\n",
      "[0.06254057 0.0279377  0.26786825 0.6511585 ]\n",
      "[0.0335259  0.06635777 0.57593673 0.29154667]\n",
      "[0.06249799 0.02690833 0.26054755 0.66010505]\n",
      "[0.0334921  0.06477885 0.57068324 0.29689172]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0624536  0.02589494 0.2532245  0.669123  ]\n",
      "[0.03345755 0.06316207 0.56512046 0.3025594 ]\n",
      "[0.06240732 0.0248993  0.24591604 0.67819256]\n",
      "[0.03342231 0.06150838 0.5592295  0.3085712 ]\n",
      "[0.06235904 0.02392312 0.23863944 0.6872932 ]\n",
      "[0.03338639 0.05981887 0.5529906  0.31494972]\n",
      "[0.06230868 0.02296802 0.23141228 0.69640326]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8317757248878479\n",
      "loss training = 0.3709753453731537\n",
      "___________________________________\n",
      "Epoch 96\n",
      "[0.0317087  0.01614913 0.2695132  0.6145483 ]\n",
      "[0.03277406 0.05477979 0.5418793  0.31102976]\n",
      "[0.06073868 0.01945135 0.2178403  0.7043172 ]\n",
      "[0.0323834  0.05487196 0.5538328  0.30768457]\n",
      "[0.06059287 0.02080227 0.23043315 0.6889161 ]\n",
      "[0.03247224 0.05857347 0.56885463 0.29334834]\n",
      "[0.06067207 0.02257817 0.24468721 0.67050576]\n",
      "[0.03257853 0.0624972  0.5832181  0.279572  ]\n",
      "[0.06075454 0.02458828 0.26028064 0.65071905]\n",
      "[0.03269172 0.06654943 0.5967945  0.2666193 ]\n",
      "[0.06083481 0.02685125 0.2772152  0.6296577 ]\n",
      "[0.03281104 0.07070817 0.6095521  0.25449893]\n",
      "[0.06091253 0.02938892 0.2954538  0.6074469 ]\n",
      "[0.03293579 0.07494956 0.621473   0.2432068 ]\n",
      "[0.06098747 0.03221895 0.31490034 0.5842781 ]\n",
      "[0.03306513 0.07924568 0.63254946 0.23273355]\n",
      "[0.06105954 0.03535185 0.33539057 0.5604116 ]\n",
      "[0.03319793 0.08356427 0.64278233 0.22306603]\n",
      "[0.06112858 0.03878751 0.3566879  0.53617173]\n",
      "[0.03333281 0.08786849 0.6521791  0.2141884 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7943925261497498\n",
      "loss training = 0.40543118119239807\n",
      "___________________________________\n",
      "Epoch 97\n",
      "[0.03195554 0.01412488 0.23827878 0.6586608 ]\n",
      "[0.03219438 0.04561892 0.4897321  0.36814874]\n",
      "[0.06203711 0.0158887  0.18342751 0.7561907 ]\n",
      "[0.03187797 0.0444385  0.49558747 0.37209737]\n",
      "[0.06191992 0.01651717 0.1901629  0.74847925]\n",
      "[0.03189741 0.04652676 0.5066279  0.36106208]\n",
      "[0.0619843  0.01743278 0.19799416 0.7382007 ]\n",
      "[0.0319415  0.04878075 0.5175034  0.3499861 ]\n",
      "[0.06205542 0.01843834 0.206412   0.7272337 ]\n",
      "[0.03198867 0.05110037 0.5280691  0.33926633]\n",
      "[0.06212485 0.01953468 0.21542853 0.71561563]\n",
      "[0.03203798 0.05347789 0.53829926 0.328926  ]\n",
      "[0.06219209 0.02072898 0.22506236 0.7033437 ]\n",
      "[0.03208926 0.05590771 0.5481741  0.31897616]\n",
      "[0.06225694 0.02202859 0.23532538 0.6904241 ]\n",
      "[0.03214245 0.05838383 0.5576773  0.3094249 ]\n",
      "[0.06231939 0.02344064 0.24622035 0.6768751 ]\n",
      "[0.03219741 0.06089932 0.5667958  0.30027795]\n",
      "[0.06237938 0.02497162 0.25773886 0.66272926]\n",
      "[0.03227206 0.06347009 0.575476   0.29156134]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7313084006309509\n",
      "loss training = 0.4387408196926117\n",
      "___________________________________\n",
      "Epoch 98\n",
      "[0.03195356 0.01217022 0.20875198 0.7007796 ]\n",
      "[0.0315983  0.03746185 0.43689924 0.42849275]\n",
      "[0.0329432  0.08340789 0.6073438  0.25263935]\n",
      "[0.06372178 0.03957467 0.34551468 0.5677202 ]\n",
      "[0.03276782 0.07703559 0.5996648  0.2679444 ]\n",
      "[0.06357003 0.03979406 0.34946406 0.56576824]\n",
      "[0.03276979 0.07761137 0.6013727  0.26640365]\n",
      "[0.06357252 0.04069232 0.3546764  0.5601541 ]\n",
      "[0.03279242 0.07842378 0.6033071  0.26436412]\n",
      "[0.06358378 0.04162044 0.35988227 0.55449283]\n",
      "[0.03281578 0.07923186 0.60518944 0.2623701 ]\n",
      "[0.06359513 0.04255315 0.36503503 0.5489112 ]\n",
      "[0.03283888 0.08002633 0.6070112  0.26043886]\n",
      "[0.06360614 0.043488   0.37012577 0.5434202 ]\n",
      "[0.03286162 0.08080606 0.60877293 0.2585706 ]\n",
      "[0.06361678 0.04442338 0.37514707 0.53802705]\n",
      "[0.03288397 0.08157054 0.6104751  0.2567646 ]\n",
      "[0.06362703 0.04535768 0.38009188 0.5327379 ]\n",
      "[0.03290591 0.08231909 0.6121186  0.2550202 ]\n",
      "[0.06363695 0.04628931 0.38495365 0.5275586 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7780373692512512\n",
      "loss training = 0.40497103333473206\n",
      "___________________________________\n",
      "Epoch 99\n",
      "[0.03155693 0.01095558 0.19160576 0.72430986]\n",
      "[0.03126035 0.032678   0.40374178 0.46456617]\n",
      "[0.03253136 0.07802156 0.59314257 0.26676974]\n",
      "[0.06316601 0.03367869 0.31015047 0.6080642 ]\n",
      "[0.03201116 0.07049572 0.58317924 0.2852248 ]\n",
      "[0.06293046 0.03282926 0.30752826 0.6133869 ]\n",
      "[0.03197975 0.07000541 0.5822     0.2865462 ]\n",
      "[0.06291687 0.03258037 0.30602103 0.61517876]\n",
      "[0.03197245 0.06974988 0.5815012  0.2872941 ]\n",
      "[0.0629129  0.03235243 0.30454534 0.61686   ]\n",
      "[0.03196618 0.06950123 0.58080447 0.28803056]\n",
      "[0.06290933 0.03212553 0.30306727 0.6185437 ]\n",
      "[0.03195995 0.06925157 0.58010066 0.28877434]\n",
      "[0.06290576 0.03189898 0.30158573 0.6202335 ]\n",
      "[0.03195373 0.06900059 0.57938945 0.28952605]\n",
      "[0.06290216 0.03167278 0.3001008  0.62192935]\n",
      "[0.03194749 0.06874824 0.5786705  0.2902859 ]\n",
      "[0.06289856 0.03144696 0.29861268 0.6236312 ]\n",
      "[0.03194123 0.06849454 0.577944   0.29105386]\n",
      "[0.06289491 0.03122151 0.29712152 0.6253389 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.855140209197998\n",
      "loss training = 0.3569639027118683\n",
      "___________________________________\n",
      "Epoch 100\n",
      "[0.03145526 0.01218017 0.21088375 0.6958327 ]\n",
      "[0.03130728 0.0387046  0.44811133 0.41159585]\n",
      "[0.06220809 0.01270825 0.15276793 0.79848415]\n",
      "[0.03098453 0.03612822 0.44572526 0.4258251 ]\n",
      "[0.06206664 0.01274239 0.1543193  0.7976204 ]\n",
      "[0.03097463 0.03678023 0.45038104 0.42121053]\n",
      "[0.06208159 0.01299148 0.15664059 0.7944844 ]\n",
      "[0.03098364 0.03755291 0.45525482 0.41603366]\n",
      "[0.06210393 0.01325873 0.15907727 0.79116464]\n",
      "[0.03099397 0.03834903 0.46015322 0.410835  ]\n",
      "[0.06212654 0.01353843 0.16161554 0.78771806]\n",
      "[0.03100477 0.0391656  0.46506763 0.4056336 ]\n",
      "[0.06214903 0.01383103 0.16425931 0.78414166]\n",
      "[0.03101606 0.04000275 0.4699941  0.40043336]\n",
      "[0.06217138 0.01413721 0.16701336 0.7804304 ]\n",
      "[0.03102777 0.04086061 0.4749292  0.3952376 ]\n",
      "[0.0621935  0.01445776 0.16988252 0.776579  ]\n",
      "[0.03103995 0.04173942 0.47986916 0.39004982]\n",
      "[0.06221542 0.01479343 0.17287184 0.7725826 ]\n",
      "[0.0310526  0.04263936 0.48481038 0.38487354]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8925233483314514\n",
      "loss training = 0.3442988097667694\n",
      "___________________________________\n",
      "Epoch 101\n",
      "[0.03156593 0.01066504 0.18655504 0.7301258 ]\n",
      "[0.03090871 0.03156374 0.39880055 0.466912  ]\n",
      "[0.03213352 0.07977025 0.6042118  0.2546114 ]\n",
      "[0.06360205 0.03265786 0.3032729  0.6110712 ]\n",
      "[0.03176847 0.07186228 0.59301144 0.2737311 ]\n",
      "[0.06342822 0.03161168 0.29906526 0.6182605 ]\n",
      "[0.03173956 0.07107478 0.591182   0.27588835]\n",
      "[0.06341582 0.03113736 0.29598743 0.6219099 ]\n",
      "[0.03172768 0.0705139  0.58961844 0.27750897]\n",
      "[0.06341035 0.03068267 0.29292607 0.62547535]\n",
      "[0.03171647 0.0699538  0.5880266  0.27915055]\n",
      "[0.06340507 0.03022927 0.28984708 0.6290692 ]\n",
      "[0.03170523 0.06938674 0.58639574 0.28083244]\n",
      "[0.06339966 0.0297767  0.28675047 0.632694  ]\n",
      "[0.03169389 0.06881246 0.58472455 0.2825564 ]\n",
      "[0.0633941  0.0293251  0.28363726 0.63634896]\n",
      "[0.03168245 0.06823088 0.5830118  0.28432348]\n",
      "[0.06338832 0.02887462 0.2805085  0.640033  ]\n",
      "[0.03167093 0.06764205 0.58125645 0.2861351 ]\n",
      "[0.06338236 0.02842545 0.27736542 0.64374495]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8457943797111511\n",
      "loss training = 0.3610840141773224\n",
      "___________________________________\n",
      "Epoch 102\n",
      "[0.03115326 0.01294473 0.22433929 0.67661357]\n",
      "[0.03105212 0.04322536 0.48010325 0.37476262]\n",
      "[0.06233305 0.01393071 0.16522826 0.77903134]\n",
      "[0.03054319 0.04085189 0.48249677 0.38375697]\n",
      "[0.06215435 0.01423747 0.16949748 0.77454615]\n",
      "[0.03055113 0.04235092 0.49139616 0.37486294]\n",
      "[0.06217415 0.01481898 0.1748001  0.76737714]\n",
      "[0.030587   0.04403668 0.500432   0.36554408]\n",
      "[0.06220217 0.01545559 0.18049575 0.75969034]\n",
      "[0.03062574 0.04579315 0.5094166  0.35631603]\n",
      "[0.06222948 0.01614443 0.1865921  0.7515246 ]\n",
      "[0.0306669  0.04761726 0.5183234  0.34721088]\n",
      "[0.06225566 0.01689    0.193114   0.7428588 ]\n",
      "[0.03071049 0.0495088  0.5271321  0.3382459 ]\n",
      "[0.06228064 0.01769735 0.20008633 0.73367155]\n",
      "[0.03075655 0.05146728 0.53582263 0.32943738]\n",
      "[0.06230429 0.01857187 0.20753329 0.72394395]\n",
      "[0.03080511 0.05349179 0.54437596 0.32080057]\n",
      "[0.06232658 0.01951924 0.21547727 0.7136609 ]\n",
      "[0.03085619 0.05558097 0.55277365 0.31234998]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8925233483314514\n",
      "loss training = 0.3485427796840668\n",
      "___________________________________\n",
      "Epoch 103\n",
      "[0.03149133 0.01114491 0.19472174 0.71906155]\n",
      "[0.03058686 0.03476795 0.42351428 0.43936804]\n",
      "[0.03177167 0.08473291 0.61692905 0.24153663]\n",
      "[0.06425045 0.03590131 0.32445648 0.5863616 ]\n",
      "[0.03158437 0.07675494 0.60675704 0.25951332]\n",
      "[0.06414157 0.03562069 0.32566422 0.58762115]\n",
      "[0.03158201 0.07694807 0.6075762  0.2589597 ]\n",
      "[0.06413632 0.03605246 0.32846412 0.5845523 ]\n",
      "[0.03159074 0.07743178 0.60878056 0.25773203]\n",
      "[0.06413607 0.0365173  0.33134198 0.5813118 ]\n",
      "[0.03160008 0.07792786 0.60999143 0.2564879 ]\n",
      "[0.06413607 0.03699005 0.33424276 0.5780506 ]\n",
      "[0.03160957 0.07842586 0.611195   0.2552513 ]\n",
      "[0.06413604 0.03746966 0.33716303 0.57477593]\n",
      "[0.03161911 0.07892513 0.6123902  0.25402343]\n",
      "[0.06413599 0.03795594 0.3401013  0.5714897 ]\n",
      "[0.03162871 0.07942539 0.61357665 0.25280493]\n",
      "[0.06413589 0.03844873 0.34305587 0.5681938 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03163835 0.07992635 0.6147537  0.25159615]\n",
      "[0.06413572 0.03894786 0.34602517 0.56489027]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.7873831987380981\n",
      "loss training = 0.3987748324871063\n",
      "___________________________________\n",
      "Epoch 104\n",
      "[0.0311306  0.01079663 0.19039303 0.72430605]\n",
      "[0.03041448 0.03358714 0.41588515 0.4454652 ]\n",
      "[0.03154643 0.08528171 0.6211276  0.23674251]\n",
      "[0.06352101 0.03456489 0.31812927 0.59076303]\n",
      "[0.03097274 0.07658541 0.6118185  0.25406113]\n",
      "[0.06331616 0.03417904 0.3189022  0.5924663 ]\n",
      "[0.03096385 0.0766925  0.6124556  0.25369582]\n",
      "[0.06330846 0.03450158 0.3210958  0.59004503]\n",
      "[0.03097469 0.07709532 0.61344635 0.25269753]\n",
      "[0.06330778 0.03485584 0.3233714  0.5874484 ]\n",
      "[0.03098639 0.07751312 0.6144527  0.25167415]\n",
      "[0.06330739 0.03521828 0.3256821  0.58481437]\n",
      "[0.03099837 0.07793611 0.61546266 0.25064725]\n",
      "[0.06330702 0.03558817 0.32802594 0.5821482 ]\n",
      "[0.03101047 0.0783637  0.6164752  0.24961792]\n",
      "[0.06330662 0.03596545 0.33040237 0.5794509 ]\n",
      "[0.03102277 0.07879578 0.6174901  0.24858646]\n",
      "[0.0633062  0.03635018 0.33281082 0.5767232 ]\n",
      "[0.03103521 0.07923228 0.6185067  0.24755345]\n",
      "[0.06330575 0.0367424  0.33525074 0.5739661 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8644859790802002\n",
      "loss training = 0.33821937441825867\n",
      "___________________________________\n",
      "Epoch 105\n",
      "[0.03103167 0.01098094 0.1931664  0.71933436]\n",
      "[0.03032288 0.03463496 0.42533025 0.43202248]\n",
      "[0.03145345 0.09009171 0.637395   0.2203117 ]\n",
      "[0.06324349 0.03636824 0.33084986 0.5711846 ]\n",
      "[0.030911   0.0817808  0.63022596 0.23480454]\n",
      "[0.06304676 0.03660116 0.33561435 0.56826866]\n",
      "[0.03092332 0.08266667 0.6325669  0.23274735]\n",
      "[0.06303541 0.03759031 0.34189332 0.5612163 ]\n",
      "[0.03095464 0.08386422 0.6352092  0.23014715]\n",
      "[0.06303023 0.03864172 0.34834692 0.553928  ]\n",
      "[0.03098715 0.08508655 0.6378356  0.2275563 ]\n",
      "[0.06302513 0.03973108 0.3549171  0.5465512 ]\n",
      "[0.03102013 0.08632152 0.64043057 0.22499777]\n",
      "[0.06301989 0.04085644 0.36158708 0.53910935]\n",
      "[0.0310535  0.0875662  0.6429888  0.22247697]\n",
      "[0.06301446 0.04201633 0.36834008 0.53162247]\n",
      "[0.03108712 0.08881786 0.6455054  0.21999857]\n",
      "[0.06300889 0.04320888 0.37515783 0.5241122 ]\n",
      "[0.03112093 0.09007353 0.6479756  0.2175672 ]\n",
      "[0.06300317 0.04443178 0.38202012 0.5166014 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8738317489624023\n",
      "loss training = 0.3340487480163574\n",
      "___________________________________\n",
      "Epoch 106\n",
      "[0.03127392 0.00971852 0.17150718 0.7503685 ]\n",
      "[0.0300116  0.02749748 0.37014297 0.49433413]\n",
      "[0.03098973 0.07898263 0.61244804 0.2447975 ]\n",
      "[0.063926   0.02806844 0.272326   0.6411455 ]\n",
      "[0.03062914 0.06978813 0.5983984  0.26661685]\n",
      "[0.06381869 0.02669976 0.26499724 0.6523695 ]\n",
      "[0.0306101  0.06823708 0.5940501  0.27120188]\n",
      "[0.06382247 0.02584324 0.25869033 0.66017675]\n",
      "[0.03059862 0.06686976 0.58978415 0.27545264]\n",
      "[0.06382881 0.02499959 0.2523104  0.66805184]\n",
      "[0.03058725 0.06546291 0.5852543  0.2799661 ]\n",
      "[0.06383501 0.02415485 0.24583091 0.67609936]\n",
      "[0.03057579 0.06400869 0.5804284  0.28478432]\n",
      "[0.06384083 0.02331012 0.23926167 0.6843122 ]\n",
      "[0.03056423 0.06250629 0.5752832  0.28993294]\n",
      "[0.06384616 0.0224671  0.23261508 0.692678  ]\n",
      "[0.03055259 0.06095543 0.56979394 0.29543915]\n",
      "[0.06385087 0.02162758 0.22590496 0.70118165]\n",
      "[0.03054092 0.05935606 0.5639343  0.30133262]\n",
      "[0.06385485 0.0207934  0.21914655 0.7098065 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8574766516685486\n",
      "loss training = 0.34221115708351135\n",
      "___________________________________\n",
      "Epoch 107\n",
      "[0.02982315 0.01596984 0.27723056 0.6048539 ]\n",
      "[0.03046545 0.05995134 0.56861174 0.28105548]\n",
      "[0.06212572 0.01921091 0.21839489 0.7011594 ]\n",
      "[0.03003465 0.05972883 0.5831368  0.2770461 ]\n",
      "[0.0619319  0.02131803 0.23818782 0.6769546 ]\n",
      "[0.03012548 0.06534473 0.6027992  0.25872424]\n",
      "[0.0618942  0.02420465 0.2616322  0.6471683 ]\n",
      "[0.03024315 0.07144634 0.62122136 0.24148552]\n",
      "[0.0618524  0.02762447 0.2878465  0.6147455 ]\n",
      "[0.03037251 0.07781695 0.63811827 0.22578748]\n",
      "[0.06180311 0.03161374 0.31651276 0.58035684]\n",
      "[0.03051085 0.0843664  0.65342283 0.21165104]\n",
      "[0.06174818 0.03618433 0.3470323  0.5449056 ]\n",
      "[0.03065506 0.0909823  0.66710466 0.19906856]\n",
      "[0.06169023 0.04129507 0.37850022 0.50954056]\n",
      "[0.03080115 0.09752655 0.6791619  0.1880169 ]\n",
      "[0.06163217 0.04683604 0.4097848  0.47551674]\n",
      "[0.03094471 0.10384311 0.68962073 0.17845556]\n",
      "[0.06157676 0.05262644 0.43968806 0.4440024 ]\n",
      "[0.03108113 0.109773   0.6985368  0.1703225 ]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.822429895401001\n",
      "loss training = 0.39029237627983093\n",
      "___________________________________\n",
      "Epoch 108\n",
      "[0.03020104 0.01354238 0.24005947 0.65723246]\n",
      "[0.02994045 0.04828162 0.5103918  0.34371236]\n",
      "[0.0639917  0.01485055 0.17683369 0.76370376]\n",
      "[0.02943061 0.04618472 0.51793176 0.34832788]\n",
      "[0.06386027 0.0158145  0.18742381 0.7513963 ]\n",
      "[0.02947173 0.04936101 0.53327316 0.33313432]\n",
      "[0.06385972 0.01725864 0.20037921 0.7345669 ]\n",
      "[0.02953755 0.0528847  0.5483356  0.31794307]\n",
      "[0.06385645 0.01891888 0.21479435 0.7160628 ]\n",
      "[0.02961065 0.05657867 0.56275743 0.3034687 ]\n",
      "[0.06384575 0.0208087  0.23068103 0.6959973 ]\n",
      "[0.02969005 0.06041947 0.5764581  0.28978115]\n",
      "[0.06382765 0.02294944 0.24803045 0.67446053]\n",
      "[0.02977519 0.06438332 0.5893783  0.27692014]\n",
      "[0.06380275 0.02535785 0.26676223 0.6516285 ]\n",
      "[0.02986523 0.06843958 0.60147    0.26491663]\n",
      "[0.06377187 0.0280421  0.2867071  0.6277776 ]\n",
      "[0.02995904 0.07255    0.612696   0.2537946 ]\n",
      "[0.06373617 0.03099752 0.30759737 0.6032833 ]\n",
      "[0.03005525 0.07666875 0.6230295  0.24357109]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7406542301177979\n",
      "loss training = 0.4335334599018097\n",
      "___________________________________\n",
      "Epoch 109\n",
      "[0.03050896 0.01173007 0.21082193 0.69894075]\n",
      "[0.02944902 0.04005216 0.46009597 0.40074143]\n",
      "[0.06537946 0.01181654 0.14604793 0.80915135]\n",
      "[0.02966115 0.03736134 0.45784286 0.41664603]\n",
      "[0.06553022 0.01212561 0.15022662 0.8052338 ]\n",
      "[0.02968805 0.03889931 0.46737826 0.4069502 ]\n",
      "[0.06554944 0.01274499 0.15615174 0.79749644]\n",
      "[0.02970368 0.04066632 0.47733876 0.39635208]\n",
      "[0.06555855 0.01343351 0.16261259 0.7890537 ]\n",
      "[0.02972107 0.04251283 0.48721927 0.38586208]\n",
      "[0.06556354 0.01418708 0.16959068 0.78000224]\n",
      "[0.02974084 0.04443171 0.49697065 0.37554565]\n",
      "[0.06556451 0.01501141 0.17711502 0.7703202 ]\n",
      "[0.02976297 0.046421   0.50656337 0.36542946]\n",
      "[0.0655613  0.01591286 0.18521367 0.759986  ]\n",
      "[0.02978755 0.04847829 0.5159692  0.3555382 ]\n",
      "[0.06555384 0.01689791 0.19391003 0.7489854 ]\n",
      "[0.02981447 0.05060017 0.5251614  0.3458949 ]\n",
      "[0.06554214 0.01797302 0.20322083 0.737314  ]\n",
      "[0.0298438  0.05278228 0.53411424 0.33652186]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.7967289686203003\n",
      "loss training = 0.4052348732948303\n",
      "___________________________________\n",
      "Epoch 110\n",
      "[0.03018247 0.01041897 0.1917231  0.72619027]\n",
      "[0.02909267 0.03485953 0.4236821  0.4421944 ]\n",
      "[0.02996955 0.08135758 0.5991838  0.25830728]\n",
      "[0.06499554 0.0322839  0.30683595 0.61548024]\n",
      "[0.02970078 0.07058991 0.5845468  0.28374   ]\n",
      "[0.06496553 0.0323284  0.31109634 0.614399  ]\n",
      "[0.02973348 0.07129636 0.5867414  0.28183156]\n",
      "[0.06494521 0.03339503 0.31821573 0.60660934]\n",
      "[0.02975523 0.0724446  0.58966744 0.27871677]\n",
      "[0.06491842 0.03451457 0.32538748 0.59864193]\n",
      "[0.02977575 0.07358779 0.59250236 0.27568123]\n",
      "[0.06489169 0.03563845 0.3324431  0.5908385 ]\n",
      "[0.0297958  0.07470207 0.5952049  0.27278703]\n",
      "[0.06486551 0.03675953 0.3393481  0.5832417 ]\n",
      "[0.02981541 0.0757836  0.5977729  0.27003714]\n",
      "[0.06484    0.03787265 0.3460766  0.5758771 ]\n",
      "[0.02983446 0.07682963 0.6002071  0.26743114]\n",
      "[0.06481525 0.03897278 0.3526054  0.56876653]\n",
      "[0.02985293 0.07783786 0.60250837 0.26496765]\n",
      "[0.06479134 0.04005508 0.35891378 0.5619289 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8341121673583984\n",
      "loss training = 0.3853670656681061\n",
      "___________________________________\n",
      "Epoch 111\n",
      "[0.02986902 0.00940577 0.17672183 0.74665076]\n",
      "[0.02885836 0.03072881 0.39290175 0.47601107]\n",
      "[0.02966346 0.07601143 0.58284545 0.274317  ]\n",
      "[0.06485768 0.02758796 0.27474025 0.65303224]\n",
      "[0.02917841 0.06447745 0.56548524 0.30375463]\n",
      "[0.06481656 0.02682032 0.27311736 0.65851945]\n",
      "[0.02920024 0.06423767 0.5651905  0.3046074 ]\n",
      "[0.06482447 0.02694653 0.27418268 0.6574747 ]\n",
      "[0.0292106  0.06443506 0.56578964 0.30403876]\n",
      "[0.0648239  0.02711274 0.27539077 0.6561097 ]\n",
      "[0.0292194  0.06465239 0.56643075 0.30340147]\n",
      "[0.0648225  0.02728218 0.27661213 0.65472245]\n",
      "[0.02922778 0.0648706  0.5670707  0.30276072]\n",
      "[0.0648208  0.02745309 0.2778403  0.65332747]\n",
      "[0.02923575 0.06508867 0.5677072  0.30211967]\n",
      "[0.06481878 0.0276254  0.27907467 0.6519255 ]\n",
      "[0.02924332 0.06530657 0.56834006 0.30147853]\n",
      "[0.0648165  0.02779913 0.2803155  0.6505163 ]\n",
      "[0.02925052 0.06552437 0.5689695  0.30083716]\n",
      "[0.06481392 0.02797428 0.28156278 0.6491001 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8528037667274475\n",
      "loss training = 0.3675101697444916\n",
      "___________________________________\n",
      "Epoch 112\n",
      "[0.02984018 0.0100746  0.18743302 0.73008716]\n",
      "[0.02942803 0.03487119 0.42220706 0.44316378]\n",
      "[0.03364507 0.09536801 0.63121074 0.25216544]\n",
      "[0.07058468 0.03466977 0.31862608 0.61983633]\n",
      "[0.03997858 0.09922282 0.6533022  0.2864927 ]\n",
      "[0.08094867 0.04032057 0.34937295 0.6287619 ]\n",
      "[0.05141356 0.12789783 0.69904286 0.2971561 ]\n",
      "[0.09924219 0.05147839 0.39536852 0.63851005]\n",
      "[0.06716973 0.16678402 0.74350965 0.30846396]\n",
      "[0.12632148 0.06670684 0.4446542  0.6577047 ]\n",
      "[0.0848128  0.19583611 0.76458865 0.33598867]\n",
      "[0.15197341 0.07639685 0.46922114 0.68764967]\n",
      "[0.09787902 0.20709115 0.7692537  0.3654654 ]\n",
      "[0.16964194 0.07759868 0.4677012  0.7195188 ]\n",
      "[0.10526644 0.204234   0.76394403 0.3931993 ]\n",
      "[0.17935106 0.07238586 0.4473279  0.75058824]\n",
      "[0.10831519 0.19219239 0.7515611  0.4203543 ]\n",
      "[0.18285659 0.06391067 0.41566464 0.7792456 ]\n",
      "[0.10823221 0.174868   0.7334896  0.4473263 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18145429 0.0544836  0.37831914 0.8042172 ]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.8738317489624023\n",
      "loss training = 0.34251174330711365\n",
      "___________________________________\n",
      "Epoch 113\n",
      "[0.03033461 0.01512459 0.26006067 0.64072347]\n",
      "[0.03656934 0.06852212 0.5709184  0.3338924 ]\n",
      "[0.07711731 0.01966922 0.21282694 0.75595677]\n",
      "[0.04593464 0.08411027 0.6262188  0.35027143]\n",
      "[0.09611732 0.02756755 0.26521653 0.75075865]\n",
      "[0.06306702 0.12284685 0.6953115  0.35224438]\n",
      "[0.12822942 0.04155398 0.3350991  0.75159395]\n",
      "[0.08461493 0.16870071 0.7470741  0.3607065 ]\n",
      "[0.16236757 0.05720382 0.3956334  0.7570591 ]\n",
      "[0.10169017 0.19185178 0.7615501  0.38476658]\n",
      "[0.18343134 0.06376522 0.41648203 0.77115846]\n",
      "[0.11043686 0.19476973 0.75967604 0.40818566]\n",
      "[0.19349863 0.06340552 0.41339564 0.7867495 ]\n",
      "[0.1140381  0.18835019 0.7513759  0.428953  ]\n",
      "[0.19713025 0.05977312 0.39906174 0.8015539 ]\n",
      "[0.11478285 0.17759533 0.73933226 0.44831622]\n",
      "[0.19679168 0.054825   0.37953922 0.8148838 ]\n",
      "[0.11374379 0.16491945 0.72472215 0.46652472]\n",
      "[0.19367659 0.04949811 0.3576673  0.8265061 ]\n",
      "[0.11139357 0.15152511 0.7081299  0.48340967]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8785046935081482\n",
      "loss training = 0.3662227392196655\n",
      "___________________________________\n",
      "Epoch 114\n",
      "[0.02521724 0.01477095 0.26425993 0.5908851 ]\n",
      "[0.02569632 0.05681173 0.5393273  0.27745637]\n",
      "[0.05724258 0.01780271 0.20796433 0.69286877]\n",
      "[0.02568098 0.05695464 0.55671567 0.27458882]\n",
      "[0.05755888 0.02105177 0.2381278  0.6569925 ]\n",
      "[0.02677415 0.06594057 0.5859711  0.2555037 ]\n",
      "[0.05861383 0.02574336 0.2747194  0.6159412 ]\n",
      "[0.02889412 0.07822149 0.6181916  0.2404463 ]\n",
      "[0.06080034 0.03171685 0.31568184 0.5773243 ]\n",
      "[0.03250258 0.09504405 0.65373427 0.23033401]\n",
      "[0.06467868 0.03929912 0.3602092  0.5446555 ]\n",
      "[0.03792041 0.11749569 0.6911054  0.22463958]\n",
      "[0.07165135 0.04952803 0.4097744  0.5206766 ]\n",
      "[0.04523466 0.14589053 0.7276299  0.22215368]\n",
      "[0.08151583 0.06257247 0.46102247 0.50472164]\n",
      "[0.05397887 0.1784046  0.75999534 0.22160685]\n",
      "[0.09252878 0.07710465 0.5075411  0.4942304 ]\n",
      "[0.08465072 0.02056747 0.21829003 0.75735056]\n",
      "[0.03610133 0.07203857 0.6017449  0.31299627]\n",
      "[0.06734207 0.02125188 0.23382227 0.70311725]\n",
      "ABABA1AABBAAB => BABABABABABABABAABAB\n",
      "accuracy training = 0.8574766516685486\n",
      "loss training = 0.35338035225868225\n",
      "___________________________________\n",
      "Epoch 115\n",
      "[0.02511068 0.01213829 0.2266612  0.63931453]\n",
      "[0.02452586 0.0450412  0.48692763 0.32182285]\n",
      "[0.05756611 0.01320053 0.165189   0.75236714]\n",
      "[0.0241231  0.04256502 0.49339482 0.3264255 ]\n",
      "[0.05742528 0.0146044  0.18096901 0.7316714 ]\n",
      "[0.02417407 0.04640008 0.51175153 0.30813158]\n",
      "[0.05728978 0.01668428 0.20057154 0.7042108 ]\n",
      "[0.02423037 0.05063861 0.529391   0.29044387]\n",
      "[0.05713068 0.01910037 0.2222291  0.67456037]\n",
      "[0.02429982 0.05499882 0.54558325 0.2744606 ]\n",
      "[0.05696323 0.02182793 0.24542744 0.64368844]\n",
      "[0.02438584 0.05940222 0.5602539  0.26025438]\n",
      "[0.05679903 0.02482527 0.2694952  0.6126216 ]\n",
      "[0.02449387 0.0637759  0.57341826 0.2478316 ]\n",
      "[0.05665151 0.02801584 0.2935954  0.58249676]\n",
      "[0.02463234 0.06805293 0.5851562  0.23717096]\n",
      "[0.05653524 0.03129325 0.31684518 0.5543929 ]\n",
      "[0.02481133 0.07217949 0.5955995  0.22821659]\n",
      "[0.05646358 0.03453629 0.33846182 0.52915776]\n",
      "[0.02505036 0.07613657 0.6048671  0.22088768]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8107476830482483\n",
      "loss training = 0.3891667127609253\n",
      "___________________________________\n",
      "Epoch 116\n",
      "[0.02541617 0.01072235 0.204635   0.6769783 ]\n",
      "[0.02434224 0.03902286 0.45202866 0.3660367 ]\n",
      "[0.0589467  0.01085474 0.14148468 0.7934729 ]\n",
      "[0.0244044  0.03614893 0.45178205 0.37890494]\n",
      "[0.05906843 0.01164958 0.15133075 0.78135073]\n",
      "[0.02446673 0.03878894 0.46678603 0.36318088]\n",
      "[0.05899153 0.01294215 0.16437826 0.7630328 ]\n",
      "[0.02451141 0.04178862 0.48190838 0.3469737 ]\n",
      "[0.05888135 0.01443058 0.1788843  0.74289006]\n",
      "[0.02456308 0.04490417 0.49623463 0.3317588 ]\n",
      "[0.05875688 0.01610705 0.19467485 0.7213406 ]\n",
      "[0.02462357 0.04809577 0.5096505  0.31765997]\n",
      "[0.05862324 0.01796969 0.21157008 0.6987146 ]\n",
      "[0.02469368 0.0513291  0.5221063  0.30472252]\n",
      "[0.05848593 0.02000552 0.22929269 0.67545295]\n",
      "[0.02477536 0.05456733 0.53358203 0.29297736]\n",
      "[0.05835163 0.0221876  0.24747258 0.6520918 ]\n",
      "[0.02487211 0.05777401 0.54408985 0.28244236]\n",
      "[0.05822806 0.0244749  0.265675   0.62921625]\n",
      "[0.02498909 0.06091677 0.5536746  0.27312008]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.8341121673583984\n",
      "loss training = 0.3895271420478821\n",
      "___________________________________\n",
      "Epoch 117\n",
      "[0.02531916 0.00991756 0.19299689 0.69736177]\n",
      "[0.02423118 0.03614175 0.43188938 0.392299  ]\n",
      "[0.05939523 0.00968001 0.12942143 0.8138841 ]\n",
      "[0.02423652 0.03283335 0.42886344 0.4093099 ]\n",
      "[0.05955764 0.01023471 0.13690436 0.8051716 ]\n",
      "[0.02429578 0.03496931 0.44219574 0.39502177]\n",
      "[0.05949748 0.0112272  0.14728902 0.7906541 ]\n",
      "[0.02432964 0.03744439 0.45598915 0.37976006]\n",
      "[0.05940091 0.01236433 0.15883772 0.7746068 ]\n",
      "[0.02436838 0.04002637 0.4692536  0.3651833 ]\n",
      "[0.05929033 0.01363901 0.17143764 0.7573306 ]\n",
      "[0.02441441 0.04268751 0.48187307 0.35143238]\n",
      "[0.05916965 0.01505455 0.18501894 0.7389789 ]\n",
      "[0.02446845 0.04540759 0.49379382 0.338562  ]\n",
      "[0.05904242 0.01660929 0.19945605 0.7197731 ]\n",
      "[0.02453187 0.04816443 0.5049828  0.32661587]\n",
      "[0.05891319 0.01829422 0.21455902 0.7000126 ]\n",
      "[0.02460736 0.05093521 0.51542974 0.31563017]\n",
      "[0.05878764 0.02009184 0.23007832 0.6800628 ]\n",
      "[0.02469931 0.05369889 0.5251511  0.30563277]\n",
      "ABABA1AABBAAB => BABABABABABABABABABA\n",
      "accuracy training = 0.836448609828949\n",
      "loss training = 0.381559282541275\n",
      "___________________________________\n",
      "Epoch 118\n",
      "[0.02524468 0.00931963 0.1839136  0.711535  ]\n",
      "[0.02407109 0.03406171 0.41615716 0.41051635]\n",
      "[0.06002026 0.00890903 0.12058437 0.8271231 ]\n",
      "[0.02411437 0.03058987 0.41103357 0.4303849 ]\n",
      "[0.02468242 0.0739316  0.5657533  0.25353622]\n",
      "[0.05849699 0.02888829 0.2915832  0.60146093]\n",
      "[0.02481106 0.06311094 0.54702234 0.2812503 ]\n",
      "[0.05867504 0.02915076 0.29759225 0.5983757 ]\n",
      "[0.0250645  0.06452885 0.5512386  0.2789471 ]\n",
      "[0.05871543 0.03054449 0.30735657 0.58758295]\n",
      "[0.02538988 0.06672595 0.55737096 0.2754096 ]\n",
      "[0.05880274 0.03194294 0.3166533  0.5775722 ]\n",
      "[0.02581682 0.06912018 0.5639758  0.27242637]\n",
      "[0.05895798 0.0332741  0.32521632 0.5688267 ]\n",
      "[0.02632169 0.07161936 0.57075745 0.2700104 ]\n",
      "[0.05917034 0.03452574 0.33302847 0.5612875 ]\n",
      "[0.02687215 0.0741436  0.5774626  0.2680651 ]\n",
      "[0.05942377 0.03568996 0.34009436 0.55484086]\n",
      "[0.02743928 0.07662047 0.5838867  0.26649964]\n",
      "[0.05970273 0.03676191 0.346435   0.5493603 ]\n",
      "ABABA1AABBAAB => BABBABABABABABABABAB\n",
      "accuracy training = 0.8457943797111511\n",
      "loss training = 0.3772728443145752\n",
      "___________________________________\n",
      "Epoch 119\n",
      "[0.02513588 0.0087647  0.17575718 0.7231429 ]\n",
      "[0.02381673 0.03208213 0.40178704 0.42543003]\n",
      "[0.0244719  0.07179148 0.55290955 0.26202062]\n",
      "[0.05889103 0.02566085 0.2666099  0.6304998 ]\n",
      "[0.02454792 0.05858532 0.528744   0.29754686]\n",
      "[0.05912326 0.02569518 0.27164263 0.62898177]\n",
      "[0.02475955 0.05977141 0.53252083 0.29515445]\n",
      "[0.05912131 0.02698555 0.2813154  0.6178085 ]\n",
      "[0.02498969 0.06173188 0.538308   0.29092854]\n",
      "[0.05913087 0.0283014  0.29068255 0.60707235]\n",
      "[0.02529694 0.06383424 0.5444399  0.2872021 ]\n",
      "[0.05919076 0.02956453 0.29940736 0.5974294 ]\n",
      "[0.02568176 0.06603825 0.5507893  0.284065  ]\n",
      "[0.05930239 0.03076518 0.3074718  0.588891  ]\n",
      "[0.02613125 0.06831739 0.55725366 0.2814539 ]\n",
      "[0.0594602  0.03189861 0.31488425 0.5813984 ]\n",
      "[0.02662763 0.07063351 0.56370103 0.2792937 ]\n",
      "[0.0596558  0.03296138 0.32166135 0.57486886]\n",
      "[0.0271524  0.07294448 0.57000023 0.2775124 ]\n",
      "[0.0598798  0.03395142 0.3278274  0.56920815]\n",
      "ABABA1AABBAAB => BBABABABABABABABABAB\n",
      "accuracy training = 0.836448609828949\n",
      "loss training = 0.37481775879859924\n",
      "___________________________________\n",
      "Epoch 120\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-91338c54aaff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         tr_loss, tr_acc = model.train_on_batch(np.array([[one_hot_input]]),\n\u001b[0;32m--> 104\u001b[0;31m                                                np.array([one_hot_output]))\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mmean_tr_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mmean_tr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pixiedust\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "#text = ';'.join([s + '.' + s[::-1] for s in [''.join(random.choices(['A','B','C','D','E','F','G','H','I'], k=4)) for i in range(0, 100)]])\n",
    "#text_test = 'ABCD.'\n",
    "\n",
    "# text = \"ABABABABABABABABABABABABABABABABABABABABABABAB\"\n",
    "# text_test = \"BABAB\"\n",
    "\n",
    "#text = \"ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB.ABB\"\n",
    "#text_test = \"BB.ABB.ABB.A\"\n",
    "\n",
    "text = \"1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA1AABBAABB2BABABABA\"\n",
    "text_test = \"ABABA1AABBAAB\"\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "one_hot_chars = np.eye(len(chars))\n",
    "\n",
    "N_train = 1\n",
    "max_len = len(text)\n",
    "input_len = len(chars)\n",
    "lstm_t = 1 * input_len\n",
    "\n",
    "# print('Vectorization...')\n",
    "# X_train = np.zeros((N_train, max_len, input_len), dtype=np.bool)\n",
    "# # Y_train = np.zeros((N_train, input_len), dtype=np.bool)\n",
    "# for t, char in enumerate(text):\n",
    "#     X_train[0, t, char_indices[char]] = 1\n",
    "# # Y_train[0, char_indices[text[t+1]]] = 1\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(lstm_t, batch_input_shape=(1, 1, input_len), return_sequences=False, stateful=True))\n",
    "model.add(Dense(input_len, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(text)\n",
    "print()\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch):\n",
    "    input_text = []\n",
    "    output_text = []\n",
    "\n",
    "    for i in range(0, len(text_test) - 1):\n",
    "        input_char = text_test[i]\n",
    "        one_hot_input = one_hot_chars[char_indices[input_char]]\n",
    "        preds = model.predict(np.array([[one_hot_input]]), verbose=0)[0]\n",
    "\n",
    "    char = text_test[-1]\n",
    "    for i in range(0, 20):\n",
    "        input_char = char\n",
    "        one_hot_input = one_hot_chars[char_indices[input_char]]\n",
    "        input_text.append(input_char)\n",
    "\n",
    "        preds = model.predict(np.array([[one_hot_input]]), verbose=0)[0]\n",
    "        print(preds)\n",
    "\n",
    "        char = indices_char[sample(preds, 0.01)]\n",
    "        output_text.append(char)\n",
    "\n",
    "    #print('input  = {}'.format(''.join(input_text)))\n",
    "    #print('output = {}'.format(''.join(output_text)))\n",
    "    print('{} => {}'.format(text_test, ''.join(output_text)))\n",
    "\n",
    "        \n",
    "print('Train...')\n",
    "for epoch in range(500):\n",
    "    print('Epoch {}'.format(epoch))\n",
    "    mean_tr_acc = []\n",
    "    mean_tr_loss = []\n",
    "    for i in range(0, len(text) - 1):\n",
    "        input_char = text[i]\n",
    "        output_char = text[i+1]\n",
    "        #print('{} -> {}'.format(input_char, output_char))\n",
    "        one_hot_input = one_hot_chars[char_indices[input_char]]\n",
    "        one_hot_output = one_hot_chars[char_indices[output_char]]\n",
    "\n",
    "        tr_loss, tr_acc = model.train_on_batch(np.array([[one_hot_input]]),\n",
    "                                               np.array([one_hot_output]))\n",
    "        mean_tr_acc.append(tr_acc)\n",
    "        mean_tr_loss.append(tr_loss)\n",
    "    model.reset_states()\n",
    "\n",
    "    on_epoch_end(epoch)\n",
    "    print('accuracy training = {}'.format(np.mean(mean_tr_acc)))\n",
    "    print('loss training = {}'.format(np.mean(mean_tr_loss)))\n",
    "    print('___________________________________')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
