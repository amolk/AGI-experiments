{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02 Test BetaVAE.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oLazUxVPHSDB","colab_type":"text"},"source":["From https://github.com/1Konny/Beta-VAE"]},{"cell_type":"code","metadata":{"id":"dOdWaSfiHEqG","colab_type":"code","colab":{}},"source":["\"\"\"model.py\"\"\"\n","\n","import torch\n","import torch.nn as nn\n","#import torch.nn.functional as F\n","import torch.nn.init as init\n","from torch.autograd import Variable\n","\n","\n","def reparametrize(mu, logvar):\n","    std = logvar.div(2).exp()\n","    eps = Variable(std.data.new(std.size()).normal_())\n","    return mu + std*eps\n","\n","\n","class View(nn.Module):\n","    def __init__(self, size):\n","        super(View, self).__init__()\n","        self.size = size\n","\n","    def forward(self, tensor):\n","        return tensor.view(self.size)\n","\n","\n","class BetaVAE_H(nn.Module):\n","    \"\"\"Model proposed in original beta-VAE paper(Higgins et al, ICLR, 2017).\"\"\"\n","\n","    def __init__(self, z_dim=10, nc=3):\n","        super(BetaVAE_H, self).__init__()\n","        self.z_dim = z_dim\n","        self.nc = nc\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(nc, 32, 4, 2, 1),          # B,  32, 32, 32\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32, 16, 16\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 64, 4, 2, 1),          # B,  64,  8,  8\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 64, 4, 2, 1),          # B,  64,  4,  4\n","            nn.ReLU(True),\n","            nn.Conv2d(64, 256, 4, 1),            # B, 256,  1,  1\n","            nn.ReLU(True),\n","            View((-1, 256*1*1)),                 # B, 256\n","            nn.Linear(256, z_dim*2),             # B, z_dim*2\n","        )\n","        self.decoder = nn.Sequential(\n","            nn.Linear(z_dim, 256),               # B, 256\n","            View((-1, 256, 1, 1)),               # B, 256,  1,  1\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(256, 64, 4),      # B,  64,  4,  4\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 64, 4, 2, 1), # B,  64,  8,  8\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(64, 32, 4, 2, 1), # B,  32, 16, 16\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 32, 32\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, nc, 4, 2, 1),  # B, nc, 64, 64\n","        )\n","\n","        self.weight_init()\n","\n","    def weight_init(self):\n","        for block in self._modules:\n","            for m in self._modules[block]:\n","                kaiming_init(m)\n","\n","    def forward(self, x):\n","        distributions = self._encode(x)\n","        mu = distributions[:, :self.z_dim]\n","        logvar = distributions[:, self.z_dim:]\n","        z = reparametrize(mu, logvar)\n","        x_recon = self._decode(z)\n","\n","        return x_recon, mu, logvar\n","\n","    def _encode(self, x):\n","        return self.encoder(x)\n","\n","    def _decode(self, z):\n","        return self.decoder(z)\n","\n","\n","class BetaVAE_B(BetaVAE_H):\n","    \"\"\"Model proposed in understanding beta-VAE paper(Burgess et al, arxiv:1804.03599, 2018).\"\"\"\n","\n","    def __init__(self, z_dim=10, nc=1):\n","        super(BetaVAE_B, self).__init__()\n","        self.nc = nc\n","        self.z_dim = z_dim\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(nc, 32, 4, 2, 1),          # B,  32, 32, 32\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32, 16, 16\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32,  8,  8\n","            nn.ReLU(True),\n","            nn.Conv2d(32, 32, 4, 2, 1),          # B,  32,  4,  4\n","            nn.ReLU(True),\n","            View((-1, 32*4*4)),                  # B, 512\n","            nn.Linear(32*4*4, 256),              # B, 256\n","            nn.ReLU(True),\n","            nn.Linear(256, 256),                 # B, 256\n","            nn.ReLU(True),\n","            nn.Linear(256, z_dim*2),             # B, z_dim*2\n","        )\n","\n","        self.decoder = nn.Sequential(\n","            nn.Linear(z_dim, 256),               # B, 256\n","            nn.ReLU(True),\n","            nn.Linear(256, 256),                 # B, 256\n","            nn.ReLU(True),\n","            nn.Linear(256, 32*4*4),              # B, 512\n","            nn.ReLU(True),\n","            View((-1, 32, 4, 4)),                # B,  32,  4,  4\n","            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32,  8,  8\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 16, 16\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, 32, 4, 2, 1), # B,  32, 32, 32\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(32, nc, 4, 2, 1), # B,  nc, 64, 64\n","        )\n","        self.weight_init()\n","\n","    def weight_init(self):\n","        for block in self._modules:\n","            for m in self._modules[block]:\n","                kaiming_init(m)\n","\n","    def forward(self, x):\n","        distributions = self._encode(x)\n","        mu = distributions[:, :self.z_dim]\n","        logvar = distributions[:, self.z_dim:]\n","        z = reparametrize(mu, logvar)\n","        x_recon = self._decode(z).view(x.size())\n","\n","        return x_recon, mu, logvar\n","\n","    def _encode(self, x):\n","        return self.encoder(x)\n","\n","    def _decode(self, z):\n","        return self.decoder(z)\n","\n","\n","def kaiming_init(m):\n","    if isinstance(m, (nn.Linear, nn.Conv2d)):\n","        init.kaiming_normal(m.weight)\n","        if m.bias is not None:\n","            m.bias.data.fill_(0)\n","    elif isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d)):\n","        m.weight.data.fill_(1)\n","        if m.bias is not None:\n","            m.bias.data.fill_(0)\n","\n","\n","def normal_init(m, mean, std):\n","    if isinstance(m, (nn.Linear, nn.Conv2d)):\n","        m.weight.data.normal_(mean, std)\n","        if m.bias.data is not None:\n","            m.bias.data.zero_()\n","    elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n","        m.weight.data.fill_(1)\n","        if m.bias.data is not None:\n","            m.bias.data.zero_()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rwGHDTs3HYl3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}