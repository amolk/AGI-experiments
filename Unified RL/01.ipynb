{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"asxI0xI9MW14","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1836},"outputId":"a2f78f5f-466f-4b8b-9237-8217f9c774d4","executionInfo":{"status":"ok","timestamp":1560224178334,"user_tz":420,"elapsed":341,"user":{"displayName":"Amol Kelkar","photoUrl":"","userId":"07278259258766517376"}}},"source":["from enum import Enum\n","import random\n","import numpy as np\n","\n","GRID_HEIGHT = 5\n","GRID_WIDTH = 6\n","\n","class ACTION(int, Enum):\n","  UP = 0\n","  DOWN = 1\n","  LEFT = 2\n","  RIGHT = 3\n","  \n","ACTION_MIN = 0\n","ACTION_MAX = ACTION.RIGHT\n","\n","class Agent:\n","  def __init__(self):\n","    pass\n","  \n","  def get_next_action(self, observation):\n","    return ACTION(random.randint(ACTION_MIN, ACTION_MAX))\n","\n","\n","class GridWorld:\n","  def __init__(self, height, width):\n","    self.height = height\n","    self.width = width\n","    self.init_board()\n","    self.agent_y = self.agent_x = 1\n","    \n","    self.set_agent_position(y=random.randint(1, height-2), x=random.randint(1, width-2))\n","    self.agent = Agent()\n","\n","  def init_board(self):\n","    self.board = np.zeros((self.height, self.width), int)\n","    self.board[0,:] = 1\n","    self.board[-1, :] = 1\n","    self.board[:, 0] = 1\n","    self.board[:, -1] = 1\n","    \n","  def set_agent_position(self, y, x):\n","    self.board[self.agent_y, self.agent_x] = 0\n","    self.agent_y = y\n","    self.agent_x = x\n","    self.board[self.agent_y, self.agent_x] = 2\n","\n","  def __repr__(self):\n","    s = []\n","    s.append(f\"GridWorld(height={self.height}, width={self.width})\")\n","    s.append(f\"    Agent x={self.agent_x}, y={self.agent_y}\")\n","    s.append(\"\\n\".join([\"\".join([str(self.board[row, col]) for col in range(self.width)]) for row in range(self.height)]))\n","    return \"\\n\".join(s)\n","    \n","  def act(self, action):\n","    agent_y = self.agent_y\n","    agent_x = self.agent_x\n","    \n","    if action == ACTION.UP:\n","      agent_y -= 1\n","    elif action == ACTION.DOWN:\n","      agent_y += 1\n","    elif action == ACTION.LEFT:\n","      agent_x -= 1\n","    elif action == ACTION.RIGHT:\n","      agent_x += 1\n","    else:\n","      raise ValueError(f\"Invalid ACTION {action}\")\n","      \n","    reward = 0\n","    \n","    if self.board[agent_y, agent_x] != 0:\n","      reward = -1\n","    else:      \n","      self.set_agent_position(y=agent_y, x=agent_x)\n","    \n","    return reward\n","  \n","  def run(self):\n","    for _ in range(10):\n","      observation = np.zeros((ACTION_MAX + 1, ))\n","      observation[ACTION.UP]     = self.board[self.agent_y + 1, self.agent_x    ]\n","      observation[ACTION.DOWN]   = self.board[self.agent_y - 1, self.agent_x    ]\n","      observation[ACTION.LEFT]   = self.board[self.agent_y    , self.agent_x - 1]\n","      observation[ACTION.RIGHT]  = self.board[self.agent_y    , self.agent_x + 1]\n","      print(\"Observation \", observation)\n","      \n","      action = self.agent.get_next_action(observation)\n","      print(action)\n","      reward = self.act(action)\n","      print(f\"    Reward {reward}\")\n","      print(self)\n","    \n","  \n","grid_world = GridWorld(GRID_HEIGHT, GRID_WIDTH)\n","print(grid_world)\n","\n","grid_world.run()"],"execution_count":49,"outputs":[{"output_type":"stream","text":["GridWorld(height=5, width=6)\n","    Agent x=4, y=2\n","111111\n","100001\n","100021\n","100001\n","111111\n","Observation  [0. 0. 0. 1.]\n","ACTION.UP\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=1\n","111111\n","100021\n","100001\n","100001\n","111111\n","Observation  [0. 1. 0. 1.]\n","ACTION.UP\n","    Reward -1\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=1\n","111111\n","100021\n","100001\n","100001\n","111111\n","Observation  [0. 1. 0. 1.]\n","ACTION.LEFT\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=3, y=1\n","111111\n","100201\n","100001\n","100001\n","111111\n","Observation  [0. 1. 0. 0.]\n","ACTION.RIGHT\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=1\n","111111\n","100021\n","100001\n","100001\n","111111\n","Observation  [0. 1. 0. 1.]\n","ACTION.DOWN\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=2\n","111111\n","100001\n","100021\n","100001\n","111111\n","Observation  [0. 0. 0. 1.]\n","ACTION.DOWN\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=3\n","111111\n","100001\n","100001\n","100021\n","111111\n","Observation  [1. 0. 0. 1.]\n","ACTION.UP\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=2\n","111111\n","100001\n","100021\n","100001\n","111111\n","Observation  [0. 0. 0. 1.]\n","ACTION.RIGHT\n","    Reward -1\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=2\n","111111\n","100001\n","100021\n","100001\n","111111\n","Observation  [0. 0. 0. 1.]\n","ACTION.DOWN\n","    Reward 0\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=3\n","111111\n","100001\n","100001\n","100021\n","111111\n","Observation  [1. 0. 0. 1.]\n","ACTION.DOWN\n","    Reward -1\n","GridWorld(height=5, width=6)\n","    Agent x=4, y=3\n","111111\n","100001\n","100001\n","100021\n","111111\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2Cxp--iGNClq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}